document_id,category,original_text,stemmed_text,word_count,keyword_percentage
6819,Computers and IT,"For pt. I. see Vestn. KhGPU, no. 81, p. 15-18 (2000). The paper presents the results of development of an object-oriented systemological method used to design complex systems. A formal system representation, as well as an axiomatics of the calculus of systems as functional flow-type objects based on a Node-Function-Object class hierarchy are proposed. A formalized NFO/UFO analysis algorithm and CASE tools used to support it are considered","for pt . i. see vestn . khgpu , no. 81 , p. 15-18 -LRB- 2000 -RRB- . the paper present the result of development of an object-oriented systemological method use to design complex system . a formal system representation , as well as an axiomatic of the calculus of system as functional flow-type object base on a node-function-object class hierarchy be propose . a formalize nfo/ufo analysis algorithm and case tool use to support it be consider",68,0.625
6820,Computers and IT,Problems and an associated technique for developing a Bayesian approach to decision-making in the case of fuzzy data are presented. The concept of fuzzy and pseudofuzzy quantities is introduced and main operations with pseudofuzzy quantities are considered. The basic relationships and the principal concepts of the Bayesian decision procedure based on the modus-ponens rule are proposed. Some problems concerned with the practical realization of the fuzzy Bayesian method are considered,problem and an associate technique for develop a bayesian approach to decision-making in the case of fuzzy data be present . the concept of fuzzy and pseudofuzzy quantity be introduce and main operation with pseudofuzzy quantity be consider . the basic relationship and the principal concept of the bayesian decision procedure base on the modus-ponen rule be propose . some problem concern with the practical realization of the fuzzy bayesian method be consider,70,0.4
6821,Computers and IT,"A safe problem with mn locks is studied. It is reduced to a system of linear equations in the modulo 2 residue class. There are three possible variants defined by the numbers m and n evenness, with only one of them having a solution. In two other cases, correction of the initial state of the safe insuring a solution is proposed","a safe problem with mn lock be study . it be reduce to a system of linear equation in the modulo 2 residue class . there be three possible variant define by the number m and n evenness , with only one of them have a solution . in two other case , correction of the initial state of the safe insure a solution be propose",61,0.5
6822,Computers and IT,A general accelerated simulation method for evaluation of the steady-state availability of non-Markovian systems is proposed. It is applied to the investigation of a class of systems with repair. Numerical examples are given,a general accelerate simulation method for evaluation of the steady-state availability of non-markovian system be propose . it be apply to the investigation of a class of system with repair . numerical example be give,33,1
6823,Computers and IT,New optimal control problems are considered for distributed systems described by elliptic equations with conjugate conditions and a quadratic minimized function. Highly accurate computational discretization schemes are constructed for the case where a feasible control set u/sub delta / coincides with the full Hilbert space u of controls,new optimal control problem be consider for distribute system describe by elliptic equation with conjugate condition and a quadratic minimize function . highly accurate computational discretization scheme be construct for the case where a feasible control set u/sub delta / coincide with the full hilbert space u of control,48,1
6824,Computers and IT,"The problem of identification of states of complex systems on the basis of fuzzy values of informative attributes is considered. Some estimates of a maximally admissible degree of measurement error are obtained that make it possible, using the apparatus of fuzzy set theory, to correctly identify the current state of a system","the problem of identification of state of complex system on the basis of fuzzy value of informative attribute be consider . some estimate of a maximally admissible degree of measurement error be obtain that make it possible , use the apparatus of fuzzy set theory , to correctly identify the current state of a system",52,0.5
6825,Computers and IT,"For pt. I. see Upr. Sist. Mash. , no. 6, p. 29-42 (1999). A new approach to the decomposition of Boolean, functions that depend on n variables and are represented in various forms is considered. The approach is based on the method of q-partitioning of minterms and on the introduced concept of a decomposition clone. The theorem on simple disjunctive decomposition of full and partial functions is formulated. The approach proposed is illustrated by examples","for pt . i. see upr . sist . mash . , no. 6 , p. 29-42 -LRB- 1999 -RRB- . a new approach to the decomposition of boolean , function that depend on n variable and be represent in various form be consider . the approach be base on the method of q-partitioning of minterm and on the introduce concept of a decomposition clone . the theorem on simple disjunctive decomposition of full and partial function be formulate . the approach propose be illustrate by example",75,0.714285714
6826,Computers and IT,"A method of construction of a nonlinear extrapolation algorithm is proposed. This method makes it possible to take into account any nonlinear random dependences that exist in an investigated process and are described by mixed central moment functions. The method is based on the V. S. Pugachev canonical decomposition apparatus. As an example, the problem of nonlinear extrapolation is solved for a moment function of third order","a method of construction of a nonlinear extrapolation algorithm be propose . this method make it possible to take into account any nonlinear random dependence that exist in an investigate process and be describe by mixed central moment function . the method be base on the v. s. pugachev canonical decomposition apparatus . as an example , the problem of nonlinear extrapolation be solve for a moment function of third order",67,0.833333333
6827,Computers and IT,A system of linear algebraic equations with m-dimensional lambda -matrices is considered. The proposed method of searching for the solution of this system lies in reducing it to a numerical system of a special kind,a system of linear algebraic equation with m-dimensional lambda - matrix be consider . the propose method of search for the solution of this system lie in reduce it to a numerical system of a special kind,35,1
6828,Computers and IT,"Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types of systems and systems of mixed types","criterion of compatibility of a system of linear diophantine equation , strict inequation , and nonstrict inequation be consider . upper bound for component of a minimal set of solution and algorithm of construction of minimal generate set of solution for all type of system be give . these criterion and the corresponding algorithm for construct a minimal support set of solution can be use in solve all the consider type of system and system of mixed type",74,0.714285714
6829,Computers and IT,"This article reviews the last two-and-a-half decades of literature on acquiring out-of-print materials to assess recurring issues and identify changing practices. The out-of-print literature is uniform in its assertion that libraries need to acquire o. p. materials to replace worn or damaged copies, to replace missing copies, to duplicate copies of heavily used materials, to fill gaps in collections, to strengthen weak collections, to continue to develop strong collections, and to provide materials for new courses, new programs, and even entire new libraries","this article review the last two-and-a-half decade of literature on acquire out-of-print material to assess recur issue and identify change practice . the out-of-print literature be uniform in its assertion that library need to acquire o. p. material to replace worn or damaged copy , to replace miss copy , to duplicate copy of heavily used material , to fill gap in collection , to strengthen weak collection , to continue to develop strong collection , and to provide material for new course , new program , and even entire new library",83,0.5
6830,Computers and IT,Optimization problems on graphs are formulated to obtain new lower bounds of the size of error-correcting codes for the Z-channel,optimization problem on graph be formulate to obtain new low bound of the size of error-correcting code for the z-channel,20,1
6831,Computers and IT,"Descriptological foundations of programming are constructed. An explication of the concept of a descriptive process is given. The operations of introduction and elimination of abstraction at the level of processes are refined. An intensional concept of a bipolar function is introduced. An explication of the concept of introduction and extraction of abstraction at the bipole level is given. On this basis, a complete set of descriptological operations is constructed","descriptological foundation of programming be construct . an explication of the concept of a descriptive process be give . the operation of introduction and elimination of abstraction at the level of process be refine . an intensional concept of a bipolar function be introduce . an explication of the concept of introduction and extraction of abstraction at the bipole level be give . on this basis , a complete set of descriptological operation be construct",69,1
6832,Computers and IT,"Orthogonal frequency division multiplexing (OFDM) has been applied in broadband wireline and wireless systems for high data rate transmission where severe intersymbol interference (ISI) always occurs. The conventional OFDM system provides advantages through conversion of an ISI channel into ISI-free subchannels at multiple frequency bands. However, it may suffer from channel spectral nulls and heavy data rate overhead due to cyclic prefix insertion. Previously, a new OFDM framework, the precoded OFDM, has been proposed to mitigate the above two problems through precoding and conversion of an ISI channel into ISI-free vector channels. In this paper, we consider the application of the precoded OFDM system to efficient scalable video transmission. We propose to enhance the precoded OFDM system with adaptive vector channel allocation to provide stronger protection against errors to more important layers in the layered bit stream structure of scalable video. The more critical layers, or equivalently, the lower layers, are allocated vector channels of higher transmission quality. The channel quality is characterized by Frobenius norm metrics; based on channel estimation at the receiver. The channel allocation information is fed back periodically to the transmitter through a control channel. Simulation results have demonstrated the robustness of the proposed scheme to noise and fading inherent in wireless channels","orthogonal frequency division multiplex -LRB- ofdm -RRB- have be apply in broadband wireline and wireless system for high data rate transmission where severe intersymbol interference -LRB- isi -RRB- always occur . the conventional ofdm system provide advantage through conversion of an isi channel into isi-free subchannel at multiple frequency band . however , it may suffer from channel spectral null and heavy data rate overhead due to cyclic prefix insertion . previously , a new ofdm framework , the precoded ofdm , have be propose to mitigate the above two problem through precod and conversion of an isi channel into isi-free vector channel . in this paper , we consider the application of the precoded ofdm system to efficient scalable video transmission . we propose to enhance the precoded ofdm system with adaptive vector channel allocation to provide strong protection against error to more important layer in the layered bit stream structure of scalable video . the more critical layer , or equivalently , the low layer , be allocate vector channel of high transmission quality . the channel quality be characterize by frobeniu norm metric ; base on channel estimation at the receiver . the channel allocation information be feed back periodically to the transmitter through a control channel . simulation result have demonstrate the robustness of the propose scheme to noise and fading inherent in wireless channel",207,0.944444444
6833,Computers and IT,"The popularity regarding wireless communications is such that more and more WAP sites have been developed with wireless markup language (WML). Meanwhile, to translate hypertext markup language (HTML) pages into proper WML ones becomes imperative since it is difficult for WAP users to read most contents designed for PC users via their mobile phone screens. However, for those sites that have been maintained with hypertext markup language (HTML), considerable time and manpower costs will be incurred to rebuild them with WML. In this paper, we propose an intelligent WAP site management system to cope with these problems. With the help of the intelligent management system, the original contents of HTML Web sites can be automatically translated to proper WAP content in an efficient way. As a consequence, the costs associated with maintaining WAP sites could be significantly reduced. The management system also allows the system manager to define the relevance of numerals and keywords for removing unimportant or meaningless contents. The original contents will be reduced and reorganized to fit the size of mobile phone screens, thus reducing the communication cost and enhancing readability. Numerical results gained through various experiments have evinced the effective performance of the WAP management system","the popularity regard wireless communication be such that more and more wap site have be develop with wireless markup language -LRB- wml -RRB- . meanwhile , to translate hypertext markup language -LRB- html -RRB- page into proper wml one become imperative since it be difficult for wap user to read most content design for pc user via their mobile phone screen . however , for those site that have be maintain with hypertext markup language -LRB- html -RRB- , considerable time and manpower cost will be incur to rebuild them with wml . in this paper , we propose an intelligent wap site management system to cope with these problem . with the help of the intelligent management system , the original content of html web site can be automatically translate to proper wap content in an efficient way . as a consequence , the cost associate with maintain wap site could be significantly reduce . the management system also allow the system manager to define the relevance of numeral and keyword for remove unimportant or meaningless content . the original content will be reduce and reorganize to fit the size of mobile phone screen , thus reduce the communication cost and enhance readability . numerical result gain through various experiment have evince the effective performance of the wap management system",200,0.7
6834,Computers and IT,"To render government procurement efficient, transparent, nondiscriminating, and accountable, an electronic government procurement system is required. Accordingly, Taiwan government procurement law (TGPL) states that suppliers may employ electronic devices to forward a tender. This investigation demonstrates how the electronic government procurement system functions and reengineers internal procurement processes, which in turn benefits both government bodies and vendors. The system features explored herein include posting/receiving bids via the Internet, vendor registration, certificate authorization, contract development tools, bid/request for proposal (RFP) development, online bidding, and online payment, all of which can be integrated easily within most existing information infrastructures","to render government procurement efficient , transparent , nondiscriminating , and accountable , an electronic government procurement system be require . accordingly , taiwan government procurement law -LRB- tgpl -RRB- state that supplier may employ electronic device to forward a tender . this investigation demonstrate how the electronic government procurement system function and reengineer internal procurement process , which in turn benefit both government body and vendor . the system feature explore herein include posting/receiv bid via the internet , vendor registration , certificate authorization , contract development tool , bid/requ for proposal -LRB- rfp -RRB- development , online bidding , and online payment , all of which can be integrate easily within most exist information infrastructure",97,0.5625
6835,Computers and IT,"A mobile manipulator imaging system is developed for the automation of bridge crack inspection. During bridge safety inspections, an eyesight inspection is made for preliminary evaluation and screening before a more precise inspection. The inspection for cracks is an important part of the preliminary evaluation. Currently, the inspectors must stand on the platform of a bridge inspection vehicle or a temporarily erected scaffolding to examine the underside of a bridge. However, such a procedure is risky. To help automate the bridge crack inspection process, we installed two CCD cameras and a four-axis manipulator system on a mobile vehicle. The parallel cameras are used to detect cracks. The manipulator system is equipped with binocular charge coupled devices (CCD) for examining structures that may not be accessible to the eye. The system also reduces the danger of accidents to the human inspectors. The manipulator system consists of four arms. Balance weights are placed at the ends of arms 2 and 4, respectively, to maintain the center of gravity during operation. Mechanically, arms 2 and 4 can revolve smoothly. Experiments indicated that the system could be useful for bridge crack inspections","a mobile manipulator imaging system be develop for the automation of bridge crack inspection . during bridge safety inspection , an eyesight inspection be make for preliminary evaluation and screen before a more precise inspection . the inspection for crack be an important part of the preliminary evaluation . currently , the inspector must stand on the platform of a bridge inspection vehicle or a temporarily erect scaffolding to examine the underside of a bridge . however , such a procedure be risky . to help automate the bridge crack inspection process , we instal two ccd camera and a four-axis manipulator system on a mobile vehicle . the parallel camera be use to detect crack . the manipulator system be equip with binocular charge couple device -LRB- ccd -RRB- for examine structure that may not be accessible to the eye . the system also reduce the danger of accident to the human inspector . the manipulator system consist of four arm . balance weight be place at the end of arm 2 and 4 , respectively , to maintain the center of gravity during operation . mechanically , arm 2 and 4 can revolve smoothly . experiment indicate that the system could be useful for bridge crack inspection",188,0.9
6836,Computers and IT,"Recently, it is of great interest to adopt the Internet/intranet to develop building management systems (BMS) and facilities management systems (FMS). This paper addresses two technical issues: the Web-based access (including database integration) and the integration of BMS and FMS. These should be addressed for accessing BMS remotely via the Internet, integrating control networks using the Internet protocols and infrastructures, and using Internet/intranet for building facilities management. An experimental Internet-enabled system that integrates building and facilities management systems has been developed and tested. This system integrated open control networks with the Internet and is developed utilizing the embedded Web server, the PC Web server and the Distributed Component Object Model (DCOM) software development technology on the platform of an open control network. Three strategies for interconnecting BMS local networks via Internet/intranet are presented and analyzed","recently , it be of great interest to adopt the internet/intranet to develop building management system -LRB- bm -RRB- and facility management system -LRB- fm -RRB- . this paper address two technical issue : the web-based access -LRB- include database integration -RRB- and the integration of bm and fm . these should be address for access bm remotely via the internet , integrate control network use the internet protocol and infrastructure , and use internet/intranet for building facility management . an experimental internet-enabled system that integrate building and facility management system have be develop and test . this system integrate open control network with the internet and be develop utilize the embed web server , the pc web server and the distribute component object model -LRB- dcom -RRB- software development technology on the platform of an open control network . three strategy for interconnect bm local network via internet/intranet be present and analyze",135,0.866666667
6837,Computers and IT,"This study examines user acceptance of building management systems (BMS) using a questionnaire survey. These systems are crucial for optimising building performance and yet it has been widely reported that users are not making full use of their systems' facilities. Established models of technology acceptance have been employed in this research, and the positive influence of user perceptions of ease of use and compatibility has been demonstrated. Previous research has indicated differing levels of importance of perceived ease of use relative to other factors. Here, perceived ease of use is shown generally to be more important, though the balance between this and compatibility is moderated by the user perceptions of voluntariness","this study examine user acceptance of build management system -LRB- bm -RRB- use a questionnaire survey . these system be crucial for optimise building performance and yet it have be widely report that user be not make full use of their system ' facility . establish model of technology acceptance have be employ in this research , and the positive influence of user perception of ease of use and compatibility have be demonstrate . previous research have indicate differ level of importance of perceive ease of use relative to other factor . here , perceive ease of use be show generally to be more important , though the balance between this and compatibility be moderate by the user perception of voluntarines",111,0.6
6838,Computers and IT,"The collective dose provides an estimate of the effects of facility operations on the public based on an estimate of the population in the area. Geographic information system software, electronic population data resources, and a personal computer were used to develop estimates of population within 80 km radii of two sites","the collective dose provide an estimate of the effect of facility operation on the public base on an estimate of the population in the area . geographic information system software , electronic population data resource , and a personal computer be use to develop estimate of population within 80 km radii of two site",51,0.833333333
6839,Computers and IT,"measurement systems Reports on a new utility for development of computational phantoms for Monte Carlo calculations and data analysis for in vivo measurements of radionuclides deposited in tissues. The individual properties of each worker can be acquired for a rather precise geometric representation of his (her) anatomy, which is particularly important for low energy gamma ray emitting sources such as thorium, uranium, plutonium and other actinides. The software enables automatic creation of an MCNP input data file based on scanning data. The utility includes segmentation of images obtained with either computed tomography or magnetic resonance imaging by distinguishing tissues according to their signal (brightness) and specification of the source and detector. In addition, a coupling of individual voxels within the tissue is used to reduce the memory demand and to increase the calculational speed. The utility was tested for low energy emitters in plastic and biological tissues as well as for computed tomography and magnetic resonance imaging scanning information","measurement system report on a new utility for development of computational phantom for monte carlo calculation and data analysis for in vivo measurement of radionuclide deposit in tissue . the individual property of each worker can be acquire for a rather precise geometric representation of his -LRB- her -RRB- anatomy , which be particularly important for low energy gamma ray emit source such as thorium , uranium , plutonium and other actinide . the software enable automatic creation of an mcnp input data file base on scan data . the utility include segmentation of image obtain with either computed tomography or magnetic resonance imaging by distinguish tissue accord to their signal -LRB- brightness -RRB- and specification of the source and detector . in addition , a coupling of individual voxel within the tissue be use to reduce the memory demand and to increase the calculational speed . the utility be test for low energy emitter in plastic and biological tissue as well as for computed tomography and magnetic resonance imaging scan information",159,0.870967742
6840,Computers and IT,"The Purdue University Libraries Interlibrary Loan unit proposed a pilot project to purchase patrons' loan requests from Amazon. com, lend them to the patrons, and then add the titles to the collection. Staff analyzed previous monograph loans, developed ordering criteria, implemented the proposal as a pilot project for six months, and evaluated the resulting patron comments, statistics, and staff perceptions. As a result of enthusiastic patron comments and a review of the project statistics, the program was extended","the purdue university library interlibrary loan unit propose a pilot project to purchase patron ' loan request from amazon . com , lend them to the patron , and then add the title to the collection . staff analyze previous monograph loan , develop order criterion , implement the proposal as a pilot project for six month , and evaluate the result patron comment , statistic , and staff perception . as a result of enthusiastic patron comment and a review of the project statistic , the program be extend",78,0.833333333
6841,Computers and IT,"We have used the plane strain theory of transversely isotropic bodies to study a piezoelectric cantilever. In order to find the general solution of a density functionally gradient piezoelectric cantilever, we have used the inverse method (i. e. the Airy stress function method). We have obtained the stress and induction functions in the form of polynomials as well as the general solution of the beam. Based on this general solution, we have deduced the solutions of the cantilever under different loading conditions. Furthermore, as applications of this general solution in engineering, we have studied the tip deflection and blocking force of a piezoelectric cantilever actuator. Finally, we have addressed a method to determine the density distribution profile for a given piezoelectric material","we have use the plane strain theory of transversely isotropic body to study a piezoelectric cantilever . in order to find the general solution of a density functionally gradient piezoelectric cantilever , we have use the inverse method -LRB- i. e. the airy stress function method -RRB- . we have obtain the stress and induction function in the form of polynomial as well as the general solution of the beam . base on this general solution , we have deduce the solution of the cantilever under different load condition . furthermore , as application of this general solution in engineering , we have study the tip deflection and block force of a piezoelectric cantilever actuator . finally , we have address a method to determine the density distribution profile for a give piezoelectric material",122,1
6842,Computers and IT,We report an experiment on mapping a quantum state of light onto the ground state spin of an ensemble of Cs atoms with the lifetime of 2 ms. Recording of one of the two quadrature phase operators of light is demonstrated with vacuum and squeezed states of light. The sensitivity of the mapping procedure at the level of approximately 1 photon/sec per Hz is shown. The results pave the road towards complete (storing both quadrature phase observables) quantum memory for Gaussian states of light. The experiment also sheds new light on fundamental limits of sensitivity of the magneto-optical resonance method,we report an experiment on map a quantum state of light onto the ground state spin of an ensemble of c atom with the lifetime of 2 ms. recording of one of the two quadrature phase operator of light be demonstrate with vacuum and squeeze state of light . the sensitivity of the mapping procedure at the level of approximately 1 photon/sec per hz be show . the result pave the road towards complete -LRB- store both quadrature phase observable -RRB- quantum memory for gaussian state of light . the experiment also shed new light on fundamental limit of sensitivity of the magneto-optical resonance method,100,0.583333333
6843,Computers and IT,"Proposals for scalable quantum computing devices suffer not only from decoherence due to the interaction with their environment, but also from severe engineering constraints. Here we introduce a practical solution to these major concerns, addressing solid-state proposals in particular. Decoherence is first reduced by encoding a logical qubit into two qubits, then completely eliminated by an efficient set of decoupling pulse sequences. The same encoding removes the need for single-qubit operations, which pose a difficult design constraint. We further show how the dominant decoherence processes can be identified empirically, in order to optimize the decoupling pulses","proposal for scalable quantum computing device suffer not only from decoherence due to the interaction with their environment , but also from severe engineering constraint . here we introduce a practical solution to these major concern , address solid-state proposal in particular . decoherence be first reduce by encode a logical qubit into two qubit , then completely eliminate by an efficient set of decouple pulse sequence . the same encode remove the need for single-qubit operation , which pose a difficult design constraint . we far show how the dominant decoherence process can be identify empirically , in order to optimize the decouple pulse",96,0.375
6844,Computers and IT,"In the marketing model of Solomon and Weisbuch, people buy a product only if their neighbours tell them of its quality, and if this quality is higher than their own quality expectations. Now we introduce additional information from the mass media, which is analogous to the ghost field in percolation theory. The mass media shift the percolative phase transition observed in the model, and decrease the time after which the stationary state is reached","in the marketing model of solomon and weisbuch , people buy a product only if their neighbor tell them of its quality , and if this quality be high than their own quality expectation . now we introduce additional information from the mass medium , which be analogous to the ghost field in percolation theory . the mass medium shift the percolative phase transition observe in the model , and decrease the time after which the stationary state be reach",74,0.4
6845,Computers and IT,"A major issue in financial economics is the behavior of asset returns over long horizons. Various estimators of long-range dependence have been proposed. Even though some have known asymptotic properties, it is important to test their accuracy by using simulated series of different lengths. We test R/S analysis, detrended fluctuation analysis and periodogram regression methods on samples drawn from Gaussian white noise. The DFA statistics turns out to be the unanimous winner. Unfortunately, no asymptotic distribution theory has been derived for this statistics so far. We were able, however, to construct empirical (i. e. approximate) confidence intervals for all three methods. The obtained values differ largely from heuristic values proposed by some authors for the R/S statistics and are very close to asymptotic values for the periodogram regression method","a major issue in financial economics be the behavior of asset return over long horizon . various estimator of long-range dependence have be propose . even though some have know asymptotic property , it be important to test their accuracy by use simulated series of different length . we test r/ analysis , detrend fluctuation analysis and periodogram regression method on sample draw from gaussian white noise . the dfa statistic turn out to be the unanimous winner . unfortunately , no asymptotic distribution theory have be derive for this statistic so far . we be able , however , to construct empirical -LRB- i. e. approximate -RRB- confidence interval for all three method . the obtain value differ largely from heuristic value propose by some author for the r/ statistic and be very close to asymptotic value for the periodogram regression method",129,0.909090909
6846,Computers and IT,"We present simulations of evacuation processes using a recently introduced cellular automaton model for pedestrian dynamics. This model applies a bionics approach to describe the interaction between the pedestrians using ideas from chemotaxis. Here we study a rather simple situation, namely the evacuation from a large room with one or two doors. It is shown that the variation of the model parameters allows to describe different types of behaviour, from regular to panic. We find a non-monotonic dependence of the evacuation times on the coupling constants. These times depend on the strength of the herding behaviour, with minimal evacuation times for some intermediate values of the couplings, i. e. , a proper combination of herding and use of knowledge about the shortest way to the exit","we present simulation of evacuation process use a recently introduce cellular automaton model for pedestrian dynamic . this model apply a bionics approach to describe the interaction between the pedestrian use idea from chemotaxis . here we study a rather simple situation , namely the evacuation from a large room with one or two door . it be show that the variation of the model parameter allow to describe different type of behavior , from regular to panic . we find a non-monotonic dependence of the evacuation time on the coupling constant . these time depend on the strength of the herding behavior , with minimal evacuation time for some intermediate value of the coupling , i. e. , a proper combination of herding and use of knowledge about the short way to the exit",126,0.428571429
6847,Computers and IT,We study the dynamical behavior of a recurrent bus on a circular route with many bus stops when the recurrent bus passes some bus stops without stopping. The recurrent time (one period) is described in terms of a nonlinear map. It is shown that the recurrent bus exhibits the complex periodic behaviors. The dynamical transitions to periodic motions occur by increasing nonstops. The periodic motions depend on the property of an attractor of the nonlinear map. The period n of the attractor varies sensitively with the number of nonstops,we study the dynamical behavior of a recurrent bus on a circular route with many bus stop when the recurrent bus pass some bus stop without stop . the recurrent time -LRB- one period -RRB- be describe in term of a nonlinear map . it be show that the recurrent bus exhibit the complex periodic behavior . the dynamical transition to periodic motion occur by increase nonstop . the periodic motion depend on the property of an attractor of the nonlinear map . the period n of the attractor vary sensitively with the number of nonstop,89,1
6848,Computers and IT,"In Penna's (1995) single-species asexual bit-string model of biological ageing, the Verhulst factor has too strong a restraining effect on the development of the population. Danuta Makowiec gave an improved model based on the lattice, where the restraining factor of the four neighbours take the place of the Verhulst factor. Here, we discuss the two populations' Penna model with predation on the planar lattice of two dimensions. A cellular automata model containing movable wolves and sheep has been built. The results show that both the quantity of the wolves and the sheep fluctuate in accordance with the law that one quantity increases while the other one decreases","in penna 's -LRB- 1995 -RRB- single-specie asexual bit-string model of biological ageing , the verhulst factor have too strong a restrain effect on the development of the population . danuta makowiec give an improve model base on the lattice , where the restrain factor of the four neighbor take the place of the verhulst factor . here , we discuss the two population ' penna model with predation on the planar lattice of two dimension . a cellular automaton model contain movable wolf and sheep have be build . the result show that both the quantity of the wolf and the sheep fluctuate in accordance with the law that one quantity increase while the other one decrease",107,0.846153846
6849,Computers and IT,"Within a path integral formalism for non-Gaussian price fluctuations, we set up a simple stochastic calculus and derive a natural martingale for option pricing from the wealth balance of options, stocks, and bonds. The resulting formula is evaluated for truncated Levy distributions","within a path integral formalism for non-gaussian price fluctuation , we set up a simple stochastic calculus and derive a natural martingale for option pricing from the wealth balance of option , stock , and bond . the result formula be evaluate for truncate levy distribution",42,0.875
6850,Computers and IT,We propose a quantum-like description of markets and economics. The approach has roots in the recently developed quantum game theory,we propose a quantum-like description of market and economics . the approach have root in the recently develop quantum game theory,20,0.4
6851,Computers and IT,"Non-specialist librarians are alerted to factors important in the successful acquisition of out-of-print music, both scholarly editions and performance editions. The appropriate technical music vocabulary, the music publishing industry, specialized publishers and vendors, and methods of acquisition of out-of-print printed music are introduced, and the need for familiarity with them is emphasized","non-specialist librarian be alert to factor important in the successful acquisition of out-of-print music , both scholarly edition and performance edition . the appropriate technical music vocabulary , the music publishing industry , specialize publisher and vendor , and method of acquisition of out-of-print print music be introduce , and the need for familiarity with them be emphasize",52,0.875
6852,Computers and IT,"We analyze the exit dynamics of pedestrians who are initially confined in a room. Pedestrians are modeled as cellular automata and compete to escape via a known exit at the soonest possible time. A pedestrian could move forward, backward, left or right within each iteration time depending on adjacent cell vacancy and in accordance with simple rules that determine the compulsion to move and physical capability relative to his neighbors. The arching signatures of jamming were observed and the pedestrians exited in bursts of various sizes. Power-law behavior is found in the burst-size frequency distribution for exit widths w greater than one cell dimension (w 1). The slope of the power-law curve varies with w from -1. 3092 (w = 2) to -1. 0720 (w = 20). Streaming which is a diffusive behavior, arises in large burst sizes and is more likely in a single-exit room with w = 1 and leads to a counterintuitive result wherein an average exit throughput Q is obtained that is higher than with w = 2, 3, or 4. For a two-exit room (w = 1), Q is not greater than twice the yield of a single-exit room. If the doors are not separated far enough ( 4w), Q becomes even significantly less due to a collective slow-down that emerges among pedestrians crossing in each other's path (disruptive interference effect). For the same w and door number, Q is also higher with relaxed pedestrians than with anxious ones","we analyze the exit dynamic of pedestrian who be initially confine in a room . pedestrian be model as cellular automaton and compete to escape via a known exit at the soon possible time . a pedestrian could move forward , backward , leave or right within each iteration time depend on adjacent cell vacancy and in accordance with simple rule that determine the compulsion to move and physical capability relative to his neighbor . the arching signature of jam be observe and the pedestrian exit in burst of various size . power-law behavior be find in the burst-size frequency distribution for exit width w great than one cell dimension -LRB- w 1 -RRB- . the slope of the power-law curve vary with w from -1 . 3092 -LRB- w = 2 -RRB- to -1 . 0720 -LRB- w = 20 -RRB- . stream which be a diffusive behavior , arise in large burst size and be more likely in a single-exit room with w = 1 and lead to a counterintuitive result wherein an average exit throughput q be obtain that be high than with w = 2 , 3 , or 4 . for a two-exit room -LRB- w = 1 -RRB- , q be not great than twice the yield of a single-exit room . if the door be not separate far enough -LRB- 4w -RRB- , q become even significantly less due to a collective slow-down that emerge among pedestrian cross in each other 's path -LRB- disruptive interference effect -RRB- . for the same w and door number , q be also high with relax pedestrian than with anxious one",244,0.769230769
6853,Computers and IT,"We study the effects of tollbooths on the traffic flow. The highway traffic is simulated by the Nagel-Schreckenberg model. Various types of toll collection are examined, which can be characterized either by a waiting time or a reduced speed. A first-order phase transition is observed. The phase separation results a saturated flow, which is observed as a plateau region in the fundamental diagram. The effects of lane expansion near the tollbooth are examined. The full capacity of a highway can be restored. The emergence of vehicle queuing is studied. Besides the numerical results, we also obtain analytical expressions for various quantities. The numerical simulations can be well described by the analytical formulas. We also discuss the influence on the travel time and its variance. The tollbooth increases the travel time but decreases its variance. The differences between long- and short-distance travelers are also discussed","we study the effect of tollbooth on the traffic flow . the highway traffic be simulated by the nagel-schreckenberg model . various type of toll collection be examine , which can be characterize either by a wait time or a reduced speed . a first-order phase transition be observe . the phase separation result a saturate flow , which be observe as a plateau region in the fundamental diagram . the effect of lane expansion near the tollbooth be examine . the full capacity of a highway can be restore . the emergence of vehicle queue be study . besides the numerical result , we also obtain analytical expression for various quantity . the numerical simulation can be well describe by the analytical formula . we also discuss the influence on the travel time and its variance . the tollbooth increase the travel time but decrease its variance . the difference between long - and short-distance traveler be also discuss",144,1
6854,Computers and IT,"We argue that the analysis of the so-called Bagsik Oscillator, recently published by Piotrowski and Sladkowski (2001), is erroneous due to: (1) the incorrect banking data used and (2) the application of statistical mechanism apparatus to processes that are totally deterministic","we argue that the analysis of the so-called bagsik oscillator , recently publish by piotrowski and sladkowski -LRB- 2001 -RRB- , be erroneous due to : -LRB- 1 -RRB- the incorrect banking data use and -LRB- 2 -RRB- the application of statistical mechanism apparatus to process that be totally deterministic",41,0.5
6855,Computers and IT,"Recent evidence suggests that a power-law relationship exists between a firm's size and the variance of its growth rate. The flatness of the relation is regarded as puzzling, in that it suggests that large firms are not much more stable than small firms. It has been suggested that the powerlaw nature of the relationship reflects the presence of some form of correlation of growth rates across the firm's constituent businesses. Here, it is shown that a model of independent businesses which allows for the fact that these businesses vary in size, as modelled by a simple 'partitions of integers' model, provides a good representation of what is observed empirically","recent evidence suggest that a power-law relationship exist between a firm 's size and the variance of its growth rate . the flatness of the relation be regard as puzzling , in that it suggest that large firm be not much more stable than small firm . it have be suggest that the powerlaw nature of the relationship reflect the presence of some form of correlation of growth rate across the firm 's constituent business . here , it be show that a model of independent business which allow for the fact that these business vary in size , as model by a simple ` partition of integer ' model , provide a good representation of what be observe empirically",109,0.444444444
6856,Computers and IT,"A quantitative check of efficiency in US dollar/Deutsche mark exchange rates is developed using high-frequency (tick by tick) data. The antipersistent Markov behavior of log-price fluctuations of given size implies, in principle, the possibility of a statistical forecast. We introduce and measure the available information of the quote sequence, and we show how it can be profitable following a particular trading rule","a quantitative check of efficiency in us dollar/deutsche mark exchange rate be develop use high-frequency -LRB- tick by tick -RRB- data . the antipersistent markov behavior of log-price fluctuation of give size imply , in principle , the possibility of a statistical forecast . we introduce and measure the available information of the quote sequence , and we show how it can be profitable follow a particular trading rule",62,0.692307692
6857,Computers and IT,"We elucidate on several empirical statistical observations of stock market returns. Moreover, we find that these properties are recurrent and are also present in invariant measures of low-dimensional dynamical systems. Thus, we propose that the returns are modeled by the first Poincare return time of a low-dimensional chaotic trajectory. This modeling, which captures the recurrent properties of the return fluctuations, is able to predict well the evolution of the observed statistical quantities. In addition, it explains the reason for which stocks present simultaneously dynamical properties and high uncertainties. In our analysis, we use data from the S&P 500 index and the Brazilian stock Telebras","we elucidate on several empirical statistical observation of stock market return . moreover , we find that these property be recurrent and be also present in invariant measure of low-dimensional dynamical system . thus , we propose that the return be model by the first poincare return time of a low-dimensional chaotic trajectory . this modeling , which capture the recurrent property of the return fluctuation , be able to predict well the evolution of the observed statistical quantity . in addition , it explain the reason for which stock present simultaneously dynamical property and high uncertainty . in our analysis , we use data from the s & p 500 index and the brazilian stock telebra",104,0.888888889
6858,Computers and IT,"In this work we have applied nonlinear time series analysis to high-frequency currency exchange data. The time series studied are the exchange rates between the US Dollar and 18 other foreign currencies from within and without the Euro zone. Our goal was to determine if their dynamical behaviours were in some way correlated. The nonexistence of stationarity called for the application of recurrence quantification analysis as a tool for this analysis, and is based on the definition of several parameters that allow for the quantification of recurrence plots. The method was checked using the European Monetary System currency exchanges. The results show, as expected, the high correlation between the currencies that are part of the Euro, but also a strong correlation between the Japanese Yen, the Canadian Dollar and the British Pound. Singularities of the series are also demonstrated taking into account historical events, in 1996, in the Euro zone","in this work we have apply nonlinear time series analysis to high-frequency currency exchange data . the time series study be the exchange rate between the us dollar and 18 other foreign currency from within and without the euro zone . our goal be to determine if their dynamical behavior be in some way correlate . the nonexistence of stationarity call for the application of recurrence quantification analysis as a tool for this analysis , and be base on the definition of several parameter that allow for the quantification of recurrence plot . the method be check use the european monetary system currency exchange . the result show , as expect , the high correlation between the currency that be part of the euro , but also a strong correlation between the japanese yen , the canadian dollar and the british pound . singularity of the series be also demonstrate take into account historical event , in 1996 , in the euro zone",150,0.875
6859,Computers and IT,"Using singular spectrum analysis (SSA), we model the realized volatility and logarithmic standard deviations of two important futures return series. The realized volatility and logarithmic standard deviations are constructed following the methodology of Andersen et al. [J. Am. Stat. Ass. 96 (2001) 42-55] using intra-day transaction data. We find that SSA decomposes the volatility series quite well and effectively captures both the market trend (accounting for about 34-38% of the total variance in the series) and, more importantly, a number of underlying market periodicities. Reliable identification of any periodicities is extremely important for options pricing and risk management and we believe that SSA can be a useful addition to the financial practitioners' toolbox","use singular spectrum analysis -LRB- ssa -RRB- , we model the realize volatility and logarithmic standard deviation of two important future return series . the realize volatility and logarithmic standard deviation be construct follow the methodology of andersen et al. -LRB- j. be . stat . ass . 96 -LRB- 2001 -RRB- 42-55 -RRB- use intra-day transaction data . we find that ssa decompose the volatility series quite well and effectively capture both the market trend -LRB- accounting for about 34-38 % of the total variance in the series -RRB- and , more importantly , a number of underlie market periodicity . reliable identification of any periodicity be extremely important for option pricing and risk management and we believe that ssa can be a useful addition to the financial practitioner ' toolbox",113,0.692307692
6860,Computers and IT,"In a recent experiment [Phys. Rev. Lett. 88 (2002) 023601], phase-dependent photon statistics in a c. w. system has been observed in the mixing of a coherent field with a two-photon source. Their system has the advantage over other atomic transition-based fluorescent systems. In this paper, we examine further the squeezing properties of higher-order quantum fluctuations in one of the quadrature components of the combined field in this system. We demonstrate that efficient and lasting higher-order squeezing effects could be observed with proper choice of the relative phase between the pump and coherent fields. This nonclassical feature is attributed to a constructive two-photon interference. Relationship between the second- and higher-order squeezing of the field is discussed","in a recent experiment -LRB- phy . rev. lett . 88 -LRB- 2002 -RRB- 023601 -RRB- , phase-dependent photon statistic in a c. w. system have be observe in the mixing of a coherent field with a two-photon source . their system have the advantage over other atomic transition-based fluorescent system . in this paper , we examine far the squeeze property of higher-order quantum fluctuation in one of the quadrature component of the combined field in this system . we demonstrate that efficient and lasting higher-order squeeze effect could be observe with proper choice of the relative phase between the pump and coherent field . this nonclassical feature be attribute to a constructive two-photon interference . relationship between the second - and higher-ord squeeze of the field be discuss",116,0.625
6861,Computers and IT,"In this study, we present a systematic self-consistent multiclass multilane traffic model derived from the vehicular Boltzmann equation and the traffic dispersion model. The multilane domain is considered as a two-dimensional space and the interaction among vehicles in the domain is described by a dispersion model. The reason we consider a multilane domain as a two-dimensional space is that the driving behavior of road users may not be restricted by lanes, especially motorcyclists. The dispersion model, which is a nonlinear Poisson equation, is derived from the car-following theory and the equilibrium assumption. Under the concept that all kinds of users share the finite section, the density is distributed on a road by the dispersion model. In addition, the dynamic evolution of the traffic flow is determined by the systematic gas-kinetic model derived from the Boltzmann equation. Multiplying Boltzmann equation by the zeroth, first- and second-order moment functions, integrating both side of the equation and using chain rules, we can derive continuity, motion and variance equation, respectively. However, the second-order moment function, which is the square of the individual velocity, is employed by previous researches does not have physical meaning in traffic flow","in this study , we present a systematic self-consistent multiclas multilane traffic model derive from the vehicular boltzmann equation and the traffic dispersion model . the multilane domain be consider as a two-dimensional space and the interaction among vehicle in the domain be describe by a dispersion model . the reason we consider a multilane domain as a two-dimensional space be that the drive behavior of road user may not be restrict by lane , especially motorcyclist . the dispersion model , which be a nonlinear poisson equation , be derive from the car-following theory and the equilibrium assumption . under the concept that all kind of user share the finite section , the density be distribute on a road by the dispersion model . in addition , the dynamic evolution of the traffic flow be determine by the systematic gas-kinetic model derive from the boltzmann equation . multiply boltzmann equation by the zeroth , first - and second-ord moment function , integrate both side of the equation and use chain rule , we can derive continuity , motion and variance equation , respectively . however , the second-ord moment function , which be the square of the individual velocity , be employ by previous research do not have physical meaning in traffic flow",192,0.818181818
6862,Computers and IT,"A simple associationist neural network learns to factor abstract rules (i. e. , grammars) from sequences of arbitrary input symbols by inventing abstract representations that accommodate unseen symbol sets as well as unseen but similar grammars. The neural network is shown to have the ability to transfer grammatical knowledge to both new symbol vocabularies and new grammars. Analysis of the state-space shows that the network learns generalized abstract structures of the input and is not simply memorizing the input strings. These representations are context sensitive, hierarchical, and based on the state variable of the finite-state machines that the neural network has learned. Generalization to new symbol sets or grammars arises from the spatial nature of the internal representations used by the network, allowing new symbol sets to be encoded close to symbol sets that have already been learned in the hidden unit space of the network. The results are counter to the arguments that learning algorithms based on weight adaptation after each exemplar presentation (such as the long term potentiation found in the mammalian nervous system) cannot in principle extract symbolic knowledge from positive examples as prescribed by prevailing human linguistic theory and evolutionary psychology","a simple associationist neural network learn to factor abstract rule -LRB- i. e. , grammar -RRB- from sequence of arbitrary input symbol by invent abstract representation that accommodate unseen symbol set as well as unseen but similar grammar . the neural network be show to have the ability to transfer grammatical knowledge to both new symbol vocabulary and new grammar . analysis of the state-space show that the network learn generalize abstract structure of the input and be not simply memorize the input string . these representation be context sensitive , hierarchical , and base on the state variable of the finite-state machine that the neural network have learn . generalization to new symbol set or grammar arise from the spatial nature of the internal representation use by the network , allow new symbol set to be encode close to symbol set that have already be learn in the hidden unit space of the network . the result be counter to the argument that learn algorithm base on weight adaptation after each exemplar presentation -LRB- such as the long term potentiation find in the mammalian nervous system -RRB- can not in principle extract symbolic knowledge from positive example as prescribe by prevail human linguistic theory and evolutionary psychology",195,0.75
6863,Computers and IT,"A number of global companies have adopted electronic commerce as a means of reducing transaction related expenditures, connecting with current and potential customers, and enhancing revenues and profitability. If a restaurant is to have an Internet presence, what aspects of the business should be highlighted? Food service companies that have successfully ventured onto the web have employed assorted web-based technologies to create a powerful marketing tool of unparalleled strength. Historically, it has been difficult to create a set of criteria against which to evaluate website effectiveness. As practitioners consider additional resources for website development, the effectiveness of e-marketing investment becomes increasingly important. Care must be exercised to ensure that the quality of the site adheres to high standards and incorporates evolving technology, as appropriate. Developing a coherent website strategy, including an effective website design, are proving critical to an effective web presence","a number of global company have adopt electronic commerce as a mean of reduce transaction relate expenditure , connect with current and potential customer , and enhance revenue and profitability . if a restaurant be to have an internet presence , what aspect of the business should be highlight ? food service company that have successfully venture onto the web have employ assorted web-based technology to create a powerful marketing tool of unparalleled strength . historically , it have be difficult to create a set of criterion against which to evaluate website effectiveness . as practitioner consider additional resource for website development , the effectiveness of e-marketing investment become increasingly important . care must be exercise to ensure that the quality of the site adhere to high standard and incorporate evolve technology , as appropriate . develop a coherent website strategy , include an effective website design , be prove critical to an effective web presence",142,0.857142857
6864,Computers and IT,"This paper provides a content analysis study of the application of World Wide Web marketing by the hotel industry. There is a lack of historical perspective on industry related Web marketing applications and this paper attempts to resolve this with a two-year follow-up case study of the changing use of the Web to develop different types of relationships. Specifically, the aims are: (1) to identify key changes in the way hotels are using the Web; (2) to look for evidence of the adoption of a relationship marketing (RM) model as a strategy for the development of hotel Web sites and the use of new technologies; and, (3) To investigate the use of multimedia in hotel Web sites. The development and strategic exploitation of the Internet has transformed the basis of marketing. Using the evidence from a Web content survey this study reveals the way relationships are being created and managed within the hotel industry by its use of the Web as a marketing tool. The authors have collected evidence by means of a descriptive study on the way hotels build and create relationships with their Web presence delivering multimedia information as well as channel and interactive means of communication. In addition a strategic framework is offered as the means to describe the mechanism and orientation of Web based marketing by hotels. The study utilizes a model by Gilbert (1996) as a means of developing a measurement instrument to allow a content analysis of the current approach by hotels to the development of Web sites. The results indicate hotels are aware of the new uses of Web technology and are promoting hotel products in the global electronic market in new and sophisticated ways","this paper provide a content analysis study of the application of world wide web marketing by the hotel industry . there be a lack of historical perspective on industry relate web marketing application and this paper attempt to resolve this with a two-year follow-up case study of the change use of the web to develop different type of relationship . specifically , the aim be : -LRB- 1 -RRB- to identify key change in the way hotel be use the web ; -LRB- 2 -RRB- to look for evidence of the adoption of a relationship marketing -LRB- rm -RRB- model as a strategy for the development of hotel web site and the use of new technology ; and , -LRB- 3 -RRB- to investigate the use of multimedia in hotel web site . the development and strategic exploitation of the internet have transform the basis of marketing . use the evidence from a web content survey this study reveal the way relationship be be create and manage within the hotel industry by its use of the web as a marketing tool . the author have collect evidence by mean of a descriptive study on the way hotel build and create relationship with their web presence deliver multimedia information as well as channel and interactive mean of communication . in addition a strategic framework be offer as the mean to describe the mechanism and orientation of web base marketing by hotel . the study utilize a model by gilbert -LRB- 1996 -RRB- as a mean of develop a measurement instrument to allow a content analysis of the current approach by hotel to the development of web site . the result indicate hotel be aware of the new us of web technology and be promote hotel product in the global electronic market in new and sophisticated way",282,0.857142857
6865,Computers and IT,"The traditional channels of distribution for overnight accommodation are rapidly being displaced by Web site scripting, online intermediaries, and specialty brokers. Businesses that pioneered Internet usage relied on it as a sales and marketing alternative to predecessor product distribution channels. As such, Web sites replace the traditional trading model to the Internet. Web-enabled companies are popular because the medium renders the process faster, less costly, highly reliable, and secure. Auction-based models impact business models by converting the price setting mechanism from supplier-centric to market-centric and transforming the trading model from ""one to many"" to ""many to many. "" Historically, pricing was based on the cost of production plus a margin of profit. Traditionally, as products and services move through the supply chain, from the producer to the consumer, various intermediaries added their share of profit to the price. As Internet based mediums of distribution become more prevalent, traditional pricing models are being supplanted with dynamic pricing. A dynamic pricing model represents a flexible system that changes prices not only from product to product, but also from customer to customer and transaction to transaction. Many industry leaders are skeptical of the long run impact of online auctions on lodging industry profit margins, despite the fact pricing theory suggests that an increase in the flow of information results in efficient market pricing. The future of such endeavors remains promising, but controversial","the traditional channel of distribution for overnight accommodation be rapidly be displace by web site scripting , online intermediary , and specialty broker . business that pioneer internet usage rely on it as a sale and marketing alternative to predecessor product distribution channel . as such , web site replace the traditional trading model to the internet . web-enabled company be popular because the medium render the process faster , less costly , highly reliable , and secure . auction-based model impact business model by convert the price set mechanism from supplier-centric to market-centric and transform the trading model from `` one to many '' to `` many to many . '' historically , pricing be base on the cost of production plus a margin of profit . traditionally , as product and service move through the supply chain , from the producer to the consumer , various intermediary add their share of profit to the price . as internet base medium of distribution become more prevalent , traditional pricing model be be supplant with dynamic pricing . a dynamic pricing model represent a flexible system that change price not only from product to product , but also from customer to customer and transaction to transaction . many industry leader be skeptical of the long run impact of online auction on lodge industry profit margin , despite the fact pricing theory suggest that an increase in the flow of information result in efficient market pricing . the future of such endeavor remain promising , but controversial",229,0.928571429
6866,Computers and IT,"In this correspondence, we prove that the affine invariants, for image registration and object recognition, proposed recently by Yang and Cohen (see ibid. , vol. 8, no. 7, p. 934-46, July 1999) are algebraically dependent. We show how to select an independent and complete set of the invariants. The use of this new set leads to a significant reduction of the computing complexity without decreasing the discrimination power","in this correspondence , we prove that the affine invariant , for image registration and object recognition , propose recently by yang and cohen -LRB- see ibid . , vol . 8 , no. 7 , p. 934-46 , july 1999 -RRB- be algebraically dependent . we show how to select an independent and complete set of the invariant . the use of this new set lead to a significant reduction of the computing complexity without decrease the discrimination power",68,0.375
6867,Computers and IT,"Among all algorithms based on wavelet transform and zerotree quantization, Said and Pearlman's (1996) set partitioning in hierarchical trees (SPIHT) algorithm is well-known for its simplicity and efficiency. This paper deals with the real-time implementation of SPIHT algorithm using DSP chip. In order to facilitate the implementation and improve the codec's performance, some relative issues are thoroughly discussed, such as the optimization of program structure to speed up the wavelet decomposition. SPIHT's high memory requirement is a major drawback for hardware implementation. In this paper, we modify the original SPIHT algorithm by presenting two new concepts-number of error bits and absolute zerotree. Consequently, the memory cost is significantly reduced. We also introduce a new method to control the coding process by number of error bits. Our experimental results show that the implementation meets common requirement of real-time video coding and is proven to be a practical and efficient DSP solution","among all algorithm base on wavelet transform and zerotree quantization , say and pearlman 's -LRB- 1996 -RRB- set partitioning in hierarchical tree -LRB- spiht -RRB- algorithm be well-known for its simplicity and efficiency . this paper deal with the real-time implementation of spiht algorithm use dsp chip . in order to facilitate the implementation and improve the codec 's performance , some relative issue be thoroughly discuss , such as the optimization of program structure to speed up the wavelet decomposition . spiht 's high memory requirement be a major drawback for hardware implementation . in this paper , we modify the original spiht algorithm by present two new concepts-number of error bit and absolute zerotree . consequently , the memory cost be significantly reduce . we also introduce a new method to control the coding process by number of error bit . our experimental result show that the implementation meet common requirement of real-time video coding and be prove to be a practical and efficient dsp solution",150,0.916666667
6868,Computers and IT,"Local moments have attracted attention as local features in applications such as edge detection and texture segmentation. The main reason for this is that they are inherently integral-based features, so that their use reduces the effect of uncorrelated noise. The computation of local moments, when viewed as a neighborhood operation, can be interpreted as a convolution of the image with a set of masks. Nevertheless, moments computed inside overlapping windows are not independent and convolution does not take this fact into account. By introducing a matrix formulation and the concept of accumulation moments, this paper presents an algorithm which is computationally much more efficient than convolving and yet as simple","local moment have attract attention as local feature in application such as edge detection and texture segmentation . the main reason for this be that they be inherently integral-based feature , so that their use reduce the effect of uncorrelated noise . the computation of local moment , when view as a neighborhood operation , can be interpret as a convolution of the image with a set of mask . nevertheless , moment compute inside overlap window be not independent and convolution do not take this fact into account . by introduce a matrix formulation and the concept of accumulation moment , this paper present an algorithm which be computationally much more efficient than convolve and yet as simple",110,0.666666667
6869,Computers and IT,"This paper proposes a new method for image denoising with edge preservation, based on image multiresolution decomposition by a redundant wavelet transform. In our approach, edges are implicitly located and preserved in the wavelet domain, whilst image noise is filtered out. At each resolution level, the image edges are estimated by gradient magnitudes (obtained from the wavelet coefficients), which are modeled probabilistically, and a shrinkage function is assembled based on the model obtained. Joint use of space and scale consistency is applied for better preservation of edges. The shrinkage functions are combined to preserve edges that appear simultaneously at several resolutions, and geometric constraints are applied to preserve edges that are not isolated. The proposed technique produces a filtered version of the original image, where homogeneous regions appear separated by well-defined edges. Possible applications include image presegmentation, and image denoising","this paper propose a new method for image denois with edge preservation , base on image multiresolution decomposition by a redundant wavelet transform . in our approach , edge be implicitly locate and preserve in the wavelet domain , whilst image noise be filter out . at each resolution level , the image edge be estimate by gradient magnitude -LRB- obtain from the wavelet coefficient -RRB- , which be model probabilistically , and a shrinkage function be assemble base on the model obtain . joint use of space and scale consistency be apply for better preservation of edge . the shrinkage function be combine to preserve edge that appear simultaneously at several resolution , and geometric constraint be apply to preserve edge that be not isolate . the propose technique produce a filter version of the original image , where homogeneous region appear separate by well-defined edge . possible application include image presegmentation , and image denoising",140,0.727272727
6870,Computers and IT,"We propose a new method for contour tracking in video. The inverted distance transform of the edge map is used as an edge indicator function for contour detection. Using the concept of topographical distance, the watershed segmentation can be formulated as a minimization. This new viewpoint gives a way to combine the results of the watershed algorithm on different surfaces. In particular, our algorithm determines the contour as a combination of the current edge map and the contour, predicted from the tracking result in the previous frame. We also show that the problem of background clutter can be relaxed by taking the object motion into account. The compensation with object motion allows to detect and remove spurious edges in background. The experimental results confirm the expected advantages of the proposed method over the existing approaches","we propose a new method for contor tracking in video . the inverted distance transform of the edge map be use as an edge indicator function for contor detection . use the concept of topographical distance , the watershed segmentation can be formulate as a minimization . this new viewpoint give a way to combine the result of the watershed algorithm on different surface . in particular , our algorithm determine the contor as a combination of the current edge map and the contor , predict from the tracking result in the previous frame . we also show that the problem of background clutter can be relax by take the object motion into account . the compensation with object motion allow to detect and remove spurious edge in background . the experimental result confirm the expect advantage of the propose method over the exist approach",135,0.714285714
6871,Computers and IT,"The main contribution of this work is a new paradigm for image representation and image compression. We describe a new multilayered representation technique for images. An image is parsed into a superposition of coherent layers: piecewise smooth regions layer, textures layer, etc. The multilayered decomposition algorithm consists in a cascade of compressions applied successively to the image itself and to the residuals that resulted from the previous compressions. During each iteration of the algorithm, we code the residual part in a lossy way: we only retain the most significant structures of the residual part, which results in a sparse representation. Each layer is encoded independently with a different transform, or basis, at a different bitrate, and the combination of the compressed layers can always be reconstructed in a meaningful way. The strength of the multilayer approach comes from the fact that different sets of basis functions complement each others: some of the basis functions will give reasonable account of the large trend of the data, while others will catch the local transients, or the oscillatory patterns. This multilayered representation has a lot of beautiful applications in image understanding, and image and video coding. We have implemented the algorithm and we have studied its capabilities","the main contribution of this work be a new paradigm for image representation and image compression . we describe a new multilayered representation technique for image . an image be parse into a superposition of coherent layer : piecewise smooth region layer , textur layer , etc. the multilayered decomposition algorithm consist in a cascade of compression apply successively to the image itself and to the residual that result from the previous compression . during each iteration of the algorithm , we code the residual part in a lossy way : we only retain the most significant structure of the residual part , which result in a sparse representation . each layer be encode independently with a different transform , or basis , at a different bitrate , and the combination of the compress layer can always be reconstruct in a meaningful way . the strength of the multilay approach come from the fact that different set of basis function complement each other : some of the basis function will give reasonable account of the large trend of the data , while other will catch the local transient , or the oscillatory pattern . this multilayered representation have a lot of beautiful application in image understanding , and image and video coding . we have implement the algorithm and we have study its capability",204,0.666666667
6872,Computers and IT,"New methods for detecting edges in an image using spatial and scale-space domains are proposed. A priori knowledge about geometrical characteristics of edges is used to assign a probability factor to the chance of any pixel being on an edge. An improved double thresholding technique is introduced for spatial domain filtering. Probabilities that pixels belong to a given edge are assigned based on pixel similarity across gradient amplitudes, gradient phases and edge connectivity. The scale-space approach uses dynamic range compression to allow wavelet correlation over a wider range of scales. A probabilistic formulation is used to combine the results obtained from filtering in each domain to provide a final edge probability image which has the advantages of both spatial and scale-space domain methods. Decomposing this edge probability image with the same wavelet as the original image permits the generation of adaptive filters that can recognize the characteristics of the edges in all wavelet detail and approximation images regardless of scale. These matched filters permit significant reduction in image noise without contributing to edge distortion. The spatially adaptive wavelet noise-filtering algorithm is qualitatively and quantitatively compared to a frequency domain and two wavelet based noise suppression algorithms using both natural and computer generated noisy images","new method for detect edge in an image use spatial and scale-space domain be propose . a priori knowledge about geometrical characteristic of edge be use to assign a probability factor to the chance of any pixel be on an edge . an improved double thresholding technique be introduce for spatial domain filter . probability that pixel belong to a give edge be assign base on pixel similarity across gradient amplitude , gradient phase and edge connectivity . the scale-space approach use dynamic range compression to allow wavelet correlation over a wide range of scale . a probabilistic formulation be use to combine the result obtain from filter in each domain to provide a final edge probability image which have the advantage of both spatial and scale-space domain method . decompose this edge probability image with the same wavelet as the original image permit the generation of adaptive filter that can recognize the characteristic of the edge in all wavelet detail and approximation image regardless of scale . these match filter permit significant reduction in image noise without contribute to edge distortion . the spatially adaptive wavelet noise-filtering algorithm be qualitatively and quantitatively compare to a frequency domain and two wavelet base noise suppression algorithm use both natural and computer generate noisy image",204,0.826086957
6873,Computers and IT,"A three-level hierarchical mixture model for classification is presented that models the following data generation process: (1) the data are generated by a finite number of sources (clusters), and (2) the generation mechanism of each source assumes the existence of individual internal class-labeled sources (subclusters of the external cluster). The model estimates the posterior probability of class membership similar to a mixture of experts classifier. In order to learn the parameters of the model, we have developed a general training approach based on maximum likelihood that results in two efficient training algorithms. Compared to other classification mixture models, the proposed hierarchical model exhibits several advantages and provides improved classification performance as indicated by the experimental results","a three-level hierarchical mixture model for classification be present that model the following data generation process : -LRB- 1 -RRB- the data be generate by a finite number of source -LRB- cluster -RRB- , and -LRB- 2 -RRB- the generation mechanism of each source assume the existence of individual internal class-labeled source -LRB- subcluster of the external cluster -RRB- . the model estimate the posterior probability of class membership similar to a mixture of expert classifier . in order to learn the parameter of the model , we have develop a general training approach base on maximum likelihood that result in two efficient training algorithm . compare to other classification mixture model , the propose hierarchical model exhibit several advantage and provide improve classification performance as indicate by the experimental result",116,0.833333333
6874,Computers and IT,"We propose a fully three-dimensional (3-D) object-based coding system exploiting the diagnostic relevance of the different regions of the volumetric data for rate allocation. The data are first decorrelated via a 3-D discrete wavelet transform. The implementation via the lifting steps scheme allows to map integer-to-integer values, enabling lossless coding, and facilitates the definition of the object-based inverse transform. The coding process assigns disjoint segments of the bitstream to the different objects, which can be independently accessed and reconstructed at any up-to-lossless quality. Two fully 3-D coding strategies are considered: embedded zerotree coding (EZW-3D) and multidimensional layered zero coding (MLZC), both generalized for region of interest (ROI)-based processing. In order to avoid artifacts along region boundaries, some extra coefficients must be encoded for each object. This gives rise to an overheading of the bitstream with respect to the case where the volume is encoded as a whole. The amount of such extra information depends on both the filter length and the decomposition depth. The system is characterized on a set of head magnetic resonance images. Results show that MLZC and EZW-3D have competitive performances. In particular, the best MLZC mode outperforms the others state-of-the-art techniques on one of the datasets for which results are available in the literature","we propose a fully three-dimensional -LRB- 3-d -RRB- object-based coding system exploit the diagnostic relevance of the different region of the volumetric data for rate allocation . the data be first decorrelated via a 3-d discrete wavelet transform . the implementation via the lifting step scheme allow to map integer-to-integ value , enable lossless coding , and facilitate the definition of the object-based inverse transform . the cod process assign disjoint segment of the bitstream to the different object , which can be independently access and reconstruct at any up-to-lossless quality . two fully 3-d cod strategy be consider : embed zerotree coding -LRB- ezw-3d -RRB- and multidimensional layered zero coding -LRB- mlzc -RRB- , both generalize for region of interest -LRB- roi -RRB- - base processing . in order to avoid artifact along region boundary , some extra coefficient must be encode for each object . this give rise to an overheading of the bitstream with respect to the case where the volume be encode as a whole . the amount of such extra information depend on both the filter length and the decomposition depth . the system be characterize on a set of head magnetic resonance image . result show that mlzc and ezw-3d have competitive performance . in particular , the best mlzc mode outperform the other state-of-the-art technique on one of the dataset for which result be available in the literature",208,0.636363636
6875,Computers and IT,"The most common method of improving stability of the power system is the synthesis of the turbine and generator control systems, because of the high effectiveness and relatively low cost of these elements. The synthesis and construction of the effective synchronous generator and turbine controller is a very difficult task. This paper describes the seven step mu -synthesis approach to PSS design enabling the synchronous generator to remain stable over a wide range of system operating conditions","the most common method of improve stability of the power system be the synthesis of the turbine and generator control system , because of the high effectiveness and relatively low cost of these element . the synthesis and construction of the effective synchronous generator and turbine controller be a very difficult task . this paper describe the seven step mu - synthesis approach to ps design enable the synchronous generator to remain stable over a wide range of system operating condition",77,0.4
6876,Computers and IT,"The authors describe RESFAL, a software tool that can check on the behavior of distribution network resonant grounding systems with regard to compensation coil tuning and to fault detection","the author describe resfal , a software tool that can check on the behavior of distribution network resonant ground system with regard to compensation coil tuning and to fault detection",29,0.333333333
6877,Computers and IT,"This article discusses some of the changes that have taken place in power systems and explores some of the inherent requirements for simulation technologies in order to keep up with this rapidly changing environment. The authors describe how energy utilities are realizing that, with the appropriate tools, they can train and sustain engineers who can maintain a great insight into system dynamics","this article discuss some of the change that have take place in power system and explore some of the inherent requirement for simulation technology in order to keep up with this rapidly change environment . the author describe how energy utility be realize that , with the appropriate tool , they can train and sustain engineer who can maintain a great insight into system dynamic",62,0.2
6878,Computers and IT,A major component of any power system simulation is the generating plant. The purpose of DeriveAssist is to speed up the parameter derivation process and to allow engineers less versed in parameter matching and identification to get involved in the process of power plant electric generator modelling,a major component of any power system simulation be the generate plant . the purpose of deriveassist be to speed up the parameter derivation process and to allow engineer less verse in parameter matching and identification to get involve in the process of power plant electric generator modelling,47,0.363636364
6879,Computers and IT,"The so-called ""deregulation"" and restructuring of the electric power industry have made it very difficult to keep up with industry changes and have made it much more difficult to envision the future. In this article, current key issues and major developments of the past few years are reviewed to provide perspective, and prospects for future computer applications in power are suggested. Technology changes are occurring at an exponential rate. The interconnected bulk electric systems are becoming integrated with vast networked information systems. This article discusses the skills that will be needed by future power engineers to keep pace with these developments and trends","the so-called `` deregulation '' and restructuring of the electric power industry have make it very difficult to keep up with industry change and have make it much more difficult to envision the future . in this article , current key issue and major development of the past few year be review to provide perspective , and prospect for future computer application in power be suggest . technology change be occur at an exponential rate . the interconnect bulk electric system be become integrate with vast networked information system . this article discuss the skill that will be need by future power engineer to keep pace with these development and trend",103,0.666666667
6880,Computers and IT,"Despite changes with different structures, market rules, and uncertainties, a control center must always be in place to maintain the security, reliability, and quality of electric service. This article focuses on the energy management system (EMS) control center, identifying the major functions that have become standard components of every application software package. The two most important control center functions, security control and load-following control, guarantee the continuity of electric service, which after all, is the end-product of the utility business. New technology trends in the design of control center infrastructures are emerging in the liberalized environment of the energy market. An example of a control center infrastructure is described. The article ends with a concern for the security of the control center itself","despite change with different structure , market rule , and uncertainty , a control center must always be in place to maintain the security , reliability , and quality of electric service . this article focus on the energy management system -LRB- ems -RRB- control center , identify the major function that have become standard component of every application software package . the two most important control center function , security control and load-following control , guarantee the continuity of electric service , which after all , be the end-product of the utility business . new technology trend in the design of control center infrastructure be emerge in the liberalize environment of the energy market . an example of a control center infrastructure be describe . the article end with a concern for the security of the control center itself",123,0.8
6881,Computers and IT,"We all appreciate the need for, and hopefully we have all deployed, anti-virus software. The good news is that AV software has come a long way fast. Four or so years ago it was true to write that AV software could not detect Trojan Horses and similar intrusion attempts. Now it can and does. McAfee's VirusScan, for example, goes one further; it detects viruses, worms and Trojan Horses and deploys itself as a firewall to filter data packets, control access to Internet resources, activate rule sets for specific applications, in general to protect against hackers. But like so much software, we use it with little thought as to how it came to do its job. Behind the scenes there is an army of top notch programmers trying to stay ahead of the baddies who, at the last count, had produced some 60, 000 viruses","we all appreciate the need for , and hopefully we have all deploy , anti-virus software . the good news be that av software have come a long way fast . four or so year ago it be true to write that av software could not detect trojan horse and similar intrusion attempt . now it can and do . mcafee 's virusscan , for example , go one further ; it detect virus , worm and trojan horse and deploy itself as a firewall to filter data packet , control access to internet resource , activate rule set for specific application , in general to protect against hacker . but like so much software , we use it with little thought as to how it come to do its job . behind the scene there be an army of top notch programmer try to stay ahead of the baddie who , at the last count , have produce some 60 , 000 virus",144,1
6882,Computers and IT,"Over the past few years, numerous organisations have invested in the latest software applications to drive their business forward. But many are now finding that these systems are becoming redundant on their own. The key to staying ahead of the competition in today's current climate is now to integrate all of these systems, says Justin Opie, Portfolio Director at Imark Communications","over the past few year , numerous organization have invest in the late software application to drive their business forward . but many be now find that these system be become redundant on their own . the key to stay ahead of the competition in today 's current climate be now to integrate all of these system , say justin opie , portfolio director at imark communication",61,0.5
6883,Computers and IT,"Companies are increasingly required to provide assurance that their systems are secure and conform to commercial security standards. Senior business managers are ultimately responsible for the security of their corporate systems and for the implications in the event of a failure. Businesses will be exposed to unquantified security risks unless they have a formal risk management framework in place to enable risks to be identified, evaluated and managed. Failure to assess and manage risks can lead to a business suffering serious financial impacts, commercial embarrassment and fines or sanctions from regulators. This is both a key responsibility and opportunity for Management Services Practitioners","company be increasingly require to provide assurance that their system be secure and conform to commercial security standard . senior business manager be ultimately responsible for the security of their corporate system and for the implication in the event of a failure . business will be expose to unquantified security risk unless they have a formal risk management framework in place to enable risk to be identify , evaluate and manage . failure to assess and manage risk can lead to a business suffer serious financial impact , commercial embarrassment and fine or sanction from regulator . this be both a key responsibility and opportunity for management service practitioner",103,0.666666667
6884,Computers and IT,"We introduce and study an artificial neural network inspired by the probabilistic receptor affinity distribution model of olfaction. Our system consists of N sensory neurons whose outputs converge on a single processing linear threshold element. The system's aim is to model discrimination of a single target odorant from a large number p of background odorants within a range of odorant concentrations. We show that this is possible provided p does not exceed a critical value p/sub c/ and calculate the critical capacity alpha c=p/sub c//N. The critical capacity depends on the range of concentrations in which the discrimination is to be accomplished. If the olfactory bulb may be thought of as a collection of such processing elements, each responsible for the discrimination of a single odorant, our study provides a quantitative analysis of the potential computational properties of the olfactory bulb. The mathematical formulation of the problem we consider is one of determining the capacity for linear separability of continuous curves, embedded in a large-dimensional space. This is accomplished here by a numerical study, using a method that signals whether the discrimination task is realizable, together with a finite-size scaling analysis","we introduce and study an artificial neural network inspire by the probabilistic receptor affinity distribution model of olfaction . our system consist of n sensory neuron whose output converge on a single processing linear threshold element . the system 's aim be to model discrimination of a single target odorant from a large number p of background odorant within a range of odorant concentration . we show that this be possible provide p do not exceed a critical value p/sub c / and calculate the critical capacity alpha c = p/sub c / / n. the critical capacity depend on the range of concentration in which the discrimination be to be accomplish . if the olfactory bulb may be think of as a collection of such processing element , each responsible for the discrimination of a single odorant , our study provide a quantitative analysis of the potential computational property of the olfactory bulb . the mathematical formulation of the problem we consider be one of determine the capacity for linear separability of continuous curve , embed in a large-dimensional space . this be accomplish here by a numerical study , use a method that signal whether the discrimination task be realizable , together with a finite-size scaling analysis",191,0.857142857
6885,Computers and IT,"To confront the advent of the advanced information society, there has been a pressing demand for the adjustment of the communications infrastructure and the structuring of the information network by utilizing the sewage conduits. The City of Tokyo is promoting a project by the name of the sewer optical fiber teleway (SOFT) network plan. According to this plan, the total distance of the optical fiber network laid in the sewer conduits is scheduled to reach about 470 km by the end of March 2000. At the final stage, this distance will reach 800 km as a whole. We completed the construction work for the information control facilities scattered in 11 places inclusive of the Treatment Site S, with the intention to adjust and extend the information transmission network laid through the above-mentioned optical fiber network, to be used exclusively by the Bureau of Sewerage. This construction work is described in the paper","to confront the advent of the advanced information society , there have be a press demand for the adjustment of the communication infrastructure and the structuring of the information network by utilize the sewage conduit . the city of tokyo be promote a project by the name of the sewer optical fiber teleway -LRB- soft -RRB- network plan . accord to this plan , the total distance of the optical fiber network lay in the sewer conduit be schedule to reach about 470 km by the end of march 2000 . at the final stage , this distance will reach 800 km as a whole . we complete the construction work for the information control facility scatter in 11 place inclusive of the treatment site  , with the intention to adjust and extend the information transmission network lay through the above-mentioned optical fiber network , to be use exclusively by the bureau of sewerage . this construction work be describe in the paper",152,0.583333333
6886,Computers and IT,"An information-theoretic model for image watermarking and data hiding is presented in this paper. Previous theoretical results are used to characterize the fundamental capacity limits of image watermarking and data-hiding systems. Capacity is determined by the statistical model used for the host image, by the distortion constraints on the data hider and the attacker, and by the information available to the data hider, to the attacker, and to the decoder. We consider autoregressive, block-DCT, and wavelet statistical models for images and compute data-hiding capacity for compressed and uncompressed host-image sources. Closed-form expressions are obtained under sparse-model approximations. Models for geometric attacks and distortion measures that are invariant to such attacks are considered","an information-theoretic model for image watermarking and data hiding be present in this paper . previous theoretical result be use to characterize the fundamental capacity limit of image watermarking and data-hiding system . capacity be determine by the statistical model use for the host image , by the distortion constraint on the data hider and the attacker , and by the information available to the data hider , to the attacker , and to the decoder . we consider autoregressive , block-dct , and wavelet statistical model for image and compute data-hiding capacity for compress and uncompressed host-image source . closed-form expression be obtain under sparse-model approximation . model for geometric attack and distortion measure that be invariant to such attack be consider",112,0.8125
6887,Computers and IT,"This paper presents a new approach for watermarking of digital images providing robustness to geometrical distortions. The weaknesses of classical watermarking methods to geometrical distortions are outlined first. Geometrical distortions can be decomposed into two classes: global transformations such as rotations and translations and local transformations such as the StirMark attack. An overview of existing self-synchronizing schemes is then presented. Theses schemes can use periodical properties of the mark, invariant properties of transforms, template insertion, or information provided by the original image to counter geometrical distortions. Thereafter, a new class of watermarking schemes using the image content is presented. We propose an embedding and detection scheme where the mark is bound with a content descriptor defined by salient points. Three different types of feature points are studied and their robustness to geometrical transformations is evaluated to develop an enhanced detector. The embedding of the signature is done by extracting feature points of the image and performing a Delaunay tessellation on the set of points. The mark is embedded using a classical additive scheme inside each triangle of the tessellation. The detection is done using correlation properties on the different triangles. The performance of the presented scheme is evaluated after JPEG compression, geometrical attack and transformations. Results show that the fact that the scheme is robust to these different manipulations. Finally, in our concluding remarks, we analyze the different perspectives of such content-based watermarking scheme","this paper present a new approach for watermarking of digital image provide robustness to geometrical distortion . the weakness of classical watermarking method to geometrical distortion be outline first . geometrical distortion can be decompose into two class : global transformation such as rotation and translation and local transformation such as the stirmark attack . an overview of exist self-synchronizing scheme be then present . thesis scheme can use periodical property of the mark , invariant property of transform , template insertion , or information provide by the original image to counter geometrical distortion . thereafter , a new class of watermark scheme use the image content be present . we propose an embedding and detection scheme where the mark be bind with a content descriptor define by salient point . three different type of feature point be study and their robustness to geometrical transformation be evaluate to develop an enhanced detector . the embedding of the signature be do by extract feature point of the image and perform a delaunay tessellation on the set of point . the mark be embed use a classical additive scheme inside each triangle of the tessellation . the detection be do use correlation property on the different triangle . the performance of the present scheme be evaluate after jpeg compression , geometrical attack and transformation . result show that the fact that the scheme be robust to these different manipulation . finally , in our conclude remark , we analyze the different perspective of such content-based watermarking scheme",234,0.875
6888,Computers and IT,"Most commercial digital cameras use color filter arrays to sample red, green, and blue colors according to a specific pattern. At the location of each pixel only one color sample is taken, and the values of the other colors must be interpolated using neighboring samples. This color plane interpolation is known as demosaicing; it is one of the important tasks in a digital camera pipeline. If demosaicing is not performed appropriately, images suffer from highly visible color artifacts. In this paper we present a new demosaicing technique that uses inter-channel correlation effectively in an alternating-projections scheme. We have compared this technique with six state-of-the-art demosaicing techniques, and it outperforms all of them, both visually and in terms of mean square error","most commercial digital camera use color filter array to sample red , green , and blue color accord to a specific pattern . at the location of each pixel only one color sample be take , and the value of the other color must be interpolate use neighbor sample . this color plane interpolation be know as demosaicing ; it be one of the important task in a digital camera pipeline . if demosaicing be not perform appropriately , image suffer from highly visible color artifact . in this paper we present a new demosaicing technique that use inter-channel correlation effectively in an alternating-projections scheme . we have compare this technique with six state-of-the-art demosaicing technique , and it outperform all of them , both visually and in term of mean square error",121,0.857142857
6889,Computers and IT,"For pt. I see ibid. , vol. 11, no. 9, p. 972-84 (2002). We test a number of the leading computational color constancy algorithms using a comprehensive set of images. These were of 33 different scenes under 11 different sources representative of common illumination conditions. The algorithms studied include two gray world methods, a version of the Retinex method, several variants of Forsyth's (1990) gamut-mapping method, Cardei et al. 's (2000) neural net method, and Finlayson et al. 's color by correlation method (Finlayson et al. 1997, 2001; Hubel and Finlayson 2000). We discuss a number of issues in applying color constancy ideas to image data, and study in depth the effect of different preprocessing strategies. We compare the performance of the algorithms on image data with their performance on synthesized data. All data used for this study are available online at http://www. cs. sfu. ca/~color/data, and implementations for most of the algorithms are also available (http://www. cs. sfu. ca/~color/code). Experiments with synthesized data (part one of this paper) suggested that the methods which emphasize the use of the input data statistics, specifically color by correlation and the neural net algorithm, are potentially the most effective at estimating the chromaticity of the scene illuminant. Unfortunately, we were unable to realize comparable performance on real images. Here exploiting pixel intensity proved to be more beneficial than exploiting the details of image chromaticity statistics, and the three-dimensional (3-D) gamut-mapping algorithms gave the best performance","for pt . i see ibid . , vol . 11 , no. 9 , p. 972-84 -LRB- 2002 -RRB- . we test a number of the lead computational color constancy algorithm use a comprehensive set of image . these be of 33 different scene under 11 different source representative of common illumination condition . the algorithm study include two gray world method , a version of the retinex method , several variant of forsyth 's -LRB- 1990 -RRB- gamut-mapping method , cardei et al. 's -LRB- 2000 -RRB- neural net method , and finlayson et al. 's color by correlation method -LRB- finlayson et al. 1997 , 2001 ; hubel and finlayson 2000 -RRB- . we discuss a number of issue in apply color constancy idea to image data , and study in depth the effect of different preprocessing strategy . we compare the performance of the algorithm on image data with their performance on synthesize data . all data use for this study be available online at http://www . c . sfu . ca / ~ color/data , and implementation for most of the algorithm be also available -LRB- http://www . c . sfu . ca / ~ color/code -RRB- . experiment with synthesize data -LRB- part one of this paper -RRB- suggest that the method which emphasize the use of the input data statistic , specifically color by correlation and the neural net algorithm , be potentially the most effective at estimate the chromaticity of the scene illuminant . unfortunately , we be unable to realize comparable performance on real image . here exploit pixel intensity prove to be more beneficial than exploit the detail of image chromaticity statistic , and the three-dimensional -LRB- 3-d -RRB- gamut-mapping algorithm give the best performance",242,0.933333333
6890,Computers and IT,"We introduce a context for testing computational color constancy, specify our approach to the implementation of a number of the leading algorithms, and report the results of three experiments using synthesized data. Experiments using synthesized data are important because the ground truth is known, possible confounds due to camera characterization and pre-processing are absent, and various factors affecting color constancy can be efficiently investigated because they can be manipulated individually and precisely. The algorithms chosen for close study include two gray world methods, a limiting case of a version of the Retinex method, a number of variants of Forsyth's (1990) gamut-mapping method, Cardei et al. 's (2000) neural net method, and Finlayson et al. 's color by correlation method (Finlayson et al. 1997, 2001; Hubel and Finlayson 2000) . We investigate the ability of these algorithms to make estimates of three different color constancy quantities: the chromaticity of the scene illuminant, the overall magnitude of that illuminant, and a corrected, illumination invariant, image. We consider algorithm performance as a function of the number of surfaces in scenes generated from reflectance spectra, the relative effect on the algorithms of added specularities, and the effect of subsequent clipping of the data. All data is available on-line at http://www. cs. sfu. ca/~color/data, and implementations for most of the algorithms are also available (http://www. cs. sfu. ca/~color/code)","we introduce a context for testing computational color constancy , specify our approach to the implementation of a number of the lead algorithm , and report the result of three experiment use synthesize data . experiment use synthesize data be important because the ground truth be know , possible confound due to camera characterization and pre-processing be absent , and various factor affect color constancy can be efficiently investigate because they can be manipulate individually and precisely . the algorithm choose for close study include two gray world method , a limit case of a version of the retinex method , a number of variant of forsyth 's -LRB- 1990 -RRB- gamut-mapping method , cardei et al. 's -LRB- 2000 -RRB- neural net method , and finlayson et al. 's color by correlation method -LRB- finlayson et al. 1997 , 2001 ; hubel and finlayson 2000 -RRB- . we investigate the ability of these algorithm to make estimate of three different color constancy quantity : the chromaticity of the scene illuminant , the overall magnitude of that illuminant , and a correct , illumination invariant , image . we consider algorithm performance as a function of the number of surface in scene generate from reflectance spectrum , the relative effect on the algorithm of add specularitie , and the effect of subsequent clipping of the data . all data be available on-line at http://www . c . sfu . ca / ~ color/data , and implementation for most of the algorithm be also available -LRB- http://www . c . sfu . ca / ~ color/code -RRB-",223,0.857142857
6891,Computers and IT,"Due to the improvement of image rendering processes, and the increasing importance of quantitative comparisons among synthetic color images, it is essential to define perceptually based metrics which enable to objectively assess the visual quality of digital simulations. In response to this need, this paper proposes a new methodology for the determination of an objective image quality metric, and gives an answer to this problem through three metrics. This methodology is based on the LLAB color space for perception of color in complex images, a modification of the CIELab1976 color space. The first metric proposed is a pixel by pixel metric which introduces a local distance map between two images. The second metric associates, to a pair of images, a global value. Finally, the third metric uses a recursive subdivision of the images to obtain an adaptative distance map, rougher but less expensive to compute than the first method","due to the improvement of image render process , and the increase importance of quantitative comparison among synthetic color image , it be essential to define perceptually base metric which enable to objectively assess the visual quality of digital simulation . in response to this need , this paper propose a new methodology for the determination of an objective image quality metric , and give an answer to this problem through three metric . this methodology be base on the llab color space for perception of color in complex image , a modification of the cielab1976 color space . the first metric propose be a pixel by pixel metric which introduce a local distance map between two image . the second metric associate , to a pair of image , a global value . finally , the third metric us a recursive subdivision of the image to obtain an adaptative distance map , rough but less expensive to compute than the first method",149,0.733333333
6892,Computers and IT,We prove an exact controllability result for thin cups using the Fourier method and recent improvements of Ingham (1936) type theorems,we prove an exact controllability result for thin cup use the fouri method and recent improvement of ingham -LRB- 1936 -RRB- type theorem,21,0.333333333
6893,Computers and IT,"A procedure that compensates for static friction (stiction) in pneumatic control valves is presented. The compensation is obtained by adding pulses to the control signal. The characteristics of the pulses are determined from the control action. The compensator is implemented in industrial controllers and control systems, and the industrial experiences show that the procedure reduces the control error during stick-slip motion significantly compared to standard control without stiction compensation","a procedure that compensate for static friction -LRB- stiction -RRB- in pneumatic control valve be present . the compensation be obtain by add pulse to the control signal . the characteristic of the pulse be determine from the control action . the compensator be implement in industrial controller and control system , and the industrial experience show that the procedure reduce the control error during stick-slip motion significantly compare to standard control without stiction compensation",69,0.625
6894,Computers and IT,"This paper is intended to answer the question: ""When can a simple dead-time compensator be expected to perform better than a PID?"". The performance criterion used is the integrated absolute error (IAE). It is compared for PI and PID controllers and a simple dead-time compensator (DTC) when a step load disturbance is applied at the plant input. Both stable and integrating processes are considered. For a fair comparison the controllers should provide equal robustness in some sense. Here, as a measure of robustness, the H/sub infinity / norm of the sum of the absolute values of the sensitivity function and the complementary sensitivity function is used. Performance of the DTC's is given also as a function of dead-time margin (D/sub M/)","this paper be intend to answer the question : `` when can a simple dead-time compensator be expect to perform better than a pid ? '' . the performance criterion use be the integrate absolute error -LRB- iae -RRB- . it be compare for pi and pid controller and a simple dead-time compensator -LRB- dtc -RRB- when a step load disturbance be apply at the plant input . both stable and integrate process be consider . for a fair comparison the controller should provide equal robustness in some sense . here , as a measure of robustness , the h/sub infinity / norm of the sum of the absolute value of the sensitivity function and the complementary sensitivity function be use . performance of the dtc 's be give also as a function of dead-time margin -LRB- d/sub m / -RRB-",121,0.6875
6895,Computers and IT,"We study limits for the detection and estimation of weak sinusoidal signals in the primary part of the mammalian auditory system using a stochastic Fitzhugh-Nagumo model and an action-recovery model for synaptic depression. Our overall model covers the chain from a hair cell to a point just after the synaptic connection with a cell in the cochlear nucleus. The information processing performance of the system is evaluated using so-called phi -divergences from statistics that quantify ""dissimilarity"" between probability measures and are intimately related to a number of fundamental limits in statistics and information theory (IT). We show that there exists a set of parameters that can optimize several important phi -divergences simultaneously and that this set corresponds to a constant quiescent firing rate (QFR) of the spiral ganglion neuron. The optimal value of the QFR is frequency dependent but is essentially independent of the amplitude of the signal (for small amplitudes). Consequently, optimal processing according to several standard IT criteria can be accomplished for this model if and only if the parameters are ""tuned"" to values that correspond to one and the same QFR. This offers a new explanation for the QFR and can provide new insight into the role played by several other parameters of the peripheral auditory system","we study limit for the detection and estimation of weak sinusoidal signal in the primary part of the mammalian auditory system use a stochastic fitzhugh-nagumo model and an action-recovery model for synaptic depression . our overall model cover the chain from a hair cell to a point just after the synaptic connection with a cell in the cochlear nucleus . the information processing performance of the system be evaluate use so-called phi - divergence from statistic that quantify `` dissimilarity '' between probability measure and be intimately relate to a number of fundamental limit in statistic and information theory -LRB- it -RRB- . we show that there exist a set of parameter that can optimize several important phi - divergence simultaneously and that this set correspond to a constant quiescent firing rate -LRB- qfr -RRB- of the spiral ganglion neuron . the optimal value of the qfr be frequency dependent but be essentially independent of the amplitude of the signal -LRB- for small amplitude -RRB- . consequently , optimal processing accord to several standard it criterion can be accomplish for this model if and only if the parameter be `` tune '' to value that correspond to one and the same qfr . this offer a new explanation for the qfr and can provide new insight into the role play by several other parameter of the peripheral auditory system",210,0.875
6896,Computers and IT,"In this paper, we study digital control systems with non-uniform updating and sampling patterns, which include multirate sampled-data systems as special cases. We derive lifted models in the state-space domain. The main obstacle for generalized predictive control (GPC) design using the lifted models is the so-called causality constraint. Taking into account this design constraint, we propose a new GPC algorithm, which results in optimal causal control laws for the non-uniformly sampled systems. The solution applies immediately to multirate sampled-data systems where rates are integer multiples of some base period","in this paper , we study digital control system with non-uniform update and sample pattern , which include multirate sampled-data system as special case . we derive lift model in the state-space domain . the main obstacle for generalize predictive control -LRB- gpc -RRB- design use the lift model be the so-called causality constraint . take into account this design constraint , we propose a new gpc algorithm , which result in optimal causal control law for the non-uniformly sample system . the solution apply immediately to multirate sampled-data system where rate be integ multiple of some base period",89,0.454545455
6897,Computers and IT,"Based upon the proposition that the roles of inputs and outputs in a physical system and those in the corresponding output-injection observer do not really have to be consistent, a systematic procedure is developed in this work to properly divide a set of sparse system models and measurement models into a number of independent subsets with the help of a visual aid. Several smaller sub-observers can then be constructed accordingly to replace the original one. The size of each sub-observer may be further reduced by strategically selecting one or more appended states. These techniques are shown to be quite effective in relieving on-line computation load of the output-injection observers and also in identifying detectable sub-systems","base upon the proposition that the role of input and output in a physical system and those in the corresponding output-injection observer do not really have to be consistent , a systematic procedure be develop in this work to properly divide a set of sparse system model and measurement model into a number of independent subset with the help of a visual aid . several small sub-observer can then be construct accordingly to replace the original one . the size of each sub-observer may be further reduce by strategically select one or more append state . these technique be show to be quite effective in relieve on-line computation load of the output-injection observer and also in identify detectable sub-system",115,0.555555556
6898,Computers and IT,"Principal component analysis (PCA) has been widely used for monitoring complex industrial processes with multiple variables and diagnosing process and sensor faults. The objective of this paper is to develop a new subspace identification algorithm that gives consistent model estimates under the errors-in-variables (EIV) situation. In this paper, we propose a new subspace identification approach using principal component analysis. PCA naturally falls into the category of EIV formulation, which resembles total least squares and allows for errors in both process input and output. We propose to use PCA to determine the system observability subspace, the matrices and the system order for an EIV formulation. Standard PCA is modified with instrumental variables in order to achieve consistent estimates of the system matrices. The proposed subspace identification method is demonstrated using a simulated process and a real industrial process for model identification and order determination. For comparison the MOESP algorithm and N4SID algorithm are used as benchmarks to demonstrate the advantages of the proposed PCA based subspace model identification (SMI) algorithm","principal component analysis -LRB- pca -RRB- have be widely use for monitor complex industrial process with multiple variable and diagnose process and sensor fault . the objective of this paper be to develop a new subspace identification algorithm that give consistent model estimate under the errors-in-variable -LRB- eiv -RRB- situation . in this paper , we propose a new subspace identification approach use principal component analysis . pca naturally fall into the category of eiv formulation , which resemble total least square and allow for error in both process input and output . we propose to use pca to determine the system observability subspace , the matrix and the system order for an eiv formulation . standard pca be modify with instrumental variable in order to achieve consistent estimate of the system matrix . the propose subspace identification method be demonstrate use a simulated process and a real industrial process for model identification and order determination . for comparison the moesp algorithm and n4sid algorithm be use as benchmark to demonstrate the advantage of the propose pca base subspace model identification -LRB- smi -RRB- algorithm",169,0.533333333
6899,Computers and IT,"To improve availability and performance of fuel cells, the operating temperature of the molten carbonate fuel cells (MCFC) stack should be controlled within a specified range. However, most existing models of MCFC are not ready to be applied in synthesis. In the paper, a radial basis function neural networks identification model of a MCFC stack is developed based on the input-output sampled data. An adaptive fuzzy control procedure for the temperature of the MCFC stack is also developed. The parameters of the fuzzy control system are regulated by back-propagation algorithm, and the rule database of the fuzzy system is also adaptively adjusted by the nearest-neighbor-clustering algorithm. Finally using the neural networks model of MCFC stack, the simulation results of the control algorithm are presented. The results show the effectiveness of the proposed modeling and design procedures for the MCFC stack based on neural networks identification and the novel adaptive fuzzy control","to improve availability and performance of fuel cell , the operating temperature of the molten carbonate fuel cell -LRB- mcfc -RRB- stack should be control within a specify range . however , most existing model of mcfc be not ready to be apply in synthesis . in the paper , a radial basis function neural network identification model of a mcfc stack be develop base on the input-output sample data . an adaptive fuzzy control procedure for the temperature of the mcfc stack be also develop . the parameter of the fuzzy control system be regulate by back-propagation algorithm , and the rule database of the fuzzy system be also adaptively adjust by the nearest-neighbor-clustering algorithm . finally use the neural network model of mcfc stack , the simulation result of the control algorithm be present . the result show the effectiveness of the propose modeling and design procedure for the mcfc stack base on neural network identification and the novel adaptive fuzzy control",151,0.7
6900,Computers and IT,"We present a new virtual reality-based interaction metaphor for semi-automatic segmentation of medical 3D volume data. The mouse-based, manual initialization of deformable surfaces in 3D represents a major bottleneck in interactive segmentation. In our multi-modal system we enhance this process with additional sensory feedback. A 3D haptic device is used to extract the centreline of a tubular structure. Based on the obtained path a cylinder with varying diameter is generated, which in turn is used as the initial guess for a deformable surface","we present a new virtual reality-based interaction metaphor for semi-automatic segmentation of medical 3d volume data . the mouse-based , manual initialization of deformable surface in 3d represent a major bottleneck in interactive segmentation . in our multi-modal system we enhance this process with additional sensory feedback . a 3d haptic device be use to extract the centreline of a tubular structure . base on the obtain path a cylinder with vary diameter be generate , which in turn be use as the initial guess for a deformable surface",83,0.714285714
6901,Computers and IT,"This paper presents a review of surgical navigation systems in orthopaedics and categorizes these systems according to the image modalities that are used for the visualization of surgical action. Medical images used to be an essential part of surgical education and documentation as well as diagnosis and operation planning over many years. With the recent introduction of navigation techniques in orthopaedic surgery, a new field of application has been opened. Today surgical navigation systems - also known as image-guided surgery systems - are available for various applications in orthopaedic surgery. They visualize the position and orientation of surgical instruments as graphical overlays onto a medical image of the operated anatomy on a computer monitor. Preoperative image data such as computed tomography scans or intra operatively generated images (for example, ultrasonic, endoscopic or fluoroscopic images) are suitable for this purpose. A new category of medical images termed 'surgeon-defined anatomy' has been developed that exclusively relies upon the usage of navigation technology. Points on the anatomy are digitized interactively by the surgeon and are used to build up an abstract geometrical model of the bony structures to be operated on. This technique may be used when no other image data is available or appropriate for a given application","this paper present a review of surgical navigation system in orthopaedics and categoriz these system accord to the image modality that be use for the visualization of surgical action . medical image use to be an essential part of surgical education and documentation as well as diagnosis and operation planning over many year . with the recent introduction of navigation technique in orthopaedic surgery , a new field of application have be open . today surgical navigation system - also know as image-guided surgery system - be available for various application in orthopaedic surgery . they visualize the position and orientation of surgical instrument as graphical overlay onto a medical image of the operate anatomy on a computer monitor . preoperative image data such as computed tomography scan or intra operatively generate image -LRB- for example , ultrasonic , endoscopic or fluoroscopic image -RRB- be suitable for this purpose . a new category of medical image term ` surgeon-defined anatomy ' have be develop that exclusively rely upon the usage of navigation technology . point on the anatomy be digitize interactively by the surgeon and be use to build up an abstract geometrical model of the bony structure to be operate on . this technique may be use when no other image data be available or appropriate for a give application",206,0.666666667
6902,Computers and IT,"A solution to the problem of lung metastasis detection on computed tomography (CT) scans of the thorax is presented. A knowledge-based top-down approach for image interpretation is used. The method is inspired by the manner in which a radiologist and radiotherapist interpret CT images before radiotherapy is planned. A two-dimensional followed by a three-dimensional analysis is performed. The algorithm first detects the thorax contour, the lungs and the ribs, which further help the detection of metastases. Thus, two types of tumors are detected: nodules and metastases located at the lung extremities. A method to visualize the anatomical structures segmented is also presented. The system was tested on 20 patients (988 total images) from the Oncology Department of La Chaux-de-Fonds Hospital and the results show that the method is reliable as a computer-aided diagnostic tool for clinical purpose in an oncology department","a solution to the problem of lung metastasis detection on computed tomography -LRB- ct -RRB- scan of the thorax be present . a knowledge-based top-down approach for image interpretation be use . the method be inspire by the manner in which a radiologist and radiotherapist interpret ct image before radiotherapy be plan . a two-dimensional follow by a three-dimensional analysis be perform . the algorithm first detect the thorax contor , the lung and the rib , which far help the detection of metastasis . thus , two type of tumor be detect : nodule and metastasis locate at the lung extremity . a method to visualize the anatomical structure segmented be also present . the system be test on 20 patient -LRB- 988 total image -RRB- from the oncology department of la chaux-de-fond hospital and the result show that the method be reliable as a computer-aided diagnostic tool for clinical purpose in an oncology department",141,0.692307692
6903,Computers and IT,"A detailed finite element model of the human kidney for trauma research has been created directly from the National Library of Medicine Visible Human Female (VHF) Project data set. An image segmentation and organ reconstruction software package has been developed and employed to transform the 2D VHF images into a 3D polygonal representation. Nonuniform rational B-spline (NURBS) surfaces were then mapped to the polygonal surfaces, and were finally utilized to create a robust 3D hexahedral finite element mesh within a commercially available meshing software. The model employs a combined viscoelastic and hyperelastic material model to successfully simulate the behaviour of biological soft tissues. The finite element model was then validated for use in biomechanical research","a detailed finite element model of the human kidney for trauma research have be create directly from the national library of medicine visible human female -LRB- vhf -RRB- project data set . an image segmentation and organ reconstruction software package have be develop and employ to transform the 2d vhf image into a 3d polygonal representation . nonuniform rational b-spline -LRB- nurb -RRB- surface be then map to the polygonal surface , and be finally utilize to create a robust 3d hexahedral finite element mesh within a commercially available mesh software . the model employ a combine viscoelastic and hyperelastic material model to successfully simulate the behavior of biological soft tissue . the finite element model be then validate for use in biomechanical research",115,0.7
6904,Computers and IT,"We propose a new service for building user-defined 3D anatomical structures on the Web. The Web server is connected to a database storing more than 1000 3D anatomical models reconstructed from the Visible Human. Users may combine existing models as well as planar oblique slices in order to create their own structured anatomical scenes. Furthermore, they may record sequences of scene construction and visualization actions. These actions enable the server to construct high-quality video animations, downloadable by the user. Professionals and students in anatomy, medicine and related disciplines are invited to use the server and create their own anatomical scenes","we propose a new service for build user-defined 3d anatomical structure on the web . the web server be connect to a database store more than 1000 3d anatomical model reconstruct from the visible human . user may combine exist model as well as planar oblique slice in order to create their own structured anatomical scene . furthermore , they may record sequence of scene construction and visualization action . these action enable the server to construct high-quality video animation , downloadable by the user . professional and student in anatomy , medicine and relate discipline be invite to use the server and create their own anatomical scene",100,0.625
6905,Computers and IT,"In our experience, mesh-cutting methods can be distinguished by how their solutions address the following major issues: definition of the cut path, primitive removal and re-meshing, number of new primitives created, when re-meshing is performed, and representation of the cutting tool. Many researchers have developed schemes for interactive mesh cutting with the goals of reducing the number of new primitives created, creating new primitives with good aspect ratios, avoiding a disconnected mesh structure between primitives in the cut path, and representing the path traversed by the tool as accurately as possible. The goal of this paper is to explain how, by using a very simple framework, one can build a generalized cutting scheme. This method allows for any arbitrary cut to be made within a virtual object, and can simulate cutting surface, layered surface or tetrahedral objects using a virtual scalpel, scissors, or loop cautery tool. This method has been implemented in a real-time, haptic-rate surgical simulation system allowing arbitrary cuts to be made on high-resolution patient-specific models","in our experience , mesh-cutting method can be distinguish by how their solution address the follow major issue : definition of the cut path , primitive removal and re-meshing , number of new primitive create , when re-meshing be perform , and representation of the cut tool . many researcher have develop scheme for interactive mesh cut with the goal of reduce the number of new primitive create , create new primitive with good aspect ratio , avoid a disconnect mesh structure between primitive in the cut path , and represent the path traverse by the tool as accurately as possible . the goal of this paper be to explain how , by use a very simple framework , one can build a generalize cut scheme . this method allow for any arbitrary cut to be make within a virtual object , and can simulate cut surface , layer surface or tetrahedral object use a virtual scalpel , scissors , or loop cautery tool . this method have be implement in a real-time , haptic-rate surgical simulation system allow arbitrary cut to be make on high-resolution patient-specific model",168,0.571428571
6906,Computers and IT,"A large and influential class of neural network architectures uses postintegration lateral inhibition as a mechanism for competition. We argue that these algorithms are computationally deficient in that they fail to generate, or learn, appropriate perceptual representations under certain circumstances. An alternative neural network architecture is presented here in which nodes compete for the right to receive inputs rather than for the right to generate outputs. This form of competition, implemented through preintegration lateral inhibition, does provide appropriate coding properties and can be used to learn such representations efficiently. Furthermore, this architecture is consistent with both neuroanatomical and neuropsychological data. We thus argue that preintegration lateral inhibition has computational advantages over conventional neural network architectures while remaining equally biologically plausible","a large and influential class of neural network architecture use postintegration lateral inhibition as a mechanism for competition . we argue that these algorithm be computationally deficient in that they fail to generate , or learn , appropriate perceptual representation under certain circumstance . an alternative neural network architecture be present here in which nod compete for the right to receive input rather than for the right to generate output . this form of competition , implement through preintegration lateral inhibition , do provide appropriate coding property and can be use to learn such representation efficiently . furthermore , this architecture be consistent with both neuroanatomical and neuropsychological data . we thus argue that preintegration lateral inhibition have computational advantage over conventional neural network architecture while remain equally biologically plausible",120,0.833333333
6907,Computers and IT,"Selection of the best set of scales is problematic when developing signal-driven approaches for pixel-based image segmentation. Often, different possibly conflicting criteria need to be fulfilled in order to obtain the best trade-off between uncertainty (variance) and location accuracy. The optimal set of scales depends on several factors: the noise level present in the image material, the prior distribution of the different types of segments, the class-conditional distributions associated with each type of segment as well as the actual size of the (connected) segments. We analyse, theoretically and through experiments, the possibility of using the overall and class-conditional error rates as criteria for selecting the optimal sampling of the linear and morphological scale spaces. It is shown that the overall error rate is optimized by taking the prior class distribution in the image material into account. However, a uniform (ignorant) prior distribution ensures constant class-conditional error rates. Consequently, we advocate for a uniform prior class distribution when an uncommitted, scale-invariant segmentation approach is desired. Experiments with a neural net classifier developed for segmentation of dynamic magnetic resonance (MR) images, acquired with a paramagnetic tracer, support the theoretical results. Furthermore, the experiments show that the addition of spatial features to the classifier, extracted from the linear or morphological scale spaces, improves the segmentation result compared to a signal-driven approach based solely on the dynamic MR signal. The segmentation results obtained from the two types of features are compared using two novel quality measures that characterize spatial properties of labelled images","selection of the best set of scale be problematic when develop signal-driven approach for pixel-based image segmentation . often , different possibly conflict criterion need to be fulfil in order to obtain the best trade-off between uncertainty -LRB- variance -RRB- and location accuracy . the optimal set of scale depend on several factor : the noise level present in the image material , the prior distribution of the different type of segment , the class-conditional distribution associate with each type of segment as well as the actual size of the -LRB- connect -RRB- segment . we analyze , theoretically and through experiment , the possibility of use the overall and class-conditional error rate as criterion for select the optimal sampling of the linear and morphological scale space . it be show that the overall error rate be optimize by take the prior class distribution in the image material into account . however , a uniform -LRB- ignorant -RRB- prior distribution ensure constant class-conditional error rate . consequently , we advocate for a uniform prior class distribution when an uncommitted , scale-invariant segmentation approach be desire . experiment with a neural net classifier develop for segmentation of dynamic magnetic resonance -LRB- mr -RRB- image , acquire with a paramagnetic tracer , support the theoretical result . furthermore , the experiment show that the addition of spatial feature to the classifier , extract from the linear or morphological scale space , improve the segmentation result compare to a signal-driven approach base solely on the dynamic mr signal . the segmentation result obtain from the two type of feature be compare use two novel quality measure that characterize spatial property of label image",249,0.785714286
6908,Computers and IT,"We present a novel algorithm based on a hybrid of the global and local treatment of a wrapped map. The proposed algorithm is especially effective for the unwrapping of speckle-coded interferogram contour maps. In contrast to earlier unwrapping algorithms by region, we propose a local discontinuity-restoring criterion to serve as the preprocessor or postprocessor of our hybrid algorithm, which makes the unwrapping by region much easier and more efficient. With this hybrid algorithm, a robust, stable, and especially time effective phase unwrapping can be achieved. Additionally, the criterion and limitation of this hybrid algorithm are fully described. The robustness, stability, and speed of this hybrid algorithm are also studied. The proposed algorithm can be easily upgraded with minor modifications to solve the unwrapping problem of maps with phase inconsistency. Both numerical simulation and experimental applications demonstrate the effectiveness of the proposed algorithm","we present a novel algorithm base on a hybrid of the global and local treatment of a wrap map . the propose algorithm be especially effective for the unwrapping of speckle-coded interferogram contor map . in contrast to earlier unwrapping algorithm by region , we propose a local discontinuity-restoring criterion to serve as the preprocessor or postprocessor of our hybrid algorithm , which make the unwrapping by region much easy and more efficient . with this hybrid algorithm , a robust , stable , and especially time effective phase unwrapping can be achieve . additionally , the criterion and limitation of this hybrid algorithm be fully describe . the robustness , stability , and speed of this hybrid algorithm be also study . the propose algorithm can be easily upgrade with minor modification to solve the unwrapping problem of map with phase inconsistency . both numerical simulation and experimental application demonstrate the effectiveness of the propose algorithm",142,0.533333333
6909,Computers and IT,"Moire interferometry is a powerful technique for high sensitivity in-plane deformation contouring. However, from an engineering viewpoint, the derivatives of displacement, i. e. , strain, are the desired parameter. Thus there is a need to differentiate the displacement field. Optical and digital methods have been proposed for this differentiation. Optical methods provide contours that still need to be quantified, while digital methods suffer from drawbacks inherent in the digital differentiation process. We describe a novel approach of strain segmentation for the moire pattern using a multichannel Gabor filter. Appropriate filter design allows for user-specific segmentation, which is essentially in engineering design and analysis","moire interferometry be a powerful technique for high sensitivity in-plane deformation contouring . however , from an engineering viewpoint , the derivative of displacement , i. e. , strain , be the desire parameter . thus there be a need to differentiate the displacement field . optical and digital method have be propose for this differentiation . optical method provide contor that still need to be quantify , while digital method suffer from drawback inherent in the digital differentiation process . we describe a novel approach of strain segmentation for the moire pattern use a multichannel gabor filter . appropriate filter design allow for user-specific segmentation , which be essentially in engineering design and analysis",103,0.736842105
6910,Computers and IT,"We present a new algorithm that uses the randomness of the noise pattern to achieve high positioning accuracy by applying a modified averaging operation. Using the suggested approach, noise sensitivity of the positioning accuracy can be significantly reduced. This new improved algorithm can improve the performances of tracking systems used for military as well as civil applications. The concept is demonstrated theoretically as well as by optical experiment","we present a new algorithm that use the randomness of the noise pattern to achieve high positioning accuracy by apply a modify averaging operation . use the suggested approach , noise sensitivity of the positioning accuracy can be significantly reduce . this new improve algorithm can improve the performance of track system use for military as well as civil application . the concept be demonstrate theoretically as well as by optical experiment",68,0.5
6911,Computers and IT,"Even though the hue saturation intensity (HSI) color model has been widely used in color image processing and analysis, the conversion formulas from the RGB color model to HSI are nonlinear and complicated in comparison with the conversion formulas of other color models. When an RGB image is degraded by random Gaussian noise, this nonlinearity leads to a nonuniform noise distribution in HSI, making accurate image analysis more difficult. We have analyzed the noise characteristics of the HSI color model and developed an adaptive spatial filtering method to reduce the magnitude of noise and the nonuniformity of noise variance in the HSI color space. With this adaptive filtering method, the filter kernel for each pixel is dynamically adjusted, depending on the values of intensity and saturation. In our experiments we have filtered the saturation and hue components and generated edge maps from color gradients. We have found that by using the adaptive filtering method, the minimum error rate in edge detection improves by approximately 15%","even though the hue saturation intensity -LRB- hsi -RRB- color model have be widely use in color image processing and analysis , the conversion formula from the rgb color model to hsi be nonlinear and complicate in comparison with the conversion formula of other color model . when an rgb image be degraded by random gaussian noise , this nonlinearity lead to a nonuniform noise distribution in hsi , make accurate image analysis more difficult . we have analyze the noise characteristic of the hsi color model and develop an adaptive spatial filter method to reduce the magnitude of noise and the nonuniformity of noise variance in the hsi color space . with this adaptive filter method , the filter kernel for each pixel be dynamically adjust , depend on the value of intensity and saturation . in our experiment we have filter the saturation and hue component and generate edge map from color gradient . we have find that by use the adaptive filter method , the minimum error rate in edge detection improve by approximately 15 %",165,0.857142857
6912,Computers and IT,"We present a real-time method for recognizing three-dimensional (3-D) objects with scale invariance. The 3-D information of the objects is codified in deformed fringe patterns using the Fourier transform profilometry technique and is correlated using a classical convergent correlator. The scale invariance property is achieved using two different approaches: the Mellin radial harmonic decomposition and the logarithmic radial harmonic filter. Thus, the method is invariant for changes in the scale of the 3-D target within a defined interval of scale factors. Experimental results show the utility of the proposed method","we present a real-time method for recognize three-dimensional -LRB- 3-d -RRB- object with scale invariance . the 3-d information of the object be codify in deform fringe pattern use the fourier transform profilometry technique and be correlated use a classical convergent correlator . the scale invariance property be achieve use two different approach : the mellin radial harmonic decomposition and the logarithmic radial harmonic filter . thus , the method be invariant for change in the scale of the 3-d target within a define interval of scale factor . experimental result show the utility of the propose method",90,0.769230769
6913,Computers and IT,We present an automatic method for region of interest (ROI) location in camera calibration used in computer vision inspection. An intelligent ROI location algorithm based on the Radon transform is developed to automate the calibration process. The algorithm remains robust even if the anchor target has a notable rotation angle in the target plane. This method functions well although the anchor target is not carefully positioned. Several improvement methods are studied to avoid the algorithm's huge time/space consumption problem. The algorithm runs about 100 times faster if these improvement methods are applied. Using this method fully automatic camera calibration is achieved without human interactive ROI specification. Experiments show that this algorithm can help to calibrate the intrinsic parameters of the zoom lens and the camera parameters quickly and automatically,we present an automatic method for region of interest -LRB- roi -RRB- location in camera calibration use in computer vision inspection . an intelligent roi location algorithm base on the radon transform be develop to automate the calibration process . the algorithm remain robust even if the anchor target have a notable rotation angle in the target plane . this method function well although the anchor target be not carefully position . several improvement method be study to avoid the algorithm 's huge time/space consumption problem . the algorithm run about 100 time faster if these improvement method be apply . use this method fully automatic camera calibration be achieve without human interactive roi specification . experiment show that this algorithm can help to calibrate the intrinsic parameter of the zoom lens and the camera parameter quickly and automatically,129,0.733333333
6914,Computers and IT,"A technique is developed for microscope autofocusing, which is called the eccentric light beam approach with high resolution, wide focusing range, and compact construction. The principle is described. The theoretical formula of the eccentric light beam approach deduced can be applied not only to an object lens whose objective plane is just at the focal plane, but also to an object lens whose objective plane is not at the focal plane. The experimental setup uses a semiconductor laser device as the light source. The laser beam that enters into the microscope is eccentric with the main light axis. A defocused signal is acquired by a symmetrical silicon photocell for the change of the reflected light position caused by differential amplification and processed by a microprocessor. Then the electric signal is power-amplified and drives a dc motor, which moves a fine working platform to an automatic focus of the microscope. The result of the experiments shows a +or-0. 1- mu m precision of autofocusing for a range of +or-500- mu m defocusing. The system has high reliability and can meet the requirements of various accurate micro measurement systems","a technique be develop for microscope autofocusing , which be call the eccentric light beam approach with high resolution , wide focus range , and compact construction . the principle be describe . the theoretical formula of the eccentric light beam approach deduce can be apply not only to an object lens whose objective plane be just at the focal plane , but also to an object lens whose objective plane be not at the focal plane . the experimental setup use a semiconductor laser device as the light source . the laser beam that enter into the microscope be eccentric with the main light axis . a defocused signal be acquire by a symmetrical silicon photocell for the change of the reflect light position cause by differential amplification and process by a microprocessor . then the electric signal be power-amplified and drive a dc motor , which move a fine working platform to an automatic focus of the microscope . the result of the experiment show a + or-0 . 1 - mu m precision of autofocus for a range of + or-500 - mu m defocusing . the system have high reliability and can meet the requirement of various accurate micro measurement system",187,0.823529412
6915,Computers and IT,"The basic technology for a robotic system is developed to automate the packing of polycrystalline silicon nuggets into fragile fused silica crucible in Czochralski (melt pulling) semiconductor wafer production. The highly irregular shapes of the nuggets and the packing constraints make this a difficult and challenging task. It requires the delicate manipulation and packing of highly irregular polycrystalline silicon nuggets into a fragile fused silica crucible. For this application, a dual optical 3-D surface mapping system that uses active laser triangulation has been developed and successfully tested. One part of the system measures the geometry profile of a nugget being packed and the other the profile of the nuggets already in the crucible. A resolution of 1 mm with 15-KHz sampling frequency is achieved. Data from the system are used by the packing algorithm, which determines optimal nugget placement. The key contribution is to describe the design and implementation of an efficient and robust 3-D imaging system to map highly irregular shaped objects using conventional components in context of real commercial manufacturing processes","the basic technology for a robotic system be develop to automate the packing of polycrystalline silicon nugget into fragile fused silica crucible in czochralski -LRB- melt pull -RRB- semiconductor wafer production . the highly irregular shape of the nugget and the packing constraint make this a difficult and challenging task . it require the delicate manipulation and packing of highly irregular polycrystalline silicon nugget into a fragile fused silica crucible . for this application , a dual optical 3-d surface mapping system that use active laser triangulation have be develop and successfully test . one part of the system measure the geometry profile of a nugget be pack and the other the profile of the nugget already in the crucible . a resolution of 1 mm with 15-khz sample frequency be achieve . data from the system be use by the packing algorithm , which determine optimal nugget placement . the key contribution be to describe the design and implementation of an efficient and robust 3-d imaging system to map highly irregular shaped object use conventional component in context of real commercial manufacturing process",173,0.625
6916,Computers and IT,"For an accurate scene analysis using monocular color traffic image sequences, a robust segmentation of moving vehicles from the stationary background is generally required. However, the presence of moving cast shadow may lead to an inaccurate vehicle segmentation, and as a result, may lead to further erroneous scene analysis. We propose an effective method for the detection of moving cast shadow. By observing the characteristics of cast shadow in the luminance, chrominance, gradient density, and geometry domains, a combined probability map, called a shadow confidence score (SCS), is obtained. From the edge map of the input image, each edge pixel is examined to determine whether it belongs to the vehicle region based on its neighboring SCSs. The cast shadow is identified as those regions with high SCSs, which are outside the convex hull of the selected vehicle edge pixels. The proposed method is tested on 100 vehicle images taken under different lighting conditions (sunny and cloudy), viewing angles (roadside and overhead), vehicle sizes (small, medium, and large), and colors (similar to the road and not). The results indicate that an average error rate of around 14% is obtained while the lowest error rate is around 3% for large vehicles","for an accurate scene analysis use monocular color traffic image sequence , a robust segmentation of move vehicle from the stationary background be generally require . however , the presence of move cast shadow may lead to an inaccurate vehicle segmentation , and as a result , may lead to further erroneous scene analysis . we propose an effective method for the detection of move cast shadow . by observe the characteristic of cast shadow in the luminance , chrominance , gradient density , and geometry domain , a combine probability map , call a shadow confidence score -LRB- scs -RRB- , be obtain . from the edge map of the input image , each edge pixel be examine to determine whether it belong to the vehicle region base on its neighbor scs . the cast shadow be identify as those region with high scs , which be outside the convex hull of the select vehicle edge pixel . the propose method be test on 100 vehicle image take under different lighting condition -LRB- sunny and cloudy -RRB- , view angle -LRB- roadside and overhead -RRB- , vehicle size -LRB- small , medium , and large -RRB- , and color -LRB- similar to the road and not -RRB- . the result indicate that an average error rate of around 14 % be obtain while the low error rate be around 3 % for large vehicle",199,0.925925926
6917,Computers and IT,"For original paper see ibid. , vol. 36, no. 2, p. 101-30 (2000). The authors had given a method for the construction of panoramic image mosaics with global and local alignment. Unfortunately a mistake had led to an incorrect equation which whilst making little difference in many cases, for faster (and assured) convergence, the correct formulae given here should be used","for original paper see ibid . , vol . 36 , no. 2 , p. 101-30 -LRB- 2000 -RRB- . the author have give a method for the construction of panoramic image mosaic with global and local alignment . unfortunately a mistake have lead to an incorrect equation which whilst make little difference in many case , for fast -LRB- and assure -RRB- convergence , the correct formula give here should be use",61,0.5
6918,Computers and IT,"In many imaging applications, it is highly desirable to replace mechanical beam-steering components (i. e. , mirrors and gimbals) with a nonmechanical device. One such device is a nematic liquid crystal optical phased array (LCOPA). An LCOPA can implement a blazed phase grating to steer the incident light. However, when a phase grating is used in a broadband imaging system, two adverse effects can occur. First, dispersion will cause different incident wavelengths arriving at the same angle to be steered to different output angles, causing chromatic aberrations in the image plane. Second, the device will steer energy not only to the first diffraction order, but to others as well. This multiple-order effect results in multiple copies of the scene appearing in the image plane. We describe a digital image restoration technique designed to overcome these degradations. The proposed postprocessing technique is based on a Wiener deconvolution filter. The technique, however, is applicable only to scenes containing objects with approximately constant reflectivities over the spectral region of interest. Experimental results are presented to demonstrate the effectiveness of this technique","in many imaging application , it be highly desirable to replace mechanical beam-steering component -LRB- i. e. , mirror and gimbal -RRB- with a nonmechanical device . one such device be a nematic liquid crystal optical phase array -LRB- lcopa -RRB- . an lcopa can implement a blazed phase grate to steer the incident light . however , when a phase grating be use in a broadband imaging system , two adverse effect can occur . first , dispersion will cause different incident wavelength arrive at the same angle to be steer to different output angle , cause chromatic aberration in the image plane . second , the device will steer energy not only to the first diffraction order , but to other as well . this multiple-ord effect result in multiple copy of the scene appear in the image plane . we describe a digital image restoration technique design to overcome these degradation . the propose postprocessing technique be base on a wiener deconvolution filter . the technique , however , be applicable only to scene contain object with approximately constant reflectivity over the spectral region of interest . experimental result be present to demonstrate the effectiveness of this technique",178,0.730769231
6919,Computers and IT,"An efficient one-step digit-set-restricted modified signed-digit (MSD) adder based on symbolic substitution is presented. In this technique, carry propagation is avoided by introducing reference digits to restrict the intermediate carry and sum digits to {1, 0} and {0, 1}, respectively. The proposed technique requires significantly fewer minterms and simplifies system complexity compared to the reported one-step MSD addition techniques. An incoherent correlator based on an optoelectronic shared content-addressable memory processor is suggested to perform the addition operation. In this technique, only one set of minterms needs to be stored, independent of the operand length","an efficient one-step digit-set-restricted modify signed-digit -LRB- msd -RRB- add base on symbolic substitution be present . in this technique , carry propagation be avoid by introduce reference digit to restrict the intermediate carry and sum digit to -LCB- 1 , 0 -RCB- and -LCB- 0 , 1 -RCB- , respectively . the propose technique require significantly few minterm and simplifie system complexity compare to the report one-step msd addition technique . an incoherent correlator base on an optoelectronic share content-addressable memory processor be suggest to perform the addition operation . in this technique , only one set of minterm need to be store , independent of the operand length",94,0.916666667
6920,Computers and IT,"We present a two-step integral imaging system to obtain 3-D orthoscopic real images. By adopting a nonstationary micro-optics technique, we demonstrate experimentally the potential usefulness of two-step integral imaging","we present a two-step integral imaging system to obtain 3-d orthoscopic real image . by adopt a nonstationary micro-optic technique , we demonstrate experimentally the potential usefulness of two-step integral imaging",29,0.4
6921,Computers and IT,"A mask with periodic apertures imaging system is adopted very widely and plays a leading role in modern technology for uses such as pinhole cameras, coded imaging systems, optical information processing, etc. because of its high resolution, its infinite depth of focus, and its usefulness over a broad frequency spectra ranging from visible light to X-rays and gamma rays. While the masks with periodic apertures investigated in the literature are limited only to far-field diffraction, they do not take the shift of apertures within the mask into consideration. Therefore the derivation of the far-field diffraction for a single aperture cannot be applied to a mask with periodic apertures. The far-field diffraction formula modified for a multiaperture mask has been proposed in the past, the analysis remains too complicated to offer some practical guidance for mask design. We study a circular mask with periodic rectangular apertures and develop an easier way to interpret it. First, the near-field diffraction intensity of a circular aperture is calculated by means of Lommel's function. Then the convolution of the circular mask diffraction with periodic rectangular apertures is put together, and we can present a simple mathematical tool to analyze the mask properties including the intensity distribution, blurring aberration, and the criterion of defining the far- or near-field diffraction. This concept can also be expanded to analyze different types of masks with the arbitrarily shaped apertures","a mask with periodic aperture imaging system be adopt very widely and play a leading role in modern technology for us such as pinhole camera , cod imaging system , optical information processing , etc. because of its high resolution , its infinite depth of focus , and its usefulness over a broad frequency spectrum range from visible light to x-ray and gamma ray . while the mask with periodic aperture investigate in the literature be limit only to far-field diffraction , they do not take the shift of aperture within the mask into consideration . therefore the derivation of the far-field diffraction for a single aperture can not be apply to a mask with periodic aperture . the far-field diffraction formula modify for a multiaperture mask have be propose in the past , the analysis remain too complicate to offer some practical guidance for mask design . we study a circular mask with periodic rectangular aperture and develop an easy way to interpret it . first , the near-field diffraction intensity of a circular aperture be calculate by mean of lommel 's function . then the convolution of the circular mask diffraction with periodic rectangular aperture be put together , and we can present a simple mathematical tool to analyze the mask property include the intensity distribution , blur aberration , and the criterion of define the far - or near-field diffraction . this concept can also be expand to analyze different type of mask with the arbitrarily shaped aperture",230,0.826086957
6922,Computers and IT,"A Fourier-based solution to the problem of figure-ground segmentation in short baseline binocular image pairs is presented. Each image is modeled as an additive composite of two component images that exhibit a spatial shift due to the binocular parallax. The segmentation is accomplished by decoupling each Fourier component in one of the resultant additive images into its two constituent phasors, allocating each to its appropriate object-specific spectrum, and then reconstructing the foreground and background using the inverse Fourier transform. It is shown that the foreground and background shifts can be computed from the differences of the magnitudes and phases of the Fourier transform of the binocular image pair. While the model is based on translucent objects, it also works with occluding objects","a fourier-based solution to the problem of figure-ground segmentation in short baseline binocular image pair be present . each image be model as an additive composite of two component image that exhibit a spatial shift due to the binocular parallax . the segmentation be accomplish by decouple each fouri component in one of the resultant additive image into its two constituent phasor , allocate each to its appropriate object-specific spectrum , and then reconstruct the foreground and background use the inverse fourier transform . it be show that the foreground and background shift can be compute from the difference of the magnitude and phase of the fourier transform of the binocular image pair . while the model be base on translucent object , it also work with occlude object",122,0.75
6923,Computers and IT,"We describe the experimental setup of a multispectral color image acquisition system consisting of a professional monochrome CCD camera and a tunable filter in which the spectral transmittance can be controlled electronically. We perform a spectral characterization of the acquisition system taking into account the acquisition noise. To convert the camera output signals to device-independent color data, two main approaches are proposed and evaluated. One consists in applying regression methods to convert from the K camera outputs to a device-independent color space such as CIEXYZ or CIELAB. Another method is based on a spectral model of the acquisition system. By inverting the model using a principal eigenvector approach, we estimate the spectral reflectance of each pixel of the imaged surface","we describe the experimental setup of a multispectral color image acquisition system consist of a professional monochrome ccd camera and a tunable filter in which the spectral transmittance can be control electronically . we perform a spectral characterization of the acquisition system take into account the acquisition noise . to convert the camera output signal to device-independent color data , two main approach be propose and evaluate . one consist in apply regression method to convert from the k camera output to a device-independent color space such as ciexyz or cielab . another method be base on a spectral model of the acquisition system . by invert the model use a principal eigenvector approach , we estimate the spectral reflectance of each pixel of the imaged surface",120,0.904761905
6924,Computers and IT,"We develop a regularized mixed-norm image restoration algorithm to deal with various types of noise. A mixed-norm functional is introduced, which combines the least mean square (LMS) and the least mean fourth (LMF) functionals, as well as a smoothing functional. Two regularization parameters are introduced: one to determine the relative importance of the LMS and LMF functionals, which is a function of the kurtosis, and another to determine the relative importance of the smoothing functional. The two parameters are chosen in such a way that the proposed functional is convex, so that a unique minimizer exists. An iterative algorithm is utilized for obtaining the solution, and its convergence is analyzed. The novelty of the proposed algorithm is that no knowledge of the noise distribution is required, and the relative contributions of the LMS, the LMF, and the smoothing functionals are adjusted based on the partially restored image. Experimental results demonstrate the effectiveness of the proposed algorithm","we develop a regularize mixed-norm image restoration algorithm to deal with various type of noise . a mixed-norm functional be introduce , which combine the least mean square -LRB- lm -RRB- and the least mean fourth -LRB- lmf -RRB- functional , as well as a smoothing functional . two regularization parameter be introduce : one to determine the relative importance of the lm and lmf functional , which be a function of the kurtosi , and another to determine the relative importance of the smoothing functional . the two parameter be choose in such a way that the propose functional be convex , so that a unique minimizer exist . an iterative algorithm be utilize for obtain the solution , and its convergence be analyze . the novelty of the propose algorithm be that no knowledge of the noise distribution be require , and the relative contribution of the lm , the lmf , and the smoothing functional be adjust base on the partially restore image . experimental result demonstrate the effectiveness of the propose algorithm",156,0.642857143
6925,Computers and IT,A new method for computing precise estimates of the motion vector field of moving objects in a sequence of images is proposed. Correspondence vector-field computation is formulated as a matching optimization problem for multiple dynamic images. The proposed method is a heuristic modification of dynamic programming applied to the 2-D optimization problem. Motion-vector-field estimates using real movie images demonstrate good performance of the algorithm in terms of dynamic motion analysis,a new method for compute precise estimate of the motion vector field of move object in a sequence of image be propose . correspondence vector-field computation be formulate as a matching optimization problem for multiple dynamic image . the propose method be a heuristic modification of dynamic programming apply to the 2-d optimization problem . motion-vector-field estimate use real movie image demonstrate good performance of the algorithm in term of dynamic motion analysis,70,0.6875
6926,Computers and IT,"We propose three correlation-based methods to simultaneously detect the centroids of multiple objects in an input scene. The first method is based on the modulus of the moment function, the second method is based on squaring the moment function, and the third method works with a single intensity filter. These methods are invariant to changes in the position, orientation, and scale of the object and result in good noise-smoothing performance. We use spatial light modulators (SLMs) to directly implement the input of the image and filter information for the purpose of these approaches. We present results showing simulations from different approaches and provide comparisons between optical-correlation- and digital-moment-based methods. Experimental results corresponding to an optical correlator using SLMs for the centroid detection are also presented","we propose three correlation-based method to simultaneously detect the centroid of multiple object in an input scene . the first method be base on the modulus of the moment function , the second method be base on square the moment function , and the third method work with a single intensity filter . these method be invariant to change in the position , orientation , and scale of the object and result in good noise-smoothing performance . we use spatial light modulator -LRB- slm -RRB- to directly implement the input of the image and filter information for the purpose of these approach . we present result show simulation from different approach and provide comparison between optical-correlation - and digital-moment-based method . experimental result corresponding to an optical correlator use slm for the centroid detection be also present",125,0.8125
6927,Computers and IT,"Block truncation coding (BTC) is a successful image compression technique due to its simple and fast computational burden. The bit rate is fixed to 2. 0 bits/pixel, whose performance is moderate in terms of compression ratio compared to other compression schemes such as discrete cosine transform (DCT), vector quantization (VQ), wavelet transform coding (WTC), etc. Two kinds of overheads are required for BTC coding: bit plane and quantization values, respectively. A new technique is presented to reduce the bit plane overhead. Conventional bit plane overhead is 1. 0 bits/pixel; we decrease it to 0. 734 bits/pixel while maintaining the same decoded quality as absolute moment BTC (AMBTC) does for the ""Lena"" image. Compared to other published bit plane coding strategies, the proposed method outperforms all of the existing methods","block truncation coding -LRB- btc -RRB- be a successful image compression technique due to its simple and fast computational burden . the bit rate be fix to 2 . 0 bits/pixel , whose performance be moderate in term of compression ratio compare to other compression scheme such as discrete cosine transform -LRB- dct -RRB- , vector quantization -LRB- vq -RRB- , wavelet transform coding -LRB- wtc -RRB- , etc. two kind of overhead be require for btc coding : bit plane and quantization value , respectively . a new technique be present to reduce the bit plane overhead . conventional bit plane overhead be 1 . 0 bits/pixel ; we decrease it to 0 . 734 bits/pixel while maintain the same decoded quality as absolute moment btc -LRB- ambtc -RRB- do for the `` lena '' image . compare to other publish bit plane cod strategy , the propose method outperform all of the exist method",129,0.833333333
6928,Computers and IT,"A novel technique for multi-scale curvature computation on a free-form 3-D surface is presented. This is achieved by convolving local parametrisations of the surface with 2-D Gaussian filters iteratively. In our technique, semigeodesic coordinates are constructed at each vertex of the mesh. Smoothing results are shown for 3-D surfaces with different shapes indicating that surface noise is eliminated and surface details are removed gradually. A number of evolution properties of 3-D surfaces are described. Next, the surface Gaussian and mean curvature values are estimated accurately at multiple scales which are then mapped to colours and displayed directly on the surface. The performance of the technique when selecting different directions as an arbitrary direction for the geodesic at each vertex are also presented. The results indicate that the error observed for the estimation of Gaussian and mean curvatures is quite low after only one iteration. Furthermore, as the surface is smoothed iteratively, the error is further reduced. The results also show that the estimation error of Gaussian curvature is less than that of mean curvature. Our experiments demonstrate that estimation of smoothed surface curvatures are very accurate and not affected by the arbitrary direction of the first geodesic line when constructing semigeodesic coordinates. Our technique is independent of the underlying triangulation and is also more efficient than volumetric diffusion techniques since 2-D rather than 3-D convolutions are employed. Finally, the method presented here is a generalisation of the Curvature Scale Space method for 2-D contours. The CSS method has outperformed comparable techniques within the MPEG-7 evaluation framework. As a result, it has been selected for inclusion in the MPEG-7 package of standards","a novel technique for multi-scale curvature computation on a free-form 3-d surface be present . this be achieve by convolve local parametrisation of the surface with 2-d gaussian filter iteratively . in our technique , semigeodesic coordinate be construct at each vertex of the mesh . smooth result be show for 3-d surface with different shape indicate that surface noise be eliminate and surface detail be remove gradually . a number of evolution property of 3-d surface be describe . next , the surface gaussian and mean curvature value be estimate accurately at multiple scale which be then map to color and display directly on the surface . the performance of the technique when select different direction as an arbitrary direction for the geodesic at each vertex be also present . the result indicate that the error observe for the estimation of gaussian and mean curvature be quite low after only one iteration . furthermore , as the surface be smooth iteratively , the error be further reduce . the result also show that the estimation error of gaussian curvature be less than that of mean curvature . our experiment demonstrate that estimation of smooth surface curvature be very accurate and not affect by the arbitrary direction of the first geodesic line when construct semigeodesic coordinate . our technique be independent of the underlie triangulation and be also more efficient than volumetric diffusion technique since 2-d rather than 3-d convolution be employ . finally , the method present here be a generalisation of the curvature scale space method for 2-d contor . the cs method have outperform comparable technique within the mpeg-7 evaluation framework . as a result , it have be select for inclusion in the mpeg-7 package of standard",271,0.785714286
6929,Computers and IT,"A simple method to suppress the zero-order diffraction in the reconstructed image of digital holography is presented. In this method, the Laplacian of a detected hologram is used instead of the hologram itself for numerical reconstruction by computing the discrete Fresnel integral. This method can significantly improve the image quality and give better resolution and higher accuracy of the reconstructed image. The main advantages of this method are its simplicity in experimental requirements and convenience in data processing","a simple method to suppress the zero-order diffraction in the reconstructed image of digital holography be present . in this method , the laplacian of a detect hologram be use instead of the hologram itself for numerical reconstruction by compute the discrete fresnel integral . this method can significantly improve the image quality and give better resolution and high accuracy of the reconstructed image . the main advantage of this method be its simplicity in experimental requirement and convenience in data processing",78,0.666666667
6930,Computers and IT,"An efficient method for two-level thresholding is proposed based on the Bayes formula and the maximum entropy principle, in which no assumptions of the image histogram are made. An alternative criterion is derived based on maximizing entropy and used for speeding up the searching algorithm. Five forms of conditional probability distributions-simple, linear, parabola concave, parabola convex, and S-function-are employed and compared to each other for optimal threshold determination. The effect of precision on optimal threshold determination is discussed and a trade-off precision epsilon =0. 001 is selected experimentally. Our experiments demonstrate that the proposed method achieves a significant improvement in speed from 26 to 57 times faster than the exhaustive search method","an efficient method for two-level thresholding be propose base on the bayes formula and the maximum entropy principle , in which no assumption of the image histogram be make . an alternative criterion be derive base on maximize entropy and use for speed up the search algorithm . five form of conditional probability distributions-simple , linear , parabola concave , parabola convex , and s-function-are employ and compare to each other for optimal threshold determination . the effect of precision on optimal threshold determination be discuss and a trade-off precision epsilon = 0 . 001 be select experimentally . our experiment demonstrate that the propose method achieve a significant improvement in speed from 26 to 57 time fast than the exhaustive search method",112,0.714285714
6931,Computers and IT,"Digital watermarking has been proposed for copyright protection in our digital society. We propose an adaptive digital watermarking scheme based on the human visual system model and a fuzzy logic technique. The fuzzy logic approach is employed to obtain the different strengths and lengths of a watermark by the local characteristics of the image in our proposed scheme. In our experiments, this scheme provides a more robust and imperceptible watermark","digital watermarking have be propose for copyright protection in our digital society . we propose an adaptive digital watermarking scheme base on the human visual system model and a fuzzy logic technique . the fuzzy logic approach be employ to obtain the different strength and length of a watermark by the local characteristic of the image in our propose scheme . in our experiment , this scheme provide a more robust and imperceptible watermark",70,0.777777778
6932,Computers and IT,"Three-dimensional (3D) correlation of color images, considering the color distribution as the third dimension, has been shown to be useful for color pattern recognition tasks. Nevertheless, 3D correlation cannot be directly performed on an optical correlator, that can only process two-dimensional (2D) signals. We propose a method to encode 3D functions onto 2D ones in such a way that the Fourier transform and correlation of these signals, that can be optically performed, encode the 3D Fourier transform and correlation of the 3D signals. The theory for the encoding is given and experimental results obtained in an optical correlator are shown","three-dimensional -LRB- 3d -RRB- correlation of color image , consider the color distribution as the third dimension , have be show to be useful for color pattern recognition task . nevertheless , 3d correlation can not be directly perform on an optical correlator , that can only process two-dimensional -LRB- 2d -RRB- signal . we propose a method to encode 3d function onto 2d one in such a way that the fourier transform and correlation of these signal , that can be optically perform , encode the 3d fourier transform and correlation of the 3d signal . the theory for the encoding be give and experimental result obtain in an optical correlator be show",100,0.6
6933,Computers and IT,"The target-level method is considered for solving continuous multi-criterion maximization problems. In the first step, the decision-maker specifies a target-level point (the desired criterion values); then in the set of vector evaluations we seek points that are closest to the target point in the Chebyshev metric. The vector evaluations obtained in this way are in general weakly efficient. To identify the efficient evaluations, the second step maximizes the sum of the criteria on the set generated in step 1. We prove the relationship between the evaluations and decisions obtained by the proposed procedure, on the one hand, and the efficient (weakly efficient) evaluations and decisions, on the other hand. If the Edgeworth-Pareto hull of the set of vector evaluations is convex, the set of efficient vector evaluations can be approximated by the proposed method","the target-level method be consider for solve continuous multi-criterion maximization problem . in the first step , the decision-maker specify a target-level point -LRB- the desire criterion value -RRB- ; then in the set of vector evaluation we seek point that be close to the target point in the chebyshev metric . the vector evaluation obtain in this way be in general weakly efficient . to identify the efficient evaluation , the second step maximize the sum of the criterion on the set generate in step 1 . we prove the relationship between the evaluation and decision obtain by the propose procedure , on the one hand , and the efficient -LRB- weakly efficient -RRB- evaluation and decision , on the other hand . if the edgeworth-pareto hull of the set of vector evaluation be convex , the set of efficient vector evaluation can be approximate by the propose method",134,0.833333333
6934,Computers and IT,The article presents results of computer processing of experimental information obtained from patients during the acute period of concussion. A number of computational procedures are described,the article present result of computer processing of experimental information obtain from patient during the acute period of concussion . a number of computational procedure be describe,26,0.75
6935,Computers and IT,"The study considers robust estimation of linear regression parameters by the regularization method, the pseudoinverse method, and the Bayesian method allowing for correlations and errors in the data. Regularizing algorithms are constructed and their relationship with pseudoinversion, the Bayesian approach, and BLUE is investigated","the study consider robust estimation of linear regression parameter by the regularization method , the pseudoinverse method , and the bayesian method allow for correlation and error in the data . regularize algorithm be construct and their relationship with pseudoinversion , the bayesian approach , and blue be investigate",44,0.875
6936,Computers and IT,"We consider the behavior of four choice rules - plurality voting, approval voting, Borda count, and self-consistent choice - when applied to choose the best option from a three-element set. It is assumed that the two main options are preferred by a large majority of the voters, while the third option gets a very small number of votes and influences the election outcome only when the two main options receive a close number of votes. When used to rate the main options, Borda count and self-consistent choice contain terms that allow both for the ""strength of preferences"" of the voters and the rating of the main candidates by voters who vote for the third option. In this way, it becomes possible to determine more reliably the winner when plurality voting or approval voting produce close results","we consider the behavior of four choice rule - plurality voting , approval voting , borda count , and self-consistent choice - when apply to choose the best option from a three-element set . it be assume that the two main option be prefer by a large majority of the voter , while the third option get a very small number of vote and influence the election outcome only when the two main option receive a close number of vote . when use to rate the main option , borda count and self-consistent choice contain term that allow both for the `` strength of preference '' of the voter and the rating of the main candidate by voter who vote for the third option . in this way , it become possible to determine more reliably the winner when plurality voting or approval voting produce close result",136,0.833333333
6937,Computers and IT,We consider the inverse problem for the identification of the coefficient in a parabolic equation. The model is applied to describe the functioning of a hierarchical structure; it is also relevant for heat-conduction theory. Unique solvability of the inverse problem is proved,we consider the inverse problem for the identification of the coefficient in a parabolic equation . the model be apply to describe the functioning of a hierarchical structure ; it be also relevant for heat-conduction theory . unique solvability of the inverse problem be prove,42,1
6938,Computers and IT,"This paper presents a new class of interactive image editing operations designed to maintain consistency between multiple images of a physical 3D scene. The distinguishing feature of these operations is that edits to any one image propagate automatically to all other images as if the (unknown) 3D scene had itself been modified. The modified scene can then be viewed interactively from any other camera viewpoint and under different scene illuminations. The approach is useful first as a power-assist that enables a user to quickly modify many images by editing just a few, and second as a means for constructing and editing image-based scene representations by manipulating a set of photographs. The approach works by extending operations like image painting, scissoring, and morphing so that they alter a scene's plenoptic function in a physically-consistent way, thereby affecting scene appearance from all viewpoints simultaneously. A key element in realizing these operations is a new volumetric decomposition technique for reconstructing an scene's plenoptic function from an incomplete set of camera viewpoints","this paper present a new class of interactive image editing operation design to maintain consistency between multiple image of a physical 3d scene . the distinguish feature of these operation be that edit to any one image propagate automatically to all other image as if the -LRB- unknown -RRB- 3d scene have itself be modify . the modify scene can then be view interactively from any other camera viewpoint and under different scene illumination . the approach be useful first as a power-assist that enable a user to quickly modify many image by editing just a few , and second as a mean for construct and editing image-based scene representation by manipulate a set of photograph . the approach work by extend operation like image painting , scissoring , and morph so that they alter a scene 's plenoptic function in a physically-consistent way , thereby affect scene appearance from all viewpoint simultaneously . a key element in realize these operation be a new volumetric decomposition technique for reconstruct an scene 's plenoptic function from an incomplete set of camera viewpoint",168,0.916666667
6939,Computers and IT,"A mathematical model of ion exchange is considered, allowing for ion exchanger compression in the process of ion exchange. Two inverse problems are investigated for this model, unique solvability is proved, and numerical solution methods are proposed. The efficiency of the proposed methods is demonstrated by a numerical experiment","a mathematical model of ion exchange be consider , allow for ion exchanger compression in the process of ion exchange . two inverse problem be investigate for this model , unique solvability be prove , and numerical solution method be propose . the efficiency of the propose method be demonstrate by a numerical experiment",49,0.857142857
6940,Computers and IT,"The article describes the implementation of methods for numerical solution of gas-dynamic problems on a wide class of multiprocessor systems, conventionally characterized as ""cluster"" systems. A standard data-transfer interface - the so-called message passing interface - is used for parallelization of application algorithms among processors. Simulation of jets escaping into a low-pressure region is chosen as a computational example","the article describe the implementation of method for numerical solution of gas-dynamic problem on a wide class of multiprocessor system , conventionally characterize as `` cluster '' system . a standard data-transfer interface - the so-called message pass interface - be use for parallelization of application algorithm among processor . simulation of jet escape into a low-pressure region be choose as a computational example",59,0.714285714
6941,Computers and IT,"For pt. III. see Prikl. Mat. Informatika, MAKS Press, no. 4, p. 5-56 (2000). This is a survey of the literature on hybrid simulation of the Kelvin-Helmholtz instability. We start with a brief review of the theory: the simplest model of the instability - a transition layer in the form of a tangential discontinuity; compressibility of the medium; finite size of the velocity shear region; pressure anisotropy. We then describe the electromagnetic hybrid model (ions as particles and electrons as a massless fluid) and the main numerical schemes. We review the studies on two-dimensional and three-dimensional hybrid simulation of the process of particle mixing across the magnetopause shear layer driven by the onset of a Kelvin-Helmholtz instability. The article concludes with a survey of literature on hybrid simulation of the Kelvin-Helmholtz instability in finite-size objects: jets moving across the magnetic field in the middle of the field reversal layer; interaction between a magnetized plasma flow and a cylindrical plasma source with zero own magnetic field","for pt . iii . see prikl . mat . informatika , mak press , no. 4 , p. 5-56 -LRB- 2000 -RRB- . this be a survey of the literature on hybrid simulation of the kelvin-helmholtz instability . we start with a brief review of the theory : the simple model of the instability - a transition layer in the form of a tangential discontinuity ; compressibility of the medium ; finite size of the velocity shear region ; pressure anisotropy . we then describe the electromagnetic hybrid model -LRB- ion as particle and electron as a massless fluid -RRB- and the main numerical scheme . we review the study on two-dimensional and three-dimensional hybrid simulation of the process of particle mixing across the magnetopause shear layer drive by the onset of a kelvin-helmholtz instability . the article conclude with a survey of literature on hybrid simulation of the kelvin-helmholtz instability in finite-size object : jet move across the magnetic field in the middle of the field reversal layer ; interaction between a magnetize plasma flow and a cylindrical plasma source with zero own magnetic field",165,0.846153846
6942,Computers and IT,"The algorithmic complexity of the innermost loops that determine the complexity of algorithms in computational electromagnetics (CEM) codes are analyzed according to their operation count and the impact of the underlying computer hardware. As memory chips are much slower than arithmetic processors, codes that involve a high data movement compared to the number of arithmetic operations are executed comparatively slower. Hence, matrix-matrix multiplications are much faster than matrix-vector multiplications. It is seen that it is not sufficient to compare only the complexity, but also the actual performance of algorithms to judge on faster execution. Implications involve FDTD loops, LU factorizations, and iterative solvers for dense matrices. Run times on two reference platforms, namely an Athlon 900 MHz and an HP PA 8600 processor, verify the findings","the algorithmic complexity of the innermost loop that determine the complexity of algorithm in computational electromagnetics -LRB- cem -RRB- code be analyze accord to their operation count and the impact of the underlie computer hardware . as memory chip be much slow than arithmetic processor , code that involve a high data movement compare to the number of arithmetic operation be execute comparatively slow . hence , matrix-matrix multiplication be much fast than matrix-vector multiplication . it be see that it be not sufficient to compare only the complexity , but also the actual performance of algorithm to judge on fast execution . implication involve fdtd loop , lu factorization , and iterative solver for dense matrix . run time on two reference platform , namely an athlon 900 mhz and an hp pa 8600 processor , verify the finding",126,0.8
6943,Computers and IT,"This paper presents a program, GO 3D, for computing the fields of a transmitter in an indoor environment using geometrical optics. The program uses an ""image tree"" data structure to construct the images needed to compute all the rays carrying fields above a preset ""threshold"" value, no matter how many reflections are needed. The paper briefly describes the input file required to define wall construction, the floor plan, the transmitter, and the receiver locations. A case study consisting of a long corridor with a small room on one side is used to demonstrate the features of the GO 3D program","this paper present a program , go 3d , for compute the field of a transmitter in an indoor environment use geometrical optic . the program use an `` image tree '' data structure to construct the image need to compute all the ray carry field above a preset `` threshold '' value , no matter how many reflection be need . the paper briefly describe the input file require to define wall construction , the floor plan , the transmitter , and the receiver location . a case study consist of a long corridor with a small room on one side be use to demonstrate the feature of the go 3d program",100,0.363636364
6944,Computers and IT,"Flip is a solitaire board game produced by craft woodworkers. We analyze Flip and suggest modifications to the rules to make the game more marketable. In addition to being an interesting application of dynamic programming, this case shows the use of operations research in managerial decision making","flip be a solitaire board game produce by craft woodworker . we analyze flip and suggest modification to the rule to make the game more marketable . in addition to be an interesting application of dynamic programming , this case show the use of operation research in managerial decision make",47,0.833333333
6945,Computers and IT,"With over 30 years of academic experience in both engineering and management faculties, involving trial and error experimentation in teaching as well as reading relevant literature and observing other instructors in action, the author has accumulated a number of ideas, regarding the preparation and delivery of a university course, that should be of interest to other instructors. This should be particularly the case for those individuals who have had little or no teaching experience (e. g. those whose graduate education was recently completed at research-oriented institutions providing little guidance with respect to teaching). A particular perspective is used to convey the ideas, namely one of viewing the preparation and delivery of a course as two major processes that should provide outputs or outcomes that are of value to a number of customers, in particular, students","with over 30 year of academic experience in both engineering and management faculty , involve trial and error experimentation in teaching as well as read relevant literature and observe other instructor in action , the author have accumulate a number of idea , regard the preparation and delivery of a university course , that should be of interest to other instructor . this should be particularly the case for those individual who have have little or no teaching experience -LRB- e. g. those whose graduate education be recently complete at research-oriented institution provide little guidance with respect to teaching -RRB- . a particular perspective be use to convey the idea , namely one of view the preparation and delivery of a course as two major process that should provide output or outcome that be of value to a number of customer , in particular , student",135,0.5
6946,Computers and IT,This paper describes the implementation of the traditional PERT/CPM algorithm for finding the critical path in a project network in a spreadsheet. The problem is of importance due to the recent shift of attention to using the spreadsheet environment as a vehicle for delivering management science/operations research (MS/OR) techniques to end-users,this paper describe the implementation of the traditional pert/cpm algorithm for find the critical path in a project network in a spreadsheet . the problem be of importance due to the recent shift of attention to use the spreadsheet environment as a vehicle for deliver management science/operation research -LRB- ms/or -RRB- technique to end-user,51,0.5
6947,Computers and IT,This paper introduces an object-oriented version of SIMLIB (an easy-to-understand discrete-event simulation package). The object-oriented version is preferable to the original procedural language versions of SIMLIB in that it is easier to understand and teach simulation from an object point of view. A single-server queue simulation is demonstrated using the object-oriented SIMLIB,this paper introduce an object-oriented version of simlib -LRB- an easy-to-understand discrete-event simulation package -RRB- . the object-oriented version be preferable to the original procedural language version of simlib in that it be easy to understand and teach simulation from an object point of view . a single-serv queue simulation be demonstrate use the object-oriented simlib,52,1
6948,Computers and IT,In this paper we calculate the maximum expected value of perfect information (EVPI) for any probability distribution for the states of the world. This maximum EVPI is an upper bound for the EVPI with given probabilities and thus an upper bound for any partial information about the states of the world,in this paper we calculate the maximum expect value of perfect information -LRB- evpi -RRB- for any probability distribution for the state of the world . this maximum evpi be an upper bind for the evpi with give probability and thus an upper bind for any partial information about the state of the world,51,0.333333333
6949,Computers and IT,"This study investigates the problem of estimating camera calibration parameters from image motion fields induced by a rigidly moving camera with unknown parameters, where the image formation is modeled with a linear pinhole-camera model. The equations obtained show the flow to be separated into a component due to the translation and the calibration parameters and a component due to the rotation and the calibration parameters. A set of parameters encoding the latter component is linearly related to the flow, and from these parameters the calibration can be determined. However, as for discrete motion, in general it is not possible to decouple image measurements obtained from only two frames into translational and rotational components. Geometrically, the ambiguity takes the form of a part of the rotational component being parallel to the translational component, and thus the scene can be reconstructed only up to a projective transformation. In general, for full calibration at least four successive image frames are necessary, with the 3D rotation changing between the measurements. The geometric analysis gives rise to a direct self-calibration method that avoids computation of optical flow or point correspondences and uses only normal flow measurements. New constraints on the smoothness of the surfaces in view are formulated to relate structure and motion directly to image derivatives, and on the basis of these constraints the transformation of the viewing geometry between consecutive images is estimated. The calibration parameters are then estimated from the rotational components of several flow fields. As the proposed technique neither requires a special set up nor needs exact correspondence it is potentially useful for the calibration of active vision systems which have to acquire knowledge about their intrinsic parameters while they perform other tasks, or as a tool for analyzing image sequences in large video databases","this study investigate the problem of estimate camera calibration parameter from image motion field induce by a rigidly move camera with unknown parameter , where the image formation be model with a linear pinhole-camera model . the equation obtain show the flow to be separate into a component due to the translation and the calibration parameter and a component due to the rotation and the calibration parameter . a set of parameter encode the latter component be linearly relate to the flow , and from these parameter the calibration can be determine . however , as for discrete motion , in general it be not possible to decouple image measurement obtain from only two frame into translational and rotational component . geometrically , the ambiguity take the form of a part of the rotational component be parallel to the translational component , and thus the scene can be reconstruct only up to a projective transformation . in general , for full calibration at least four successive image frame be necessary , with the 3d rotation change between the measurement . the geometric analysis give rise to a direct self-calibration method that avoid computation of optical flow or point correspondence and use only normal flow measurement . new constraint on the smoothness of the surface in view be formulate to relate structure and motion directly to image derivative , and on the basis of these constraint the transformation of the view geometry between consecutive image be estimate . the calibration parameter be then estimate from the rotational component of several flow field . as the propose technique neither require a special set up nor need exact correspondence it be potentially useful for the calibration of active vision system which have to acquire knowledge about their intrinsic parameter while they perform other task , or as a tool for analyze image sequence in large video database",295,0.941176471
6950,Computers and IT,"This paper introduces a version of the internationally popular television game show Who Wants To Be A Millionaire(R) that has been created for use in the classroom using Microsoft PowerPoint(R). A suggested framework for its classroom use is presented, instructions on operating and editing the classroom version of Who Wants To Be A Millionaire(R) are provided, and sample feedback from students who have played the classroom version of Who Wants To Be A Millionaire(R) is offered","this paper introduce a version of the internationally popular television game show who want to be a millionaire -LRB- r -RRB- that have be create for use in the classroom use microsoft powerpoint -LRB- r -RRB- . a suggested framework for its classroom use be present , instruction on operating and editing the classroom version of who want to be a millionaire -LRB- r -RRB- be provide , and sample feedback from student who have play the classroom version of who want to be a millionaire -LRB- r -RRB- be offer",76,0.4
6951,Computers and IT,"Inspired by the popular television show ""Who Wants to Be a Millionaire?"", this case discusses the monetary decisions contestants face on a game consisting of 15 increasingly difficult multiple choice questions. Since the game continues as long as a contestant answers correctly, this case, at its core, is one of sequential decision analysis, amenable to analysis via stochastic dynamic programming. The case is also suitable for a course dealing with single decision analysis, allowing for discussion of utility theory and Bayesian probability revision. In developing a story line for the case, the author has sprinkled in much background material on probability and statistics. This material is placed in a historical context, illuminating some of the influential scholars involved in the development of these subjects as well as the birth of operations research and the management sciences","inspire by the popular television show `` who want to be a millionaire ? '' , this case discuss the monetary decision contestant face on a game consist of 15 increasingly difficult multiple choice question . since the game continue as long as a contestant answer correctly , this case , at its core , be one of sequential decision analysis , amenable to analysis via stochastic dynamic programming . the case be also suitable for a course deal with single decision analysis , allow for discussion of utility theory and bayesian probability revision . in develop a story line for the case , the author have sprinkle in much background material on probability and statistic . this material be place in a historical context , illuminate some of the influential scholar involve in the development of these subject as well as the birth of operation research and the management science",136,0.571428571
6952,Computers and IT,"As computers become ever faster, more and more procedures that were once viewed as iterative will continue to become instantaneous. The blitzogram is the application of this trend to histograms, which the author hopes will lead to a better tacit understanding of probability distributions among both students and managers. And this is not just an academic exercise. Commercial Monte Carlo simulation packages like @RISK and Crystal Ball, and my INSIGHT. xla are widely available","as computer become ever faster , more and more procedure that be once view as iterative will continue to become instantaneous . the blitzogram be the application of this trend to histogram , which the author hope will lead to a better tacit understanding of probability distribution among both student and manager . and this be not just an academic exercise . commercial monte carlo simulation package like @ risk and crystal ball , and my insight . xla be widely available",74,0.428571429
6953,Computers and IT,"The 1990s were a decade of enormous change for management science (MS) educators. While the outlook at the beginning of the decade was somewhat bleak, the renaissance in MS education brought about by the use of spreadsheets as the primary delivery vehicle for quantitative modeling techniques has resulted in a much brighter future. This paper takes inventory of the current state of MS education and suggests some promising new directions in the area of decision support systems for MS educators to consider for the future","the 1990s be a decade of enormous change for management science -LRB- m -RRB- educator . while the outlook at the beginning of the decade be somewhat bleak , the renaissance in m education bring about by the use of spreadsheet as the primary delivery vehicle for quantitative modeling technique have result in a much brighter future . this paper take inventory of the current state of m education and suggest some promising new direction in the area of decision support system for m educator to consider for the future",85,1
6954,Computers and IT,"This essay discusses how we can most effectively teach Management Science to students in MBA or similar programs who will be, at best, part-time practitioners of these arts. I take as a working hypothesis the radical proposition that the heart of Management Science itself is not the impressive array of tools that have been built up over the years (optimization, simulation, decision analysis, queuing, and so on) but rather the art of reasoning logically with formal models. I believe it is necessary with this group of students to teach basic modeling skills, and in fact it is only when such students have these basic skills as a foundation that they are prepared to acquire the more sophisticated skills needed to employ Management Science. In this paper I present a hierarchy of modeling skills, from numeracy skills through sophisticated Management Science skills, as a framework within which to plan courses for the occasional practitioner","this essay discuss how we can most effectively teach management science to student in mba or similar program who will be , at best , part-time practitioner of these art . i take as a work hypothesis the radical proposition that the heart of management science itself be not the impressive array of tool that have be build up over the year -LRB- optimization , simulation , decision analysis , queue , and so on -RRB- but rather the art of reasoning logically with formal model . i believe it be necessary with this group of student to teach basic modeling skill , and in fact it be only when such student have these basic skill as a foundation that they be prepare to acquire the more sophisticated skill need to employ management science . in this paper i present a hierarchy of modeling skill , from numeracy skill through sophisticated management science skill , as a framework within which to plan course for the occasional practitioner",153,1
6955,Computers and IT,"The business school management science course is suffering serious decline. The traditional model- and algorithm-based course fails to meet the needs of MBA programs and students. Poor student mathematical preparation is a reality, and is not an acceptable justification for poor teaching outcomes. Management science Ph. D. s are often poorly prepared to teach in a general management program, having more experience and interest in algorithms than management. The management science profession as a whole has focused its attention on algorithms and a narrow subset of management problems for which they are most applicable. In contrast, MBA's rarely encounter problems that are suitable for straightforward application of management science tools, living instead in a world where problems are ill-defined, data is scarce, time is short, politics is dominant, and rational ""decision makers"" are non-existent. The root cause of the profession's failure to address these issues seems to be (in Russell Ackoff's words) a habit of professional introversion that caused the profession to be uninterested in what MBA's really do on the job and how management science can help them","the business school management science course be suffer serious decline . the traditional model - and algorithm-based course fail to meet the need of mba program and student . poor student mathematical preparation be a reality , and be not an acceptable justification for poor teaching outcome . management science ph. d. s be often poorly prepare to teach in a general management program , have more experience and interest in algorithm than management . the management science profession as a whole have focus its attention on algorithm and a narrow subset of management problem for which they be most applicable . in contrast , mba 's rarely encounter problem that be suitable for straightforward application of management science tool , live instead in a world where problem be ill-defined , data be scarce , time be short , politics be dominant , and rational `` decision maker '' be non-existent . the root cause of the profession 's failure to address these issue seem to be -LRB- in russell ackoff 's word -RRB- a habit of professional introversion that cause the profession to be uninterested in what mba 's really do on the job and how management science can help them",179,0.8
6956,Computers and IT,"Gifts, by their altruistic nature, perfectly fit into the environment of universities and academic libraries. As a university's community and general public continue to donate materials, libraries accept donations willingly, both in-kind and monetary. Eight steps of gift processing are listed in the paper. Positive and negative aspects of gift acceptance are discussed. Gifts bring value for academic libraries. Gifts can be considered additional routes to contribute to library collections without direct purchases, options to add money to the library budget, and the cement of social relationships. But, unfortunately, large donations are time-consuming, labor-intensive and costly to process. Great amounts of staff time and processing space are two main negative aspects that cause concern and put the value of gift acceptance under consideration by librarians. Some strategies in handling gifts are recommended. To be effective, academic science librarians need to approach gifts as an investment. Librarians are not to be forced by moral and public notions and should be able to make professional decisions in evaluating proposed collections","gift , by their altruistic nature , perfectly fit into the environment of university and academic library . as a university 's community and general public continue to donate material , library accept donation willingly , both in-kind and monetary . eight step of gift processing be list in the paper . positive and negative aspect of gift acceptance be discuss . gift bring value for academic library . gift can be consider additional route to contribute to library collection without direct purchase , option to add money to the library budget , and the cement of social relationship . but , unfortunately , large donation be time-consuming , labor-intensive and costly to process . great amount of staff time and processing space be two main negative aspect that cause concern and put the value of gift acceptance under consideration by librarian . some strategy in handle gift be recommend . to be effective , academic science librarian need to approach gift as an investment . librarian be not to be force by moral and public notion and should be able to make professional decision in evaluate propose collection",168,0.636363636
6957,Computers and IT,"Fot pt. 1 see ibid. , p. 71-8 (2002). Data from the fifty-six titles examined qualitatively in the Patterson study are examined quantitatively. In addition to the four factors of edition, condition, dust jacket, and autograph that were hypothesized to influence the value of a book, four other factors for which information was available in the data were examined","fot pt . 1 see ibid . , p. 71-8 -LRB- 2002 -RRB- . data from the fifty-six title examine qualitatively in the patterson study be examine quantitatively . in addition to the four factor of edition , condition , dust jacket , and autograph that be hypothesize to influence the value of a book , four other factor for which information be available in the data be examine",59,0
6958,Computers and IT,"Four factors (edition, condition, dust jacket, and autograph) that are hypothesized to influence the value of books are identified and linked to basic economic principles, which are explained. A sample of fifty-six titles is qualitatively examined to test the hypothesis","four factor -LRB- edition , condition , dust jacket , and autograph -RRB- that be hypothesize to influence the value of book be identify and link to basic economic principle , which be explain . a sample of fifty-six title be qualitatively examine to test the hypothesis",40,0.25
6959,Computers and IT,"This article provides detailed advice on acquiring new, out-of-print, and rare materials in the history of science, technology, and medicine for the beginner in these fields. The focus is on the policy formation, basic reference tools, and methods of collection development and acquisitions that are the necessary basis for success in this endeavor","this article provide detailed advice on acquire new , out-of-print , and rare material in the history of science , technology , and medicine for the beginner in these field . the focus be on the policy formation , basic reference tool , and method of collection development and acquisition that be the necessary basis for success in this endeavor",53,0.7
6960,Computers and IT,"This paper is about automatically reconstructing the full 3D surface of an object observed in motion by a single static camera. Based on the two paradigms, structure from motion and linear intensity subspaces, we introduce the geotensity constraint that governs the relationship between four or more images of a moving object. We show that it is possible in theory to solve for 3D Lambertian surface structure for the case of a single point light source and propose that a solution exists for an arbitrary number point light sources. The surface may or may not be textured. We then give an example of automatic surface reconstruction of a face under a point light source using arbitrary unknown object motion and a single fixed camera","this paper be about automatically reconstruct the full 3d surface of an object observe in motion by a single static camera . base on the two paradigm , structure from motion and linear intensity subspace , we introduce the geotensity constraint that govern the relationship between four or more image of a move object . we show that it be possible in theory to solve for 3d lambertian surface structure for the case of a single point light source and propose that a solution exist for an arbitrary number point light source . the surface may or may not be textur . we then give an example of automatic surface reconstruction of a face under a point light source use arbitrary unknown object motion and a single fix camera",123,0.818181818
6961,Computers and IT,"A case study of a special collections department in a small academic library and how its collections have been acquired and developed over the years is described. It looks at the changes that have occurred in the academic environment and what effect, if any, these changes may have had on the department and how it has adapted to them. It raises questions about development and acquisitions policies and procedures","a case study of a special collection department in a small academic library and how its collection have be acquire and develop over the year be describe . it look at the change that have occur in the academic environment and what effect , if any , these change may have have on the department and how it have adapt to them . it raise question about development and acquisition policy and procedure",69,0.666666667
6962,Computers and IT,"This article presents basic acquisitions philosophy and approaches in a noted special collection, with commentary on ""just saying no"" and on how the electronic revolution has changed the acquisition of special collections materials","this article present basic acquisition philosophy and approach in a note special collection , with commentary on `` just say no '' and on how the electronic revolution have change the acquisition of special collection material",33,0.333333333
6963,Computers and IT,"A powerful encounter with underground poetry and its important role in poetry, literature, and culture is discussed. The acquisitions difficulties encountered in the unique publishing world of underground poetry are introduced. Strategies for acquiring underground poetry for library collections are proposed, including total immersion and local focus, with accompanying action","a powerful encounter with underground poetry and its important role in poetry , literature , and culture be discuss . the acquisition difficulty encounter in the unique publishing world of underground poetry be introduce . strategy for acquire underground poetry for library collection be propose , include total immersion and local focus , with accompany action",50,0.625
6964,Computers and IT,"The author refers to the comment made by Hanoch (see ibid. vol. 49 (2000)) on his model of bounded rationality and the role of the Yerkes-Dodson law and emotional arousal in it. The author points out that Hanoch's comment, however, conspicuously fails to challenge - much less contradict - the central hypothesis of his paper. In addition, several of Hanoch's criticisms are based on a wrong characterization of the positions","the author refer to the comment make by hanoch -LRB- see ibid . vol . 49 -LRB- 2000 -RRB- -RRB- on his model of bounded rationality and the role of the yerkes-dodson law and emotional arousal in it . the author point out that hanoch 's comment , however , conspicuously fail to challenge - much less contradict - the central hypothesis of his paper . in addition , several of hanoch 's criticism be base on a wrong characterization of the position",70,0.4
6965,Computers and IT,"Bruce Kaufman's article (1999), ""Emotional arousal as a source of bounded rationality"", objective is to present an additional source of bounded rationality, one that is not due to cognitive constraints, but to high emotional arousal. In doing so, Kaufman is following a long tradition of thinkers who have contrasted emotion with reason, claiming, for the most part, that emotions are a violent force hindering rational thinking. This paper aims to challenge Kaufman's unidimensional idea regarding the connection between high emotional arousal and decision making","bruce kaufman 's article -LRB- 1999 -RRB- , `` emotional arousal as a source of bounded rationality '' , objective be to present an additional source of bounded rationality , one that be not due to cognitive constraint , but to high emotional arousal . in do so , kaufman be follow a long tradition of thinker who have contrast emotion with reason , claim , for the most part , that emotion be a violent force hinder rational thinking . this paper aim to challenge kaufman 's unidimensional idea regard the connection between high emotional arousal and decision making",84,0.5
6966,Computers and IT,"A biology-based model of choice is used to examine time-inconsistent preferences and the problem of self-control. Emotion is shown to be the biological substrate of choice, in that emotional systems assign value to 'goods' in the environment and also facilitate the learning of expectations regarding alternative options for acquiring those goods. A third major function of the emotional choice systems is motivation. Self-control is shown to be the result of a problem with the inhibition of the motive force of emotion, where this inhibition is necessary for higher level deliberation","a biology-based model of choice be use to examine time-inconsistent preference and the problem of self-control . emotion be show to be the biological substrate of choice , in that emotional system assign value to ` good ' in the environment and also facilitate the learning of expectation regard alternative option for acquire those good . a third major function of the emotional choice system be motivation . self-control be show to be the result of a problem with the inhibition of the motive force of emotion , where this inhibition be necessary for high level deliberation",90,0.857142857
6967,Computers and IT,"Filson (2001) uses industry-level data on firm numbers, price, quantity and quality along with an equilibrium model of industry evolution to estimate the nature and effects of quality and cost improvements in the personal computer industry and four other new industries. This paper studies the personal computer industry in more detail and shows that the model explains some peculiar patterns that cannot be explained by previous life-cycle models. The model estimates are evaluated using historical studies of the evolution of the personal computer industry and patterns that require further model development are described","filson -LRB- 2001 -RRB- use industry-level data on firm number , price , quantity and quality along with an equilibrium model of industry evolution to estimate the nature and effect of quality and cost improvement in the personal computer industry and four other new industry . this paper study the personal computer industry in more detail and show that the model explain some peculiar pattern that can not be explain by previous life-cycle model . the model estimate be evaluate use historical study of the evolution of the personal computer industry and pattern that require further model development be describe",93,0.333333333
6968,Computers and IT,"Whilst there is substantial evidence that hyperbolic discounting models describe intertemporal preferences for monetary outcomes better than the discounted utility (DU) model, there is only very limited evidence in the context of health outcomes. This study elicits private and social intertemporal preferences for non-fatal changes in health. Specific functional forms of the DU model and three hyperbolic models are fitted. The results show that the stationarity axiom is violated, and that the hyperbolic models fit the data better than the DU model. Intertemporal preferences for private and social decisions are found to be very similar","whilst there be substantial evidence that hyperbolic discounting model describe intertemporal preference for monetary outcome better than the discounted utility -LRB- du -RRB- model , there be only very limited evidence in the context of health outcome . this study elicit private and social intertemporal preference for non-fatal change in health . specific functional form of the du model and three hyperbolic model be fit . the result show that the stationarity axiom be violate , and that the hyperbolic model fit the data better than the du model . intertemporal preference for private and social decision be find to be very similar",95,0.666666667
6969,Computers and IT,"A stylized French labor market is modeled as an endogenously evolving institution. Boundedly rational firms and individuals strive to decrease the cost or increase utility. The labor market is coordinated by a search process and decentralized setting of hiring standards, but intermediaries can speed up matching. The model reproduces the dynamics of the gross flows and spectacular changes in mobility patterns of some demographic groups when the oil crisis in the 1970's occurred, notably the sudden decline of the integration in good jobs. The internal labor markets of large firms are shown to increase unemployment if the secondary (temporary or bad) jobs do not exist","a stylize french labor market be model as an endogenously evolve institution . boundedly rational firm and individual strive to decrease the cost or increase utility . the labor market be coordinate by a search process and decentralize setting of hire standard , but intermediary can speed up matching . the model reproduce the dynamic of the gross flow and spectacular change in mobility pattern of some demographic group when the oil crisis in the 1970 's occur , notably the sudden decline of the integration in good job . the internal labor market of large firm be show to increase unemployment if the secondary -LRB- temporary or bad -RRB- job do not exist",105,0.666666667
6970,Computers and IT,"Empirical research on the organization of firms requires that firms be classified on the basis of their control structures. This should be done in a way that can potentially be made operational. It is easy to identify the ultimate controller of a hierarchical organization, and the literature has largely focused on this case. However, many organizational structures mix hierarchy with collective choice procedures such as voting, or use circular structures under which superiors are accountable to their subordinates. The author develops some analytic machinery that can be used to map the authority structures of such organizations, and show that under mild restrictions there is a well-defined ultimate control group. The results are consistent with intuitions about the nature of control in familiar economic settings","empirical research on the organization of firm require that firm be classify on the basis of their control structure . this should be do in a way that can potentially be make operational . it be easy to identify the ultimate controller of a hierarchical organization , and the literature have largely focus on this case . however , many organizational structure mix hierarchy with collective choice procedure such as voting , or use circular structure under which superior be accountable to their subordinate . the author develop some analytic machinery that can be use to map the authority structure of such organization , and show that under mild restriction there be a well-defined ultimate control group . the result be consistent with intuition about the nature of control in familiar economic setting",124,0.571428571
6971,Computers and IT,"It may be a bit strange to consider where the field of information architecture (IA) is headed. After all, many would argue that it's too new to be considered as a field at all, or that it is mislabeled, and by no means is there a widely accepted definition of what information architecture actually is. Practicing information architects probably number in the thousands, and this vibrant group is already building various forms of communal infrastructure, ranging from an IA journal and a self-organizing ""library"" of resources to a passel of local professional groups and degree-granting academic programs. So the profession has achieved a beachhead that will enable it to stabilize and perhaps even grow during these difficult times","it may be a bit strange to consider where the field of information architecture -LRB- ia -RRB- be head . after all , many would argue that it ' too new to be consider as a field at all , or that it be mislabel , and by no mean be there a widely accept definition of what information architecture actually be . practice information architect probably number in the thousand , and this vibrant group be already build various form of communal infrastructure , range from an ia journal and a self-organizing `` library '' of resource to a passel of local professional group and degree-granting academic program . so the profession have achieve a beachhead that will enable it to stabilize and perhaps even grow during these difficult time",118,1
6972,Computers and IT,"The paper is an attempt to raid both the literature on modular design and the literature on property rights to create the outlines of a modularity theory of the firm. Such a theory will look at firms, and other organizations, in terms of the partitioning of rights-understood as protected spheres of authority-among cooperating parties. It will assert that organizations reflect nonmodular structures, that is, structures in which decision rights, rights of alienation, and residual claims to income do not all reside in the same hands","the paper be an attempt to raid both the literature on modular design and the literature on property right to create the outline of a modularity theory of the firm . such a theory will look at firm , and other organization , in term of the partitioning of rights-understood as protected sphere of authority-among cooperate party . it will assert that organization reflect nonmodular structure , that be , structure in which decision right , right of alienation , and residual claim to income do not all reside in the same hand",85,0.818181818
6973,Computers and IT,"Creating an information architecture for a bilingual Web site presents particular challenges beyond those that exist for single and multilanguage sites. This article reports work in progress on the development of a content-based bilingual Web site to facilitate the sharing of resources and information between Speech and Language Therapists. The development of the information architecture is based on a combination of two aspects: an abstract structural analysis of existing bilingual Web designs focusing on the presentation of bilingual material, and a bilingual card-sorting activity conducted with potential users. Issues for bilingual developments are discussed, and some observations are made regarding the use of card-sorting activities","create an information architecture for a bilingual web site present particular challenge beyond those that exist for single and multilanguage site . this article report work in progress on the development of a content-based bilingual web site to facilitate the sharing of resource and information between speech and language therapist . the development of the information architecture be base on a combination of two aspect : an abstract structural analysis of exist bilingual web design focus on the presentation of bilingual material , and a bilingual card-sorting activity conduct with potential user . issue for bilingual development be discuss , and some observation be make regard the use of card-sorting activity",105,0.714285714
6974,Computers and IT,"A three-dimensional numerical simulation using the boundary element method is proposed, which can predict the cavity temperature distributions in the cooling stage of injection moulding. Then, choosing the radii and positions of cooling lines as design variables, the boundary integral sensitivity formulations are deduced. For the optimum design of cooling lines, the squared difference between the objective temperature and temperature of the cavity is taken as the objective function. Based on the optimization techniques with design sensitivity analysis, an iterative algorithm to reach the minimum value of the objective function is introduced, which leads to the optimum design of cooling lines at the same time","a three-dimensional numerical simulation use the boundary element method be propose , which can predict the cavity temperature distribution in the cool stage of injection moulding . then , choose the radius and position of cool line as design variable , the boundary integral sensitivity formulation be deduce . for the optimum design of cool line , the square difference between the objective temperature and temperature of the cavity be take as the objective function . base on the optimization technique with design sensitivity analysis , an iterative algorithm to reach the minimum value of the objective function be introduce , which lead to the optimum design of cool line at the same time",105,0.7
6975,Computers and IT,"This paper provides a methodology for managing safety and strategic stocks in materials requirements planning (MRP) environments to face uncertainty in market demand. A set of recommended guidelines suggest where to position, how to dimension and when to replenish both safety and strategic stocks. Trade-offs between stock positioning and dimensioning and between stock positioning and replenishment order triggering are outlined. The study reveals also that most of the decisions are system specific, so that they should be evaluated in a quantitative manner through simulation. A case study is reported, where the benefits from adopting the new proposed methodology lie in achieving the target service level even under peak demand conditions, with the value of safety stocks as a whole growing only by about 20 per cent","this paper provide a methodology for manage safety and strategic stock in material requirement plan -LRB- mrp -RRB- environment to face uncertainty in market demand . a set of recommend guideline suggest where to position , how to dimension and when to replenish both safety and strategic stock . trade-off between stock positioning and dimensioning and between stock positioning and replenishment order trigger be outline . the study reveal also that most of the decision be system specific , so that they should be evaluate in a quantitative manner through simulation . a case study be report , where the benefit from adopt the new propose methodology lie in achieve the target service level even under peak demand condition , with the value of safety stock as a whole grow only by about 20 per cent",126,0.7
6976,Computers and IT,"An innovative approach to the manufacture of impulse turbine blades using rapid prototyping, fused decomposition modelling (FDM), is presented. These blades were designed and manufactured by the Wave Energy Research Team (WERT) at the University of Limerick for the experimental analysis of a 0. 6 m impulse turbine with fixed guide vanes for wave energy power conversion. The computer aided design/manufacture (CAD/CAM) package Pro-Engineer 2000i was used for three-dimensional solid modelling of the individual blades. A detailed finite element analysis of the blades under centrifugal loads was performed using Pro-Mechanica. based on this analysis and FDM machine capabilities, blades were redesigned. Finally, Pro-E data were transferred to an FDM machine for the manufacture of turbine blades. The objective of this paper is to present the innovative method used to design, modify and manufacture blades in a time and cost effective manner using a concurrent engineering approach","an innovative approach to the manufacture of impulse turbine blade use rapid prototyping , fuse decomposition modelling -LRB- fdm -RRB- , be present . these blade be design and manufacture by the wave energy research team -LRB- wert -RRB- at the university of limerick for the experimental analysis of a 0 . 6 m impulse turbine with fix guide vane for wave energy power conversion . the computer aid design/manufacture -LRB- cad/cam -RRB- package pro-engineer 2000i be use for three-dimensional solid modelling of the individual blade . a detailed finite element analysis of the blade under centrifugal load be perform use pro-mechanica . base on this analysis and fdm machine capability , blade be redesign . finally , pro-e data be transfer to an fdm machine for the manufacture of turbine blade . the objective of this paper be to present the innovative method use to design , modify and manufacture blade in a time and cost effective manner use a concurrent engineering approach",146,0.8
6977,Computers and IT,"This paper deals with the evaluation of combined dispatching and routeing strategies on the performance of a flexible manufacturing system. Three routeing policies - no alternative routings, alternative routeing dynamics and alternative routeing plans - are considered with four dispatching rules with finite buffer capacity. In addition, the effect of changing part mix ratios is also discussed. The performance measures considered are makespan, average machine utilization, average flow time and average delay at local input buffers. Simulation results indicate that the alternative routings dynamic policy gives the best results in three performance measures except for average delay at local input buffers. Further, the effect of changing part mix ratios is not significant","this paper deal with the evaluation of combine dispatch and route strategy on the performance of a flexible manufacturing system . three route policy - no alternative routing , alternative route dynamic and alternative routeing plan - be consider with four dispatch rule with finite buffer capacity . in addition , the effect of change part mix ratio be also discuss . the performance measure consider be makespan , average machine utilization , average flow time and average delay at local input buffer . simulation result indicate that the alternative routing dynamic policy give the best result in three performance measure except for average delay at local input buffer . far , the effect of change part mix ratio be not significant",112,0.857142857
6978,Computers and IT,"This paper describes an intelligent fuzzy decision support system for real-time scheduling and dispatching of parts in a flexible manufacturing system (FMS), with alternative routing possibilities for all parts. A fuzzy logic approach is developed to improve the system performance by considering multiple performance measures and at multiple decision points. The characteristics of the system status, instead of parts, are fed back to assign priority to the parts waiting to be processed. A simulation model is developed and it is shown that the proposed intelligent fuzzy decision support system keeps all performance measures at a good level. The proposed intelligent system is a promising tool for dealing with scheduling FMSs, in contrast to traditional rules","this paper describe an intelligent fuzzy decision support system for real-time scheduling and dispatch of part in a flexible manufacturing system -LRB- fm -RRB- , with alternative rout possibility for all part . a fuzzy logic approach be develop to improve the system performance by consider multiple performance measure and at multiple decision point . the characteristic of the system status , instead of part , be feed back to assign priority to the part wait to be process . a simulation model be develop and it be show that the propose intelligent fuzzy decision support system keep all performance measure at a good level . the propose intelligent system be a promising tool for deal with scheduling fms , in contrast to traditional rule",115,0.75
6979,Computers and IT,"Presents a prototype object-oriented and rule-based system for product cost modelling and design for automation at an early design stage. The developed system comprises a computer aided design (CAD) solid modelling system, a material selection module, a knowledge-based system (KBS), a process optimization module, a design for assembly module, a cost estimation module and a user interface. Two manufacturing processes, namely machining and injection moulding processes, were considered in the developed system. The main function of the system, besides estimating the product cost, is to generate initial process planning, including the generation and selection of machining processes, their sequence and their machining parameters, and to recommend the most economical assembly technique for a product and provide design improvement suggestions based on a design feasibility technique. In addition, a feature-by-feature cost estimation report is generated using the proposed system to highlight the features of high manufacturing cost. Two case studies were used to validate the developed system","present a prototype object-oriented and rule-based system for product cost model and design for automation at an early design stage . the developed system comprise a computer aid design -LRB- cad -RRB- solid modelling system , a material selection module , a knowledge-based system -LRB- kbs -RRB- , a process optimization module , a design for assembly module , a cost estimation module and a user interface . two manufacture process , namely machining and injection moulding process , be consider in the developed system . the main function of the system , besides estimate the product cost , be to generate initial process planning , include the generation and selection of machining process , their sequence and their machining parameter , and to recommend the most economical assembly technique for a product and provide design improvement suggestion base on a design feasibility technique . in addition , a feature-by-feature cost estimation report be generate use the propose system to highlight the feature of high manufacturing cost . two case study be use to validate the developed system",156,0.631578947
6980,Computers and IT,"Presents experimental evidence for the existence of non-Euclidean contact geometry at the tool-chip interface in the machining of aluminium alloy, which challenges conventional assumptions. The geometry of contact at the tool rake face is modelled using fractals and a dimension is computed for its description. The variation in the fractal dimension with the cutting speed is explored","present experimental evidence for the existence of non-euclidean contact geometry at the tool-chip interface in the machining of aluminium alloy , which challenge conventional assumption . the geometry of contact at the tool rake face be model use fractal and a dimension be compute for its description . the variation in the fractal dimension with the cut speed be explore",57,0.777777778
6981,Computers and IT,"There is growing interest in additive and subtractive shaping theories that are synthesized to integrate the layered manufacturing process and material removal process. Layer-based machining has emerged as a promising method for integrated additive and subtractive shaping theory. In the paper, major layer-based machining systems are reviewed and compared according to characteristics of stock layers, numerical control machining configurations, stacking operations, input format and raw materials. Support structure, a major issue in machining-based systems which has seldom been addressed in previous research, is investigated in the paper with considerations of four situations: floating overhang, cantilever, vaulted overhang and ceiling. Except for the floating overhang where a support structure should not be overlooked, the necessity for support structures for the other three situations is determined by stress and deflection analysis. This is demonstrated by the machining of a large castle model","there be grow interest in additive and subtractive shape theory that be synthesize to integrate the layered manufacturing process and material removal process . layer-based machining have emerge as a promising method for integrate additive and subtractive shape theory . in the paper , major layer-based machining system be review and compare accord to characteristic of stock layer , numerical control machining configuration , stack operation , input format and raw material . support structure , a major issue in machining-based system which have seldom be address in previous research , be investigate in the paper with consideration of four situation : float overhang , cantilever , vault overhang and ceiling . except for the float overhang where a support structure should not be overlook , the necessity for support structure for the other three situation be determine by stress and deflection analysis . this be demonstrate by the machining of a large castle model",140,0.882352941
6982,Computers and IT,"In this paper, the author describes a battery energy storage system which is under construction to provide voltage compensation in support of Alaska's 138 kV Northern Intertie","in this paper , the author describe a battery energy storage system which be under construction to provide voltage compensation in support of alaska 's 138 kv northern intertie",27,0.428571429
6983,Computers and IT,"The parallel between designing a Web site and the construction of a building is a familiar one, but how often do we think of the Internet as having parks and streets? It would be absurd to say that the Internet could ever take the place of real, livable communities; however, it is safe to say that the context for using the Internet is on a path of change. As the Internet evolves beyond a simple linkage of disparate Web sites and applications, the challenge for Information Architects is establishing a process by which to structure, organize, and design networked environments. The principles that guide New Urbanism can offer much insight into networked electronic environment design. At the core of every New Urbanism principle is the idea of ""wholeness""-of making sure that neighborhoods and communities are knit together in a way that supports civic activities, economic development, efficient ecosystems, aesthetic beauty, and human interaction","the parallel between design a web site and the construction of a building be a familiar one , but how often do we think of the internet as have park and street ? it would be absurd to say that the internet could ever take the place of real , livable community ; however , it be safe to say that the context for use the internet be on a path of change . as the internet evolve beyond a simple linkage of disparate web site and application , the challenge for information architect be establish a process by which to structure , organize , and design network environment . the principle that guide new urbanism can offer much insight into networked electronic environment design . at the core of every new urbanism principle be the idea of `` wholeness '' - of make sure that neighborhood and community be knit together in a way that support civic activity , economic development , efficient ecosystem , aesthetic beauty , and human interaction",153,0.625
6984,Computers and IT,The authors present a novel all-optical logic NOR gate using two-cascaded semiconductor optical. amplifiers (SOAs) in a counterpropagating feedback configuration. This configuration accentuates the gain nonlinearity due to the mutual gain modulation of the two SOAs. The all-optical NOR gate feasibility has been demonstrated delivering an extinction ratio higher than 12 dB over a wide range of wavelength,the author present a novel all-optical logic nor gate use two-cascaded semiconductor optical . amplifier -LRB- soa -RRB- in a counterpropagating feedback configuration . this configuration accentuate the gain nonlinearity due to the mutual gain modulation of the two soa . the all-optical nor gate feasibility have be demonstrate deliver an extinction ratio high than 12 db over a wide range of wavelength,58,0.625
6985,Computers and IT,"X-ray computed tomography (CT) images of patients bearing metal intracavitary applicators or other metal foreign objects exhibit severe artifacts including streaks and aliasing. We have systematically evaluated via computer simulations the impact of scattered radiation, the polyenergetic spectrum, and measurement noise on the performance of three reconstruction algorithms: conventional filtered backprojection (FBP), deterministic iterative deblurring, and a new iterative algorithm, alternating minimization (AM), based on a CT detector model that includes noise, scatter, and polyenergetic spectra. Contrary to the dominant view of the literature, FBP streaking artifacts are due mostly to mismatches between FBP's simplified model of CT detector response and the physical process of signal acquisition. Artifacts on AM images are significantly mitigated as this algorithm substantially reduces detector-model mismatches. However, metal artifacts are reduced to acceptable levels only when prior knowledge of the metal object in the patient, including its pose, shape, and attenuation map, are used to constrain AM's iterations. AM image reconstruction, in combination with object-constrained CT to estimate the pose of metal objects in the patient, is a promising approach for effectively mitigating metal artifacts and making quantitative estimation of tissue attenuation coefficients a clinical possibility","x-ray computed tomography -LRB- ct -RRB- image of patient bear metal intracavitary applicator or other metal foreign object exhibit severe artifact include streak and alias . we have systematically evaluate via computer simulation the impact of scattered radiation , the polyenergetic spectrum , and measurement noise on the performance of three reconstruction algorithm : conventional filtered backprojection -LRB- fbp -RRB- , deterministic iterative deblurring , and a new iterative algorithm , alternate minimization -LRB- be -RRB- , base on a ct detector model that include noise , scatter , and polyenergetic spectrum . contrary to the dominant view of the literature , fbp streak artifact be due mostly to mismatch between fbp 's simplify model of ct detector response and the physical process of signal acquisition . artifact on be image be significantly mitigate as this algorithm substantially reduce detector-model mismatch . however , metal artifact be reduce to acceptable level only when prior knowledge of the metal object in the patient , include its pose , shape , and attenuation map , be use to constrain be 's iteration . be image reconstruction , in combination with object-constrained ct to estimate the pose of metal object in the patient , be a promising approach for effectively mitigate metal artifact and make quantitative estimation of tissue attenuation coefficient a clinical possibility",191,0.529411765
6986,Computers and IT,"Positron emission tomography (PET) provides important information on tumor biology, but lacks detailed anatomical information. Our aim in the present study was to develop and validate an automatic registration method for matching PET and CT scans of the head and neck. Three difficulties in achieving this goal are (1) nonrigid motions of the neck can hamper the use of automatic ridged body transformations; (2) emission scans contain too little anatomical information to apply standard image fusion methods; and (3) no objective way exists to quantify the quality of the match results. These problems are solved as follows: accurate and reproducible positioning of the patient was achieved by using a radiotherapy treatment mask. The proposed method makes use of the transmission rather than the emission scan. To obtain sufficient (anatomical) information for matching, two bed positions for the transmission scan were included in the protocol. A mutual information-based algorithm was used as a registration technique. PET and CT data were obtained in seven patients. Each patient had two CT scans and one PET scan. The datasets were used to estimate the consistency by matching PET to CT/sub 1/, CT/sub 1/ to CT/sub 2/, and CT/sub 2/ to PET using the full circle consistency test. It was found that using our method, consistency could be obtained of 4 mm and 1. 3 degrees on average. The PET voxels used for registration were 5. 15 mm, so the errors compared quite favorably with the voxel size. Cropping the images (removing the scanner bed from images) did not improve the consistency of the algorithm. The transmission scan, however, could potentially be reduced to a single position using this approach. In conclusion, the represented algorithm and validation technique has several features that are attractive from both theoretical and practical point of view, it is a user-independent, automatic validation technique for matching CT and PET scans of the head and neck, which gives the opportunity to compare different image enhancements","positron emission tomography -LRB- pet -RRB- provide important information on tumor biology , but lack detailed anatomical information . our aim in the present study be to develop and validate an automatic registration method for match pet and ct scan of the head and neck . three difficulty in achieve this goal be -LRB- 1 -RRB- nonrigid motion of the neck can hamper the use of automatic ridged body transformation ; -LRB- 2 -RRB- emission scan contain too little anatomical information to apply standard image fusion method ; and -LRB- 3 -RRB- no objective way exist to quantify the quality of the match result . these problem be solve as follow : accurate and reproducible positioning of the patient be achieve by use a radiotherapy treatment mask . the propose method make use of the transmission rather than the emission scan . to obtain sufficient -LRB- anatomical -RRB- information for match , two bed position for the transmission scan be include in the protocol . a mutual information-based algorithm be use as a registration technique . pet and ct data be obtain in seven patient . each patient have two ct scan and one pet scan . the dataset be use to estimate the consistency by match pet to ct/sub 1 / , ct/sub 1 / to ct/sub 2 / , and ct/sub 2 / to pet use the full circle consistency test . it be find that use our method , consistency could be obtain of 4 mm and 1 . 3 degree on average . the pet voxel use for registration be 5 . 15 mm , so the error compare quite favorably with the voxel size . crop the image -LRB- remove the scanner bed from image -RRB- do not improve the consistency of the algorithm . the transmission scan , however , could potentially be reduce to a single position use this approach . in conclusion , the represent algorithm and validation technique have several feature that be attractive from both theoretical and practical point of view , it be a user-independent , automatic validation technique for match ct and pet scan of the head and neck , which give the opportunity to compare different image enhancement",324,0.80952381
6987,Computers and IT,Bar code labels and wireless terminals linked to a centralized database accurately track meat products from receiving to customers for Farmland Foods,bar code label and wireless terminal link to a centralized database accurately track meat product from receive to customer for farmland food,22,0.5
6988,Computers and IT,"Potter and Anderson (1983) have developed a Bayesian decision procedure requiring the specification of a class of prior distributions restricted to have a minimal probability content for a given subset of the parameter space. They do not, however, provide a method for the selection of that subset. We show how a generalization of Gauss' inequality can be used to determine the relevant parameter subset","potter and anderson -LRB- 1983 -RRB- have develop a bayesian decision procedure require the specification of a class of prior distribution restrict to have a minimal probability content for a give subset of the parameter space . they do not , however , provide a method for the selection of that subset . we show how a generalization of gauss ' inequality can be use to determine the relevant parameter subset",64,0.571428571
6989,Computers and IT,"The essential feature of enzymatic reactions is a nonlinear dependency of reaction rate on metabolite concentration taking the form of saturation kinetics. Recently, it has been shown that this feature is associated with the phenomenon of ""loss of system coordination"" (Liu, 1999). In this paper, we study a system of ordinary differential equations representing a branched biochemical system of enzyme-mediated reactions. We show that this system can become very sensitive to changes in certain maximum enzyme activities. In particular, we show that the system exhibits three distinct responses: a unique, globally-stable steady-state, large amplitude oscillations, and asymptotically unbounded solutions, with the transition between these states being almost instantaneous. It is shown that the appearance of large amplitude, stable limit cycles occurs due to a ""false"" bifurcation or canard explosion. The subsequent disappearance of limit cycles corresponds to the collapse of the domain of attraction of the attracting set for the system and occurs due to a global bifurcation in the flow, namely, a saddle connection. Subsequently, almost all nonnegative data become unbounded under the action of the dynamical system and correspond exactly to loss of system coordination. We discuss the relevance of these results to the possible consequences of modulating such systems","the essential feature of enzymatic reaction be a nonlinear dependency of reaction rate on metabolite concentration take the form of saturation kinetics . recently , it have be show that this feature be associate with the phenomenon of `` loss of system coordination '' -LRB- liu , 1999 -RRB- . in this paper , we study a system of ordinary differential equation represent a branch biochemical system of enzyme-mediated reaction . we show that this system can become very sensitive to change in certain maximum enzyme activity . in particular , we show that the system exhibit three distinct response : a unique , globally-stable steady-state , large amplitude oscillation , and asymptotically unbounded solution , with the transition between these state be almost instantaneous . it be show that the appearance of large amplitude , stable limit cycle occur due to a `` false '' bifurcation or canard explosion . the subsequent disappearance of limit cycle correspond to the collapse of the domain of attraction of the attract set for the system and occur due to a global bifurcation in the flow , namely , a saddle connection . subsequently , almost all nonnegative data become unbounded under the action of the dynamical system and correspond exactly to loss of system coordination . we discuss the relevance of these result to the possible consequence of modulate such system",202,1
6990,Computers and IT,"This paper describes a methodology for simulating rainfall in dekads across a set of spatial units in areas where long-term meteorological records are available for a small number of sites only. The work forms part of a larger simulation model of the food system in a district of Zimbabwe, which includes a crop production component for yields of maize, small grains and groundnuts. Only a limited number of meteorological stations are available within or surrounding the district that have long time series of rainfall records. Preliminary analysis of rainfall data for these stations suggested that intra-seasonal temporal correlation was negligible, but that rainfall at any given station was correlated with rainfall at neighbouring stations. This spatial correlation structure can be modeled using a multivariate normal distribution consisting of 30 related variables, representing dekadly rainfall in each of the 30 wards. For each ward, log-transformed rainfall for each of the 36 dekads in the year was characterized by a mean and standard deviation, which were interpolated from surrounding meteorological stations. A covariance matrix derived from a distance measure was then used to represent the spatial correlation between wards. Sets of random numbers were then drawn from this distribution to simulate rainfall across the wards in any given dekad. Cross-validation of estimated rainfall parameters against observed parameters for the one meteorological station within the district suggests that the interpolation process works well. The methodology developed is useful in situations where long-term climatic records are scarce and where rainfall shows pronounced spatial correlation, but negligible temporal correlation","this paper describe a methodology for simulate rainfall in dekad across a set of spatial unit in area where long-term meteorological record be available for a small number of site only . the work form part of a large simulation model of the food system in a district of zimbabwe , which include a crop production component for yield of maize , small grain and groundnut . only a limited number of meteorological station be available within or surround the district that have long time series of rainfall record . preliminary analysis of rainfall data for these station suggest that intra-seasonal temporal correlation be negligible , but that rainfall at any give station be correlate with rainfall at neighbour station . this spatial correlation structure can be model use a multivariate normal distribution consist of 30 related variable , represent dekadly rainfall in each of the 30 ward . for each ward , log-transformed rainfall for each of the 36 dekad in the year be characterize by a mean and standard deviation , which be interpolate from surround meteorological station . a covariance matrix derive from a distance measure be then use to represent the spatial correlation between ward . set of random number be then draw from this distribution to simulate rainfall across the ward in any give dekad . cross-validation of estimate rainfall parameter against observed parameter for the one meteorological station within the district suggest that the interpolation process work well . the methodology develop be useful in situation where long-term climatic record be scarce and where rainfall show pronounced spatial correlation , but negligible temporal correlation",254,0.7
6991,Computers and IT,"Spanning tree enumeration in undirected graphs is an important issue and task in many problems encountered in computer network and circuit analysis. This paper discusses the spanning tree with flow for the case that there are flow requirements between each node pair. An algorithm based on minimal paths (MPs) is proposed to generate all spanning trees without flow. The proposed algorithm is a structured approach, which splits the system into structural MPs first, and also all steps in it are easy to follow","span tree enumeration in undirected graph be an important issue and task in many problem encounter in computer network and circuit analysis . this paper discuss the span tree with flow for the case that there be flow requirement between each node pair . an algorithm base on minimal path -LRB- mp -RRB- be propose to generate all span tree without flow . the propose algorithm be a structured approach , which split the system into structural mp first , and also all step in it be easy to follow",83,0.8
6992,Computers and IT,"In this paper, we first give a formal derivation of several systems of equations for injection moulding. This is done starting from the basic equations for nonisothermal, non-Newtonian flows in a three-dimensional domain. We derive systems for both (T/sup 0/, p/sup 0/) and (T/sup 1/, p/sup 1/) in the presence of body forces and sources. We find that body forces and sources have a nonlinear effect on the systems. We also derive a nonlinear ""Darcy law"". Our formulation includes not only the pressure gradient, but also body forces and sources, which play the role of a nonlinearity. Later, we prove the existence of weak solutions to certain boundary value problems and initial-boundary value problems associated with the resulting equations for (T/sup 0/, p/sup 0/) but in a more general mathematical setting","in this paper , we first give a formal derivation of several system of equation for injection moulding . this be do start from the basic equation for nonisothermal , non-newtonian flow in a three-dimensional domain . we derive system for both -LRB- t/sup 0 / , p/sup 0 / -RRB- and -LRB- t/sup 1 / , p/sup 1 / -RRB- in the presence of body force and source . we find that body force and source have a nonlinear effect on the system . we also derive a nonlinear `` darcy law '' . our formulation include not only the pressure gradient , but also body force and source , which play the role of a nonlinearity . later , we prove the existence of weak solution to certain boundary value problem and initial-boundary value problem associate with the result equation for -LRB- t/sup 0 / , p/sup 0 / -RRB- but in a more general mathematical setting",131,0.714285714
6993,Computers and IT,"An approach to analyzing the potential of a firm, which is understood as the firm's ability to provide goods or (and) services to be supplied to a marketplace under restrictions imposed by a business environment in which the firm functions, is proposed. The approach is based on using linear inequalities and, generally, mixed variables in modelling this ability for a broad spectrum of industrial, transportation, agricultural, and other types of firms and allows one to formulate problems of analyzing the potential of a firm as linear programming problems or mixed programming problems with linear constraints. This approach generalizes a previous one which was proposed for a more narrow class of models, and allows one to effectively employ a widely available software for solving practical problems of the considered kind, especially for firms described by large scale models of mathematical programming","an approach to analyze the potential of a firm , which be understand as the firm 's ability to provide good or -LRB- and -RRB- service to be supply to a marketplace under restriction impose by a business environment in which the firm function , be propose . the approach be base on use linear inequality and , generally , mixed variable in model this ability for a broad spectrum of industrial , transportation , agricultural , and other type of firm and allow one to formulate problem of analyze the potential of a firm as linear programming problem or mixed programming problem with linear constraint . this approach generalize a previous one which be propose for a more narrow class of model , and allow one to effectively employ a widely available software for solve practical problem of the consider kind , especially for firm describe by large scale model of mathematical programming",140,0.454545455
6994,Computers and IT,"Information interaction is the process that people use in interacting with the content of an information system. Information architecture is a blueprint and navigational aid to the content of information-rich systems. As such information architecture performs an important supporting role in information interactivity. This article elaborates on a model of information interactivity that crosses the ""no-man's land"" between user and computer articulating a model that includes user, content and system, illustrating the context for information architecture","information interaction be the process that people use in interact with the content of an information system . information architecture be a blueprint and navigational aid to the content of information-rich system . as such information architecture perform an important support role in information interactivity . this article elaborate on a model of information interactivity that cross the `` no-man 's land '' between user and computer articulate a model that include user , content and system , illustrate the context for information architecture",76,1
6995,Computers and IT,"The problem of adaptive robust stabilization for a class of linear time-varying systems with disturbance and nonlinear uncertainties is considered. The bounds of the disturbance and uncertainties are assumed to be unknown, being even arbitrary. For such uncertain dynamical systems, the adaptive robust state feedback controller is obtained. And the resulting closed-loop systems are asymptotically stable in theory. Moreover, an adaptive robust state feedback control scheme is given. The scheme ensures the closed-loop systems exponentially practically stable and can be used in practical engineering. Finally, simulations show that the control scheme is effective","the problem of adaptive robust stabilization for a class of linear time-varying system with disturbance and nonlinear uncertainty be consider . the bound of the disturbance and uncertainty be assume to be unknown , be even arbitrary . for such uncertain dynamical system , the adaptive robust state feedback controller be obtain . and the result closed-loop system be asymptotically stable in theory . moreover , an adaptive robust state feedback control scheme be give . the scheme ensure the closed-loop system exponentially practically stable and can be use in practical engineering . finally , simulation show that the control scheme be effective",93,0.6
6996,Computers and IT,"A generalization of the mathematical model and operations research problems formulated on its basis, which were presented by Belenky (2001) in the framework of an approach to planning an advertising campaign of goods and services, is considered, and corresponding nonlinear programming problems with linear constraints are formulated","a generalization of the mathematical model and operation research problem formulate on its basis , which be present by belenky -LRB- 2001 -RRB- in the framework of an approach to plan an advertising campaign of good and service , be consider , and corresponding nonlinear programming problem with linear constraint be formulate",47,0.6
6997,Computers and IT,"The novel design of an all-optical XOR gate by using cross-gain modulation of semiconductor optical amplifiers has been suggested and demonstrated successfully at 10 Gb/s. Boolean AB and AB of the two input signals A and B have been obtained and combined to achieve the all-optical XOR gate. No additional input beam such as a clock signal or continuous wave light is used in this new design, which is required in other all-optical XOR gates","the novel design of an all-optical xor gate by use cross-gain modulation of semiconductor optical amplifier have be suggest and demonstrate successfully at 10 gb/ . boolean ab and ab of the two input signal a and b have be obtain and combine to achieve the all-optical xor gate . no additional input beam such as a clock signal or continuous wave light be use in this new design , which be require in other all-optical xor gate",75,0.5
6998,Computers and IT,"Many people are now influenced by the information and advice they find on the Internet, much of it of dubious quality. This article describes two studies concerned with those factors capable of influencing people's response to online advice. The first study is a qualitative account of a group of house-hunters attempting to find worthwhile information online. The second study describes a survey of more than 2, 500 people who had actively sought advice over the Internet. A framework for understanding trust in online advice is proposed in which first impressions are distinguished from more detailed evaluations. Good Web design can influence the first process, but three key factors-source credibility, personalization, and predictability-are shown to predict whether people actually follow the advice given","many people be now influence by the information and advice they find on the internet , much of it of dubious quality . this article describe two study concern with those factor capable of influence people 's response to online advice . the first study be a qualitative account of a group of house-hunter attempt to find worthwhile information online . the second study describe a survey of more than 2 , 500 people who have actively seek advice over the internet . a framework for understand trust in online advice be propose in which first impression be distinguish from more detailed evaluation . good web design can influence the first process , but three key factors-source credibility , personalization , and predictability-are show to predict whether people actually follow the advice give",122,0.6
6999,Computers and IT,"Technology has always played a role in the development of gambling practices and continues to provide new market opportunities. One of the fastest growing areas is that of Internet gambling. The effect of such technologies should not be accepted uncritically, particularly as there may be areas of potential concern based on what is known about problem gambling offline. This article has three aims. First, it overviews some of the main social concerns about the rise of Internet gambling. Second, it looks at the limited research that has been carried out in this area. Third, it examines whether Internet gambling is doubly addictive, given research that suggests that the Internet can be addictive itself. It is concluded that technological developments in Internet gambling will increase the potential for problem gambling globally, but that many of the ideas and speculations outlined in this article need to be addressed further by large-scale empirical studies","technology have always play a role in the development of gamble practice and continue to provide new market opportunity . one of the fast grow area be that of internet gambling . the effect of such technology should not be accept uncritically , particularly as there may be area of potential concern base on what be know about problem gamble offline . this article have three aim . first , it overview some of the main social concern about the rise of internet gambling . second , it look at the limited research that have be carry out in this area . third , it examine whether internet gambling be doubly addictive , give research that suggest that the internet can be addictive itself . it be conclude that technological development in internet gambling will increase the potential for problem gamble globally , but that many of the idea and speculation outline in this article need to be address far by large-scale empirical study",151,0.428571429
7000,Computers and IT,"The use of intranets and e-mails to communicate with remote staff is increasing rapidly within organizations. For many companies this is viewed as a speedy and cost-effective way of keeping in contact with staff and ensuring their continuing commitment to company goals. This article highlights the problems experienced by staff when managers use intranets and e-mails in an inappropriate fashion for these purposes. Issues of remoteness and isolation are discussed, along with the reports of frustration and disidentification experienced. However, it will be shown that when used appropriately, communication using these technologies can facilitate shared understanding and help remote staff to view their company as alive and exciting. Theoretical aspects are highlighted and the implications of these findings are discussed","the use of intranet and e-mail to communicate with remote staff be increase rapidly within organization . for many company this be view as a speedy and cost-effective way of keep in contact with staff and ensure their continue commitment to company goal . this article highlight the problem experience by staff when manager use intranet and e-mail in an inappropriate fashion for these purpose . issue of remoteness and isolation be discuss , along with the report of frustration and disidentification experience . however , it will be show that when use appropriately , communication use these technology can facilitate share understanding and help remote staff to view their company as alive and exciting . theoretical aspect be highlight and the implication of these finding be discuss",120,0.8
7001,Computers and IT,"This article examines how the Internet transforms collective action. Current practices on the Web bear witness to thriving collective action ranging from persuasive to confrontational, individual to collective, undertakings. Even more influential than direct calls for action is the indirect mobilizing influence of the Internet's powers of mass communication, which is boosted by an antiauthoritarian ideology on the Web. Theoretically, collective action through the otherwise socially isolating computer is possible because people rely on internalized group memberships and social identities to achieve social involvement. Empirical evidence from an online survey among environmental activists and nonactivists confirms that online action is considered an equivalent alternative to offline action by activists and nonactivists alike. However, the Internet may slightly alter the motives underlying collective action and thereby alter the nature of collective action and social movements. Perhaps more fundamental is the reverse influence that successful collective action will have on the nature and function of the Internet","this article examine how the internet transform collective action . current practice on the web bear witness to thrive collective action range from persuasive to confrontational , individual to collective , undertaking . even more influential than direct call for action be the indirect mobilize influence of the internet 's power of mass communication , which be boost by an antiauthoritarian ideology on the web . theoretically , collective action through the otherwise socially isolate computer be possible because people rely on internalized group membership and social identity to achieve social involvement . empirical evidence from an online survey among environmental activist and nonactivist confirm that online action be consider an equivalent alternative to offline action by activist and nonactivist alike . however , the internet may slightly alter the motive underlie collective action and thereby alter the nature of collective action and social movement . perhaps more fundamental be the reverse influence that successful collective action will have on the nature and function of the internet",155,0.636363636
7002,Computers and IT,"Cases of identity deception on the Internet are not uncommon. Several cases of a revealed identity deception have been reported in the media. The authors examine a case of deception in an online community composed primarily of information technology professionals. In this case, an established community member (DF) invented a character (Nowheremom) whom he fell in love with and who was eventually killed in a tragic accident. When other members of the community eventually began to question Nowheremom's actual identity, DF admitted that he invented her. The discussion board was flooded with reactions to DF's revelation. The authors propose several explanations for the perpetration of identity deception, including psychiatric illness, identity play, and expressions of true self. They also analyze the reactions of community members and propose three related explanations (social identity, deviance, and norm violation) to account for their reactions. It is argued that virtual communities' reactions to such threatening events provide invaluable clues for the study of group processes on the Internet","case of identity deception on the internet be not uncommon . several case of a reveal identity deception have be report in the medium . the author examine a case of deception in an online community compose primarily of information technology professional . in this case , an establish community member -LRB- df -RRB- invent a character -LRB- nowheremom -RRB- whom he fall in love with and who be eventually kill in a tragic accident . when other member of the community eventually begin to question nowheremom 's actual identity , df admit that he invent her . the discussion board be flood with reaction to df 's revelation . the author propose several explanation for the perpetration of identity deception , include psychiatric illness , identity play , and expression of true self . they also analyze the reaction of community member and propose three related explanation -LRB- social identity , deviance , and norm violation -RRB- to account for their reaction . it be argue that virtual community ' reaction to such threatening event provide invaluable clue for the study of group process on the internet",164,0.636363636
7003,Computers and IT,"This article reports a study undertaken to investigate some of the social psychological processes underlying computer-supported group discussion in natural computer-mediated contexts. Based on the concept of deindividuation, it was hypothesized that personal identifiability and group identity would be important factors that affect the perceptions and behavior of members of computer-mediated groups. The degree of personal identifiability and the strength of group identity were manipulated across groups of geographically dispersed computer users who took part in e-mail discussions during a 2-week period. The results do not support the association between deindividuation and uninhibited behavior cited in much previous research. Instead, the data provide some support for a social identity perspective of computer-mediated communication, which explains the higher levels uninhibited in identifiable computer-mediated groups. However, predictions based on social identity theory regarding group polarization and group cohesion were not supported. Possible explanations for this are discussed and further research is suggested to resolve these discrepancies","this article report a study undertake to investigate some of the social psychological process underlie computer-supported group discussion in natural computer-mediated context . base on the concept of deindividuation , it be hypothesize that personal identifiability and group identity would be important factor that affect the perception and behavior of member of computer-mediated group . the degree of personal identifiability and the strength of group identity be manipulate across group of geographically disperse computer user who take part in e-mail discussion during a 2-week period . the result do not support the association between deindividuation and uninhibited behavior cite in much previous research . instead , the data provide some support for a social identity perspective of computer-mediated communication , which explain the high level uninhibit in identifiable computer-mediated group . however , prediction base on social identity theory regard group polarization and group cohesion be not support . possible explanation for this be discuss and further research be suggest to resolve these discrepancy",154,0.615384615
7004,Computers and IT,This article explores the viability of conducting longitudinal survey research using the Internet in samples exposed to trauma. A questionnaire battery assessing psychological adjustment following adverse life experiences was posted online. Participants who signed up to take part in the longitudinal aspect of the study were contacted 3 and 6 months after initial participation to complete the second and third waves of the research. Issues of data screening and sample attrition rates are considered and the demographic profiles and questionnaire scores of those who did and did not take part in the study during successive time points are compared. The results demonstrate that it is possible to conduct repeated measures survey research online and that the similarity in characteristics between those who do and do not take part during successive time points mirrors that found in traditional pencil-and-paper trauma surveys,this article explore the viability of conduct longitudinal survey research use the internet in sample expose to trauma . a questionnaire battery assess psychological adjustment follow adverse life experience be post online . participant who sign up to take part in the longitudinal aspect of the study be contact 3 and 6 month after initial participation to complete the second and third wave of the research . issue of data screen and sample attrition rate be consider and the demographic profile and questionnaire score of those who do and do not take part in the study during successive time point be compare . the result demonstrate that it be possible to conduct repeat measure survey research online and that the similarity in characteristic between those who do and do not take part during successive time point mirror that find in traditional pencil-and-pap trauma survey,140,0.7
7005,Computers and IT,"Internet-based psychological experimenting is presented as a method that needs careful consideration of a number of issues-from potential data corruption to revealing confidential information about participants. Ten issues are grouped into five areas of actions to be taken when developing an Internet experiment (dos) and five errors to be avoided (don'ts). Dos include: (a) utilizing dropout as a dependent variable, (b) the use of dropout to detect motivational confounding, (c) placement of questions for personal information, (d) using a collection of techniques, and (e) using Internet-based tools. Don'ts are about: (a) unprotected directories, (b) public access to confidential data, (c) revealing the experiment's structure, (d) ignoring the Internet's technical variance, and (e) improper use of form elements","internet-based psychological experiment be present as a method that need careful consideration of a number of issues-from potential data corruption to reveal confidential information about participant . ten issue be group into five area of action to be take when develop an internet experiment -LRB- dos -RRB- and five error to be avoid -LRB- do n't -RRB- . do include : -LRB- a -RRB- utilize dropout as a dependent variable , -LRB- b -RRB- the use of dropout to detect motivational confounding , -LRB- c -RRB- placement of question for personal information , -LRB- d -RRB- use a collection of technique , and -LRB- e -RRB- use internet-based tool . do n't be about : -LRB- a -RRB- unprotected directory , -LRB- b -RRB- public access to confidential data , -LRB- c -RRB- reveal the experiment 's structure , -LRB- d -RRB- ignore the internet 's technical variance , and -LRB- e -RRB- improper use of form element",117,0.6
7006,Computers and IT,"An information architecture that allows users to easily navigate through a system and quickly recover from mistakes is often defined as a highly usable system. But usability in systems design goes beyond a good interface and efficient navigation. In this article we describe two database systems in a law enforcement agency. One system is a legacy, text-based system with cumbersome navigation (RMS); the newer system is a graphical user interface with simplified navigation (CopNet). It is hypothesized that law enforcement users will evaluate CopNet higher than RMS, but experts of the older system will evaluate it higher than others will. We conducted two user studies. One study examined what users thought of RMS and CopNet, and compared RMS experts' evaluations with nonexperts. We found that all users evaluated CopNet as more effective, easier to use, and easier to navigate than RMS, and this was especially noticeable for users who were not experts with the older system. The second, follow-up study examined use behavior after CopNet was deployed some time later. The findings revealed that evaluations of CopNet were not associated with its use. If the newer system had a better interface and was easier to navigate than the older, legacy system, why were law enforcement personnel reluctant to switch? We discuss reasons why switching to a new system is difficult, especially for those who are most adept at using the older system. Implications for system design and usability are also discussed","an information architecture that allow user to easily navigate through a system and quickly recover from mistake be often define as a highly usable system . but usability in system design go beyond a good interface and efficient navigation . in this article we describe two database system in a law enforcement agency . one system be a legacy , text-based system with cumbersome navigation -LRB- rm -RRB- ; the new system be a graphical user interface with simplify navigation -LRB- copnet -RRB- . it be hypothesize that law enforcement user will evaluate copnet high than rm , but expert of the old system will evaluate it high than other will . we conduct two user study . one study examine what user think of rm and copnet , and compare rm expert ' evaluation with nonexpert . we find that all user evaluate copnet as more effective , easy to use , and easy to navigate than rm , and this be especially noticeable for user who be not expert with the old system . the second , follow-up study examine use behavior after copnet be deploy some time later . the finding reveal that evaluation of copnet be not associate with its use . if the new system have a better interface and be easy to navigate than the old , legacy system , why be law enforcement personnel reluctant to switch ? we discuss reason why switch to a new system be difficult , especially for those who be most adept at use the old system . implication for system design and usability be also discuss",241,0.875
7007,Computers and IT,"This article presents an overview of the way that the Internet is being used to assist psychological research and mediate psychological practice. It shows how psychologists are using the Internet to examine the interactions between people and computers, and highlights some of the ways that this research is important to the design and development of useable and acceptable computer systems. In particular, this introduction reviews the research presented at the International Conference on Psychology and the Internet held in the United Kingdom. The final part introduces the eight articles in this special edition. The articles are representative of the breadth of research being conducted on psychology and the Internet: there are two on methodological issues, three on group processes, one on organizational implications, and two on social implications of Internet use","this article present an overview of the way that the internet be be use to assist psychological research and mediate psychological practice . it show how psychologist be use the internet to examine the interaction between people and computer , and highlight some of the way that this research be important to the design and development of useable and acceptable computer system . in particular , this introduction review the research present at the international conference on psychology and the internet hold in the unite kingdom . the final part introduce the eight article in this special edition . the article be representative of the breadth of research be conduct on psychology and the internet : there be two on methodological issue , three on group process , one on organizational implication , and two on social implication of internet use",131,0.7
7008,Computers and IT,"Imaging dynamic changes in chlorophyll a fluorescence provides a valuable means with which to examine localised changes in photosynthetic function. Microscope-based systems provide excellent spatial resolution which allows the response of individual cells to be measured. However, such systems have a restricted depth of focus and, as leaves are inherently uneven, only a small proportion of each image at any given focal plane is in focus. In this report we describe the development of algorithms, specifically adapted for imaging chlorophyll fluorescence and photosynthetic function in living plant cells, which allow extended-focus images to be reconstructed from images taken in different focal planes. We describe how these procedures can be used to reconstruct images of chlorophyll fluorescence and calculated photosynthetic parameters, as well as producing a map of leaf topology. The robustness of this procedure is demonstrated using leaves from a number of different plant species","imaging dynamic change in chlorophyll a fluorescence provide a valuable mean with which to examine localized change in photosynthetic function . microscope-based system provide excellent spatial resolution which allow the response of individual cell to be measure . however , such system have a restrict depth of focus and , as leaf be inherently uneven , only a small proportion of each image at any give focal plane be in focus . in this report we describe the development of algorithm , specifically adapt for imaging chlorophyll fluorescence and photosynthetic function in living plant cell , which allow extended-focus image to be reconstruct from image take in different focal plane . we describe how these procedure can be use to reconstruct image of chlorophyll fluorescence and calculate photosynthetic parameter , as well as produce a map of leaf topology . the robustness of this procedure be demonstrate use leaf from a number of different plant specie",145,0.222222222
7009,Computers and IT,"Noise filtering is the subject of a voluminous literature in radio engineering. The methods of filtering require knowledge of the frequency response, which is usually unknown. D. W. Allan (see Proc. IEEE, vol. 54, no. 2, p. 221-30, 1966; IEEE Trans. Instr. Measur. , vol. IM-36, p. 646-54, 1987) proposed a simple method of determining the interval between equally accurate observations which does without this information. In this method, the variances of the increments of noise and signal are equal, so that, in observations with a greater step, the variations caused by noise are smaller than those caused by the signal. This method is the standard accepted by the USA metrology community. The present paper is devoted to a statistical analysis of the Allan method and acquisition of additional information","noise filter be the subject of a voluminous literature in radio engineering . the method of filter require knowledge of the frequency response , which be usually unknown . d. w. allan -LRB- see proc . ieee , vol . 54 , no. 2 , p. 221-30 , 1966 ; ieee tran . instr . measur . , vol . im-36 , p. 646-54 , 1987 -RRB- propose a simple method of determine the interval between equally accurate observation which do without this information . in this method , the variance of the increment of noise and signal be equal , so that , in observation with a great step , the variation cause by noise be small than those cause by the signal . this method be the standard accept by the usa metrology community . the present paper be devote to a statistical analysis of the allan method and acquisition of additional information",130,0.625
7010,Computers and IT,"The characteristics of the sliding mode that appears with using continuous convex-programming algorithms based on the exact penalty functions were discussed. For the case under study, the ideal sliding mode was shown to occur in the absence of infinite number of switchings","the characteristic of the slide mode that appear with use continuous convex-programming algorithm base on the exact penalty function be discuss . for the case under study , the ideal slide mode be show to occur in the absence of infinite number of switching",42,0.75
7011,Computers and IT,Basic features are set forth of the method for automation of the serviceability recovery of systems of complex structures in real time without the interruption of operation. Specific features of the method are revealed in an important example of the system of control of hardware components of ships,basic feature be set forth of the method for automation of the serviceability recovery of system of complex structure in real time without the interruption of operation . specific feature of the method be reveal in an important example of the system of control of hardware component of ship,48,0.6
7012,Computers and IT,A new method of operation of internal combustion engines enhances power and reduces fuel consumption and exhaust toxicity. Low-temperature plasma control combines working processes of thermal engines and steam machines into a single process,a new method of operation of internal combustion engine enhance power and reduce fuel consumption and exhaust toxicity . low-temperature plasma control combine work process of thermal engine and steam machine into a single process,34,0.875
7013,Computers and IT,The scalableness of resources is taken to mean the possibility of the prior change in the obtained dynamic characteristics of computational processes for a certain basic set of processors and the communication medium in an effort to optimize the dynamics of software applications. A method is put forward for the generation of optimal strategies-a set of the versions of the fulfillment of programs on the basis of a vector criterion. The method is urgent for the effective use of resources of computational clusters and metacomputational media and also for dynamic control of processes in real time on the basis of the static scaling,the scalablenes of resource be take to mean the possibility of the prior change in the obtain dynamic characteristic of computational process for a certain basic set of processor and the communication medium in an effort to optimize the dynamic of software application . a method be put forward for the generation of optimal strategies-a set of the version of the fulfillment of program on the basis of a vector criterion . the method be urgent for the effective use of resource of computational cluster and metacomputational medium and also for dynamic control of process in real time on the basis of the static scaling,103,0.818181818
7014,Computers and IT,"It is shown that an arbitrary grouped p-element permutation can be implemented in a conflict-free way through the commutation of channels on the double p-ary multiring or the double p-ary hypercube. It is revealed that in arbitrary single-element permutations, these commutators display the property of the (p-1)-nodal failure-tolerance and the generalized hypercube displays in addition the property of the (p-1)-channel failure-tolerance","it be show that an arbitrary group p-element permutation can be implement in a conflict-free way through the commutation of channel on the double p-ary multiring or the double p-ary hypercube . it be reveal that in arbitrary single-element permutation , these commutator display the property of the -LRB- p-1 -RRB- - nodal failure-tolerance and the generalize hypercube display in addition the property of the -LRB- p-1 -RRB- - channel failure-tolerance",61,0.75
7015,Computers and IT,A new concept of the characteristic function is defined. It matches cooperative games far better than the classical characteristic function and is useful in reducing the number of decisions that can be used as the unique solution of a game,a new concept of the characteristic function be define . it match cooperative game far better than the classical characteristic function and be useful in reduce the number of decision that can be use as the unique solution of a game,40,0.8
7016,Computers and IT,"The location of transport routes on a heterogeneous territory is studied. The network joins a given set of terminal points and a certain number of additional (branch) points. The problem is formulated, properties of the optimal solution for a. tree-like network, and the number of branch points are studied. A stepwise optimization algorithm for a. network with given adjacency matrix based on an algorithm for constructing minimal-cost routes is designed","the location of transport route on a heterogeneous territory be study . the network join a give set of terminal point and a certain number of additional -LRB- branch -RRB- point . the problem be formulate , property of the optimal solution for a. tree-like network , and the number of branch point be study . a stepwise optimization algorithm for a. network with give adjacency matrix base on an algorithm for construct minimal-cost route be design",70,0.875
7017,Computers and IT,"The paperless office is an idea whose time has come, and come, and come again. To see how pervasive computing applications might bring some substance to this dream, the author spoke recently with key managers and technologists at McKesson Corporation (San Francisco), a healthcare supplier, service, and technology company with US$50 billion in sales last year, and also at AvantGo (Hayward, Calif. ), a provider of mobile infrastructure software and services. For the past several years, McKesson has used mobility middleware developed by AvantGo to deploy major supply chain applications with thousands of pervasive clients and multiple servers that replace existing paper-based tracking systems. According to McKesson's managers, their system greatly reduced errors and associated costs caused by redelivery or loss of valuable products, giving McKesson a solid return on its investment","the paperless office be an idea whose time have come , and come , and come again . to see how pervasive computing application might bring some substance to this dream , the author speak recently with key manager and technologist at mckesson corporation -LRB- san francisco -RRB- , a healthcare supplier , service , and technology company with us $ 50 billion in sale last year , and also at avantgo -LRB- hayward , calif. -RRB- , a provider of mobile infrastructure software and service . for the past several year , mckesson have use mobility middleware develop by avantgo to deploy major supply chain application with thousand of pervasive client and multiple server that replace exist paper-based tracking system . accord to mckesson 's manager , their system greatly reduced error and associate cost cause by redelivery or loss of valuable product , give mckesson a solid return on its investment",132,0.5
7018,Computers and IT,"For active systems where the principal varies the agents' goal functions by adding to them appropriately weighted goal functions of other agents or a balanced system of inter-agent transfers, the paper formulated and solved the problems of control based on criteria and motivation. Linear active systems were considered by way of example","for active system where the principal vary the agent ' goal function by add to them appropriately weighted goal function of other agent or a balanced system of inter-agent transfer , the paper formulate and solve the problem of control base on criterion and motivation . linear active system be consider by way of example",52,0.6
7019,Computers and IT,"An important problem in designing technical systems under partial uncertainty of the initial physical, chemical, and technological data is the determination of a design in which the technical system is flexible, i. e. , its control system is capable of guaranteeing that the constraints hold even under changes in external and internal factors and application of fuzzy mathematical models in its design. Three flexibility problems, viz. , the flexibility of a technical system of given structure, structural flexibility of a technical system, and the optimal design guaranteeing the flexibility of a technical system, are studied. Two approaches to these problems are elaborated. Results of a computation experiment are given","an important problem in design technical system under partial uncertainty of the initial physical , chemical , and technological data be the determination of a design in which the technical system be flexible , i. e. , its control system be capable of guarantee that the constraint hold even under change in external and internal factor and application of fuzzy mathematical model in its design . three flexibility problem , viz . , the flexibility of a technical system of give structure , structural flexibility of a technical system , and the optimal design guarantee the flexibility of a technical system , be study . two approach to these problem be elaborate . result of a computation experiment be give",109,0.714285714
7020,Computers and IT,A fuzzy-logic adaptation algorithm is designed for adjusting the discreteness period of a control system for ensuring the stability and quality of control process with regard to the elastic structural vibrations of a deformable space vehicle. Its performance is verified by digital modeling of a discrete control system with two objects,a fuzzy-logic adaptation algorithm be design for adjust the discreteness period of a control system for ensure the stability and quality of control process with regard to the elastic structural vibration of a deformable space vehicle . its performance be verify by digital modeling of a discrete control system with two object,51,0.857142857
7021,Computers and IT,"New properties of finite-dimensional linear discrete-time systems under conical control constraints that are similar to the ""hidden convexity"" of continuous-time systems are studied",new property of finite-dimensional linear discrete-time system under conical control constraint that be similar to the `` hidden convexity '' of continuous-time system be study,23,0.5
7022,Computers and IT,"The sliding mode control systems (SMCS) for which the switching variable is designed independent of the initial conditions are known to be sensitive to parameter variations and extraneous disturbances during the reaching phase. For second order systems this drawback is eliminated by using the moving switching line technique where the switching line is initially designed to pass the initial conditions and is subsequently moved towards a predetermined switching line. In this paper, we make use of the above idea of moving switching line together with the reaching law approach to design a discrete output feedback sliding mode control. The main contributions of this work are such that we do not require to use system states as it makes use of only the output samples for designing the controller. and by using the moving switching line a low sensitivity system is obtained through shortening the reaching phase. Simulation results show that the fast output sampling feedback guarantees sliding motion similar to that obtained using state feedback","the slide mode control system -LRB- smc -RRB- for which the switch variable be design independent of the initial condition be know to be sensitive to parameter variation and extraneous disturbance during the reach phase . for second order system this drawback be eliminate by use the move switching line technique where the switching line be initially design to pass the initial condition and be subsequently move towards a predetermine switching line . in this paper , we make use of the above idea of move switch line together with the reach law approach to design a discrete output feedback slide mode control . the main contribution of this work be such that we do not require to use system state as it make use of only the output sample for design the controller . and by use the move switching line a low sensitivity system be obtain through shorten the reach phase . simulation result show that the fast output sample feedback guarantee slide motion similar to that obtain use state feedback",165,1
7023,Computers and IT,"The multidimensional stability domain of linear discrete systems is studied. Its configuration is determined from the parameters of its intersection with coordinate axes, coordinate planes, and certain auxiliary planes. Counterexamples for the discrete variant of the Kharitonov theorem are given","the multidimensional stability domain of linear discrete system be study . its configuration be determine from the parameter of its intersection with coordinate ax , coordinate plane , and certain auxiliary plane . counterexample for the discrete variant of the kharitonov theorem be give",40,0.5
7024,Computers and IT,"The probabilistic stability of the perturbed motion of a system with parameters under the action of a general Markov process is studied. The phase vector is assumed to experience random jumps when the structure the system suffers random jumps. Such a situation is encountered, for example, in the motion of a solid with random jumps in its mass. The mean-square stability of random-structure linear systems and stability. of nonlinear systems in the first approximation are studied. The applied approach is helpful in studying the asymptotic probabilistic stability and mean-square exponential stability of stochastic systems through the stability of the respective deterministic systems","the probabilistic stability of the perturb motion of a system with parameter under the action of a general markov process be study . the phase vector be assume to experience random jump when the structure the system suffer random jump . such a situation be encounter , for example , in the motion of a solid with random jump in its mass. the mean-square stability of random-structure linear system and stability . of nonlinear system in the first approximation be study . the applied approach be helpful in study the asymptotic probabilistic stability and mean-square exponential stability of stochastic system through the stability of the respective deterministic system",102,0.833333333
7025,Computers and IT,Sufficient conditions for the existence of an optimal control in a time-optimal control problem with fixed ends for a smooth nonlinear control system are formulated. The properties of this system for characterizing the optimal control switching points are studied,sufficient condition for the existence of an optimal control in a time-optimal control problem with fixed end for a smooth nonlinear control system be formulate . the property of this system for characterize the optimal control switch point be study,39,0.5
7026,Computers and IT,The class of solutions of the polynomial equations including their generalizations in the form of the Bezout matrix identities was constructed analytically using the technology of constructive system embedding. The structure of a solution depends on the number of steps of the Euclidean algorithm and is obtained explicitly by appropriate substitutions. Illustrative and descriptive examples are presented,the class of solution of the polynomial equation include their generalization in the form of the bezout matrix identity be construct analytically use the technology of constructive system embedding . the structure of a solution depend on the number of step of the euclidean algorithm and be obtain explicitly by appropriate substitution . illustrative and descriptive example be present,57,0.8
7027,Computers and IT,The terminal functional of a general control system is refined by studying an analogous problem for a variational system and regularization. A sequential refinement method is designed by combining the local approximation of the reachability set and reduction. The corresponding algorithm has relaxation properties. An illustrative example is given,the terminal functional of a general control system be refine by study an analogous problem for a variational system and regularization . a sequential refinement method be design by combine the local approximation of the reachability set and reduction . the corresponding algorithm have relaxation property . an illustrative example be give,49,0.6
7028,Computers and IT,"The problem of determining the independent constants for decomposition of the integration range of exponential functions was solved on the basis of a similar approach to polynomials. The constants obtained enable one to decompose the integration range in two so that the integrals over them are equal independently of the function parameters. For the nontrigonometrical polynomials of even functions, an alternative approach was presented","the problem of determine the independent constant for decomposition of the integration range of exponential function be solve on the basis of a similar approach to polynomial . the constant obtain enable one to decompose the integration range in two so that the integral over them be equal independently of the function parameter . for the nontrigonometrical polynomial of even function , an alternative approach be present",64,0.666666667
7029,Computers and IT,"The growing pressure to reduce the cost of electrical power in recent years has resulted in an enormous ""brain-drain"" within the power industry. A novel approach has been developed by Eskom to capture these skills before they are lost and to incorporate these into a computer-based programme called ""knowledge management""",the grow pressure to reduce the cost of electrical power in recent year have result in an enormous `` brain-drain '' within the power industry . a novel approach have be develop by eskom to capture these skill before they be lose and to incorporate these into a computer-based program call `` knowledge management '',50,0.555555556
7030,Computers and IT,Concerns generalized control problems without exact information. A method of constructing a minimal synchronizing sequence for a linear interval system over the field of real numbers is developed. This problem is reduced to a system of linear inequalities,concern generalize control problem without exact information . a method of construct a minimal synchronize sequence for a linear interval system over the field of real number be develop . this problem be reduce to a system of linear inequality,38,0.571428571
7031,Computers and IT,"A step-by-step approach to the diagnosis of the technical state of heat systems is stated. The class of physical defects is supplemented by the behavioral defects of objects, which are related to the disturbance of the modes of their operation. The implementation of the approach is illustrated by an example of the solution of a specific problem of the diagnosis of a closed heat consumption system","a step-by-step approach to the diagnosis of the technical state of heat system be state . the class of physical defect be supplement by the behavioral defect of object , which be relate to the disturbance of the mode of their operation . the implementation of the approach be illustrate by an example of the solution of a specific problem of the diagnosis of a closed heat consumption system",66,0
7032,Computers and IT,"an architecture For multiversion majority-redundant computer-aided control systems, systematization of adaptation methods that are stable to hardware and software failures, a method for estimating their reliability from an event graph model, and a method for selecting a standard architecture with regard for reliability requirements are studied","an architecture for multiversion majority-redundant computer-aided control system , systematization of adaptation method that be stable to hardware and software failure , a method for estimate their reliability from an event graph model , and a method for select a standard architecture with regard for reliability requirement be study",46,0.375
7033,Computers and IT,"For the multiring and hypercube, a method of conflictless realization of an arbitrary permutation of ""large"" data items that can be divided into many ""smaller"" data blocks was considered, and its high efficiency was demonstrated","for the multiring and hypercube , a method of conflictless realization of an arbitrary permutation of `` large '' data item that can be divide into many `` small '' data block be consider , and its high efficiency be demonstrate",35,0.4
7034,Computers and IT,"Linearization and planarization of the circuit models is pivotal to the submicron technologies. On the other hand, the characteristics of the VLSI circuits can be sometimes improved by using the multivalued components. It was shown that any l-level circuit based on the multivalued components is representable as an algebraic model based on l linear arithmetic polynomials mapped correspondingly into l decision diagrams that are linear and planar by nature. Complexity of representing a circuit as the linear decision diagram was estimated as O(G) with G for the number of multivalued components in the circuit. The results of testing the LinearDesignMV algorithm on circuits of more than 8000 LGSynth 93 multivalued components were presented","linearization and planarization of the circuit model be pivotal to the submicron technology . on the other hand , the characteristic of the vlsi circuit can be sometimes improve by use the multivalued component . it be show that any l-level circuit base on the multivalued component be representable as an algebraic model base on l linear arithmetic polynomial map correspondingly into l decision diagram that be linear and planar by nature . complexity of represent a circuit as the linear decision diagram be estimate as o -LRB- g -RRB- with g for the number of multivalued component in the circuit . the result of test the lineardesignmv algorithm on circuit of more than 8000 lgsynth 93 multivalu component be present",113,0.7
7035,Computers and IT,"The subject under discussion is a new approach to the problem of structural identification, which relies on the recognition of a decisive role of the human factor in the process of structural identification. Potential possibilities of the suggested approach are illustrated by the statement of a new mathematical problem of structural identification","the subject under discussion be a new approach to the problem of structural identification , which rely on the recognition of a decisive role of the human factor in the process of structural identification . potential possibility of the suggested approach be illustrate by the statement of a new mathematical problem of structural identification",52,0.5
7036,Computers and IT,"A method of determining a sequence of the best solutions to the problems of optimization on finite sets was proposed. Its complexity was estimated by a polynomial of the dimension of problem input, given number of sequence terms, and complexity of completing the design of the original extremal problem. The technique developed was applied to the typical problem of network reconstruction with the aim of increasing its throughput under restricted reconstruction costs","a method of determine a sequence of the best solution to the problem of optimization on finite set be propose . its complexity be estimate by a polynomial of the dimension of problem input , give number of sequence term , and complexity of complete the design of the original extremal problem . the technique develop be apply to the typical problem of network reconstruction with the aim of increase its throughput under restrict reconstruction cost",72,1
7037,Computers and IT,A control system consisting of an unstable continuous linear part and a pulse-frequency modulator in the feedback circuit is studied. Conditions for the boundedness of the solutions of the system under any initial data are determined,a control system consist of an unstable continuous linear part and a pulse-frequency modulator in the feedback circuit be study . condition for the boundedness of the solution of the system under any initial data be determine,36,0.285714286
7038,Computers and IT,"An upper estimate and an iterative ""restriction"" algorithm for the reachability set for determining the optimal control for a class of multistep control processes are designed",an upper estimate and an iterative `` restriction '' algorithm for the reachability set for determine the optimal control for a class of multistep control process be design,26,0.666666667
7039,Computers and IT,"A problem is considered for the construction of confidence sets for a random vector, the information on distribution parameters of which is incomplete. To obtain exact estimates and a detailed analysis of the problem, the notion is introduced of a generalized confidence set for a statistically indeterminate random vector. Properties of generalized confidence sets are studied. It is shown that the standard method of estimation, which relies on the unification of confidence sets, leads in many cases to wider confidence estimates. For a normally distributed random vector with an inaccurately known mean value, generalized confidence sets are built tip and the dependence of sizes of a generalized confidence set on the forms and parameters of a set of possible mean values is examined","a problem be consider for the construction of confidence set for a random vector , the information on distribution parameter of which be incomplete . to obtain exact estimate and a detailed analysis of the problem , the notion be introduce of a generalize confidence set for a statistically indeterminate random vector . property of generalize confidence set be study . it be show that the standard method of estimation , which rely on the unification of confidence set , lead in many case to wide confidence estimate . for a normally distribute random vector with an inaccurately know mean value , generalize confidence set be build tip and the dependence of size of a generalize confidence set on the form and parameter of a set of possible mean value be examine",123,1
7040,Computers and IT,"Fuzzy set theory deals with the vagueness of human thought. A major contribution of fuzzy set theory is its capability of representing vague knowledge. Fuzzy set theory is very practical when sufficient and reliable data isn't available. Information technology (IT) is the acquisition, processing, storage and dissemination of information in all its forms (auditory, pictorial, textual and numerical) through a combination of computers, telecommunication, networks and electronic devices. IT includes matters concerned with the furtherance of computer science and technology, design, development, installation and implementation of information systems and applications. In the paper, assuming that there are n independent variables and the regression function is linear, the possible levels of information technology (the sale levels of computer equipment) in Turkey are forecasted by using fuzzy linear regression. The independent variables assumed are the import level and the export level of computer equipment","fuzzy set theory deal with the vagueness of human thought . a major contribution of fuzzy set theory be its capability of represent vague knowledge . fuzzy set theory be very practical when sufficient and reliable data be n't available . information technology -LRB- it -RRB- be the acquisition , processing , storage and dissemination of information in all its form -LRB- auditory , pictorial , textual and numerical -RRB- through a combination of computer , telecommunication , network and electronic device . it include matter concern with the furtherance of computer science and technology , design , development , installation and implementation of information system and application . in the paper , assume that there be n independent variable and the regression function be linear , the possible level of information technology -LRB- the sale level of computer equipment -RRB- in turkey be forecast by use fuzzy linear regression . the independent variable assume be the import level and the export level of computer equipment",142,0.769230769
7041,Computers and IT,"For the non-cooperative games and the problems of accepting or rejecting a proposal, a new notion of equilibrium was proposed, its place among the known basic equilibria was established, and its application to the static and dynamic game problems was demonstrated","for the non-cooperative game and the problem of accept or reject a proposal , a new notion of equilibrium be propose , its place among the know basic equilibrium be establish , and its application to the static and dynamic game problem be demonstrate",41,0.25
7042,Computers and IT,"Two interrelated problems-design of the reduced observer of plant state separately and together with its control system-were considered from the standpoint of designing the multivariable linear systems from the desired matrix transfer functions. The matrix equations defining the entire constructive class of solutions of the posed problems were obtained using the system embedding technology. As was demonstrated, control based on the reduced observer is capable to provide the desired response to the control input, as well as the response to the nonzero initial conditions, only for the directly measurable part of the components of the state vector. An illustrative example was presented","two interrelated problems-design of the reduce observer of plant state separately and together with its control system-were consider from the standpoint of design the multivariable linear system from the desire matrix transfer function . the matrix equation define the entire constructive class of solution of the pose problem be obtain use the system embedding technology . as be demonstrate , control base on the reduce observer be capable to provide the desire response to the control input , as well as the response to the nonzero initial condition , only for the directly measurable part of the component of the state vector . an illustrative example be present",102,0.666666667
7043,Computers and IT,"Consideration was given to the spectral characteristics of the linear dynamic systems over a bounded time interval. Singular characteristics of standard dynamic blocks, transcendental characteristic equations, and partial spectra of the singular functions were studied. Relationship between the spectra under study and the classical frequency characteristic was demonstrated","consideration be give to the spectral characteristic of the linear dynamic system over a bounded time interval . singular characteristic of standard dynamic block , transcendental characteristic equation , and partial spectrum of the singular function be study . relationship between the spectrum under study and the classical frequency characteristic be demonstrate",48,1
7044,Computers and IT,"Science and technology could be revolutionized by quantum computers, but building them from solid-state devices will not be easy. The author outlines the challenges in scaling up the technology from lab experiments to practical devices","science and technology could be revolutionize by quantum computer , but build them from solid-state device will not be easy . the author outline the challenge in scale up the technology from lab experiment to practical device",35,1
7045,Computers and IT,The recent string of failures among dotcom companies has heightened fears of privacy abuse. What should happen to the names and addresses on a customer list if these details were obtained under a privacy policy which specified no disclosure to any third party? Should the personal data in the list be deemed to be an asset of a failing company which can be transferred to any future (third party) purchaser for its purposes? Or should the privacy policy take precedence over the commercial concerns of the purchaser?,the recent string of failure among dotcom company have heighten fear of privacy abuse . what should happen to the name and address on a customer list if these detail be obtain under a privacy policy which specify no disclosure to any third party ? should the personal data in the list be deem to be an asset of a fail company which can be transfer to any future -LRB- third party -RRB- purchaser for its purpose ? or should the privacy policy take precedence over the commercial concern of the purchaser ?,87,1
7046,Computers and IT,"NetSec 2002 took place in San Francisco, amid industry reflection on the balance to be struck between combatting cyber-terrorism and safeguarding civil liberties post-9. 11. The author reports on the punditry and the pedagogy at the CSI event, focusing on security in the enterprise","netsec 2002 take place in san francisco , amid industry reflection on the balance to be strike between combat cyber-terrorism and safeguard civil liberty post-9 . 11 . the author report on the punditry and the pedagogy at the csi event , focus on security in the enterprise",44,0.666666667
7047,Computers and IT,"This paper sets out a number of major questions and challenges which include: (a) just what is meant by `trusted' or `trustworthy' systems after 20 years of experience, or more likely, lack of business level experience, with the 'trusted computer system' criteria anyway; (b) does anyone really care about the adoption of international standards for computer system security evaluation by IT product and system manufacturers and suppliers (IS 15408) and, if so, how does it all relate to business risk management anyway (IS 17799); (c) with the explosion of adoption of the microcomputer and personal computer some 20 years ago, has the industry abandoned all that it learnt about security during the `mainframe era'; or - `whatever happened to MULTICS' and its lessons; (d) has education kept up with security requirements by industry and government alike in the need for safe and secure operation of large scale and networked information systems on national and international bases, particularly where Web or Internet-based information services are being proposed as the major `next best thing' in the IT industry; (e) has the `fourth generation' of computer professionals inherited the spirit of information systems management and control that resided by necessity with the last `generation', the professionals who developed and created the applications for shared mainframe and minicomputer systems?","this paper set out a number of major question and challenge which include : -LRB- a -RRB- just what be mean by ` trust ' or ` trustworthy ' system after 20 year of experience , or more likely , lack of business level experience , with the ` trust computer system ' criterion anyway ; -LRB- b -RRB- do anyone really care about the adoption of international standard for computer system security evaluation by it product and system manufacturer and supplier -LRB- be 15408 -RRB- and , if so , how do it all relate to business risk management anyway -LRB- be 17799 -RRB- ; -LRB- c -RRB- with the explosion of adoption of the microcomputer and personal computer some 20 year ago , have the industry abandon all that it learn about security during the ` mainframe era ' ; or - ` whatever happen to multic ' and its lesson ; -LRB- d -RRB- have education keep up with security requirement by industry and government alike in the need for safe and secure operation of large scale and networked information system on national and international base , particularly where web or internet-based information service be be propose as the major ` next best thing ' in the it industry ; -LRB- e -RRB- have the ` fourth generation ' of computer professional inherit the spirit of information system management and control that reside by necessity with the last ` generation ' , the professional who develop and create the application for share mainframe and minicomputer system ?",215,0.578947368
7048,Computers and IT,"JPEG files do not contain any executable code and it is impossible to infect such files. The author takes a look at the details surrounding the Win32. Perrun virus and make clear exactly what it does. The main virus feature is its ability to affect JPEG image files (compressed graphic images) and to spread via affected JPEG files. The virus affects, or modifies, or alters JPEG files but does not ""infect"" them","jpeg file do not contain any executable code and it be impossible to infect such file . the author take a look at the detail surround the win32 . perrun virus and make clear exactly what it do . the main virus feature be its ability to affect jpeg image file -LRB- compress graphic image -RRB- and to spread via affected jpeg file . the virus affect , or modify , or alter jpeg file but do not `` infect '' them",72,1
7049,Computers and IT,"One of the most important information security controls, is the information security policy. This vital direction-giving document is, however, not always easy to develop and the authors thereof battle with questions such as what constitutes a policy. This results in the policy authors turning to existing sources for guidance. One of these sources is the various international information security standards. These standards are a good starting point for determining what the information security policy should consist of, but should not be relied upon exclusively for guidance. Firstly, they are not comprehensive in their coverage and furthermore, tending to rather address the processes needed for successfully implementing the information security policy. It is far more important the information security policy must fit in with the organisation's culture and must therefore be developed with this in mind","one of the most important information security control , be the information security policy . this vital direction-giving document be , however , not always easy to develop and the author thereof battle with question such as what constitute a policy . this result in the policy author turn to exist source for guidance . one of these source be the various international information security standard . these standard be a good start point for determine what the information security policy should consist of , but should not be rely upon exclusively for guidance . firstly , they be not comprehensive in their coverage and furthermore , tend to rather address the process need for successfully implement the information security policy . it be far more important the information security policy must fit in with the organisation 's culture and must therefore be develop with this in mind",135,1
7050,Computers and IT,"Of the more pervasive problems in any kind of security event is how the security event is managed from the inception to the end. There's a lot written about how to manage a specific incident or how to deal with a point problem such as a firewall log, but little tends to be written about how to deal with the management of a security event as part of corporate crisis management. This article discusses the basics of security crisis management and of the logical steps required to ensure that a security crisis does not get out of hand","of the more pervasive problem in any kind of security event be how the security event be manage from the inception to the end . there ' a lot write about how to manage a specific incident or how to deal with a point problem such as a firewall log , but little tend to be write about how to deal with the management of a security event as part of corporate crisis management . this article discuss the basic of security crisis management and of the logical step require to ensure that a security crisis do not get out of hand",98,1
7051,Computers and IT,"This paper focuses on the technological change in the high-end computing market. The discussion combines historical analysis with strategic analysis to provide a framework to analyse a key component of the computer industry. This analysis begins from the perspective of government research and development spending; then examines the confusion around the evolution of the high-end computing market in the context of standard theories of technology strategy and new product innovation. Rather than the high-end market being 'dead', one should view the market as changing due to increased capability and competition from the low-end personal computer market. The high-end market is also responding to new product innovation from the introduction of new parallel computing architectures. In the conclusion, key leverage points in the market are identified and the trends in high-end computing are highlighted with implications","this paper focus on the technological change in the high-end computing market . the discussion combine historical analysis with strategic analysis to provide a framework to analyze a key component of the computer industry . this analysis begin from the perspective of government research and development spending ; then examine the confusion around the evolution of the high-end computing market in the context of standard theory of technology strategy and new product innovation . rather than the high-end market be ` dead ' , one should view the market as change due to increase capability and competition from the low-end personal computer market . the high-end market be also respond to new product innovation from the introduction of new parallel computing architecture . in the conclusion , key leverage point in the market be identify and the trend in high-end computing be highlight with implication",135,0.769230769
7052,Computers and IT,"In the past few years the data center market has changed dramatically, forcing many companies into consolidation or bankruptcy. Gone are the days when companies raised millions of dollars to acquire large industrial buildings and transform them into glittering, high-tech palaces filled with the latest telecommunication and data technology. Whereas manufacturers of communication technology deliver the racked equipment in these, often mission-critical, facilities, ABB focuses mainly on the building infrastructure. Besides the very important redundant power supply, ABB also provides the redundant air conditioning and the security system","in the past few year the data center market have change dramatically , force many company into consolidation or bankruptcy . go be the day when company raise million of dollar to acquire large industrial building and transform them into glittering , high-tech palace fill with the late telecommunication and data technology . whereas manufacturer of communication technology deliver the rack equipment in these , often mission-critical , facility , abb focus mainly on the building infrastructure . besides the very important redundant power supply , abb also provide the redundant air conditioning and the security system",88,0.416666667
7053,Computers and IT,"ABB has taken a close look at how buildings are used and has come up with a radical solution for the technical infrastructure that places the end-user's processes at the center and integrates all the building's systems around their needs. The new solution is based on the realization that tasks like setting up an office meeting, registering a hotel guest or moving a patient in a hospital, can all benefit from the same Industrial IT concepts employed by ABB to optimize manufacturing, for example in the automotive industry","abb have take a close look at how building be use and have come up with a radical solution for the technical infrastructure that place the end-user 's process at the center and integrate all the building 's system around their need . the new solution be base on the realization that task like set up an office meeting , register a hotel guest or move a patient in a hospital , can all benefit from the same industrial it concept employ by abb to optimize manufacturing , for example in the automotive industry",88,0.5
7054,Computers and IT,"A sales force in Latin America, the design department in Europe, and production in Asia? Arrangements of this kind are the new business reality for today's global manufacturing companies. But how are such global operations to be effectively coordinated? ABB's answer was to develop and implement a new platform for high-performance, real-time collaboration. Globally distributed engineering teams can now work together, regardless of time, location or the CAD system they use, making ABB easier to do business with, for customers as well as suppliers","a sale force in latin america , the design department in europe , and production in asia ? arrangement of this kind be the new business reality for today 's global manufacturing company . but how be such global operation to be effectively coordinate ? abb 's answer be to develop and implement a new platform for high-performance , real-time collaboration . globally distribute engineering team can now work together , regardless of time , location or the cad system they use , make abb easy to do business with , for customer as well as supplier",84,0.625
7055,Computers and IT,"Spot welding, machine tending, material handling, picking, packing, painting, palletizing, assembly. . . the list of tasks being performed by ABB robots keeps on growing. Adding to this portfolio is a new robot containerization system (RCS) that ABB developed specifically for the United States Postal Service (USPS). The RCS has brought new levels of speed, accuracy, efficiency and productivity to the process of sorting and containerizing mail and packages. Recently, the 100th ABB RCS was installed at the USPS processing and distribution center in Columbus, Ohio","spot welding , machine tend , material handling , pick , packing , painting , palletiz , assembly ... the list of task be perform by abb robot keep on grow . add to this portfolio be a new robot containerization system -LRB- rc -RRB- that abb develop specifically for the unite state postal service -LRB- usps -RRB- . the rc have bring new level of speed , accuracy , efficiency and productivity to the process of sort and containerize mail and package . recently , the 100th abb rc be instal at the usps processing and distribution center in columbus , ohio",86,0.285714286
7056,Computers and IT,"As robots have gained more and more 'humanlike' capability, users have looked increasingly to their builders for ways to measure the critical variables-the robotic equivalent of a physical check-up-in order to monitor their condition and schedule maintenance more effectively. This is all the more essential considering the tremendous pressure there is to improve productivity in today's global markets. Developed for ABB robots with an S4-family controller and based on the company's broad process know-how, Optimize/sup IT/ robot condition monitoring offers maintenance routines with embedded checklists that give a clear indication of a robot's operating condition. It performs semi-automatic measurements that support engineers during trouble-shooting and enable action to be taken to prevent unplanned stops. By comparing these measurements with reference data, negative trends can be detected early and potential breakdowns predicted. Armed with all these features, Optimize/sup IT/ robot condition monitoring provides the ideal basis for reliability-centered maintenance (RCM) for robots","as robot have gain more and more ` humanlike ' capability , user have look increasingly to their builder for way to measure the critical variables-the robotic equivalent of a physical check-up-in order to monitor their condition and schedule maintenance more effectively . this be all the more essential consider the tremendous pressure there be to improve productivity in today 's global market . develop for abb robot with an s4-family controller and base on the company 's broad process know-how , optimize/sup it / robot condition monitor offer maintenance routin with embed checklist that give a clear indication of a robot 's operating condition . it perform semi-automatic measurement that support engineer during trouble-shooting and enable action to be take to prevent unplanned stop . by compare these measurement with reference data , negative trend can be detect early and potential breakdown predict . arm with all these feature , optimize/sup it / robot condition monitoring provide the ideal basis for reliability-centered maintenance -LRB- rcm -RRB- for robot",151,0.714285714
7057,Computers and IT,"Just looking through a car's windshield doesn't give us much reason to wonder about how it's made. The idea that special manufacturing expertise might be required can hardly occur to anyone, but that's exactly what is needed to ensure crystal-clear visibility, not to mention a perfect fit every time one is pressed into place on a car production line. Comprising two thin glass sheets joined by a vinyl interlayer, windshields are assembled-usually manually-to very precise product and environmental specifications. To make sure this is done as perfectly as possible, the industry invests heavily in the equipment used for their fabrication. ABB has now developed a robot-based Compact Assembling System for the automatic assembly of laminated windshields that speeds up production and increases cost efficiency","just look through a car 's windshield do n't give us much reason to wonder about how it ' make . the idea that special manufacturing expertise might be require can hardly occur to anyone , but that ' exactly what be need to ensure crystal-clear visibility , not to mention a perfect fit every time one be press into place on a car production line . comprise two thin glass sheet join by a vinyl interlayer , windshield be assembled-usually manually-to very precise product and environmental specification . to make sure this be do as perfectly as possible , the industry invest heavily in the equipment use for their fabrication . abb have now develop a robot-based compact assemble system for the automatic assembly of laminated windshield that speed up production and increase cost efficiency",124,0.625
7058,Computers and IT,"Setting up a robot to make metal cabinets or cases for desktop computers can be a complex operation. For instance, one expert might be required to carry out a feasibility study, and then another to actually program the robot. Understandably, the need for so much expertise, and the time that's required, generally limits the usefulness of automation to high-volume production. Workshops producing parts in batches smaller than 50 or so, or which rely heavily on semiskilled operators, are therefore often discouraged from investing in automation, and so miss out on its many advantages. What is needed is a software tool that operators without special knowledge of robotics, or with no more than rudimentary CAD skills, can use. One which allows easy offline programming and simulation of the work cell on a PC","set up a robot to make metal cabinet or case for desktop computer can be a complex operation . for instance , one expert might be require to carry out a feasibility study , and then another to actually program the robot . understandably , the need for so much expertise , and the time that ' require , generally limit the usefulness of automation to high-volume production . workshop produce part in batch small than 50 or so , or which rely heavily on semiskilled operator , be therefore often discourage from invest in automation , and so miss out on its many advantage . what be need be a software tool that operator without special knowledge of robotics , or with no more than rudimentary cad skill , can use . one which allow easy offline programming and simulation of the work cell on a pc",132,0.555555556
7059,Computers and IT,"Globalization of the world's markets is challenging the traditional limits of manufacturing efficiency. The competitive advantage belongs to those who understand the new requirements and opportunities, and who commit to integrated solutions that span the value chain all the way from demand to production. ABB's automation and IT expertise and the process know-how gained from its long involvement with the automotive industry, have been brought together in new, state-of-the-art software solutions for press shops. Integrated into Industrial IT architecture, they allow the full potential of the shops to be realized, with advantages at every step in the supply chain","globalization of the world 's market be challenge the traditional limit of manufacture efficiency . the competitive advantage belong to those who understand the new requirement and opportunity , and who commit to integrate solution that span the value chain all the way from demand to production . abb 's automation and it expertise and the process know-how gain from its long involvement with the automotive industry , have be bring together in new , state-of-the-art software solution for press shop . integrate into industrial it architecture , they allow the full potential of the shop to be realize , with advantage at every step in the supply chain",99,0.666666667
7060,Computers and IT,"Customer satisfaction and a focus on core competencies have dominated the thinking of a whole host of industries in recent years. However, one outcome, the outsourcing of noncore activities, has made the production of goods-from order entry to final delivery-more and more complex. Suppliers, subsuppliers, producers and customers are therefore busy adopting a new, more collaborative approach. This is mainly taking the form of order-driven planning and scheduling of production, but it is also being steered by a need to reduce inventories and working capital as well as a desire to increase throughput and optimize production","customer satisfaction and a focus on core competency have dominate the thinking of a whole host of industry in recent year . however , one outcome , the outsourcing of noncore activity , have make the production of goods-from order entry to final delivery-more and more complex . supplier , subsupplier , producer and customer be therefore busy adopt a new , more collaborative approach . this be mainly take the form of order-driven planning and scheduling of production , but it be also be steer by a need to reduce inventory and work capital as well as a desire to increase throughput and optimize production",96,0.333333333
7061,Computers and IT,"The decision to acquire a new information technology poses a number of serious evaluation and selection problems to technology managers, because the new system must not only meet current information requirements of the organisation, but also the needs for future expansion. Tangible and intangible benefits factors, as well as risks factors, must be identified and evaluated. The paper provides a review of ten major evaluation categories and available models, which fall under each category, showing their advantages and disadvantages in handling the above difficulties. This paper describes strategic implications involved in the selection decision, and the inherent difficulties in: (1) choosing or developing a model, (2) obtaining realistic inputs for the model, and (3) making tradeoffs among the conflicting factors. It proposes a conceptual framework to help the decision maker in choosing the most appropriate methodology in the evaluation process. It also offers a new model, called GAHP, for the evaluation problem combining integer goal linear programming and analytic hierarchy process (AHP) in a single hybrid multiple objective multi-criteria model. A goal programming methodology, with zero-one integer variables and mixed integer constraints, is used to set goal target values against which information technology alternatives are evaluated and selected. AHP is used to structure the evaluation process providing pairwise comparison mechanisms to quantify subjective, nonmonetary, intangible benefits and risks factors, in deriving data for the model. A case illustration is provided showing how GAHP can be formulated and solved","the decision to acquire a new information technology pose a number of serious evaluation and selection problem to technology manager , because the new system must not only meet current information requirement of the organization , but also the need for future expansion . tangible and intangible benefit factor , as well as risk factor , must be identify and evaluate . the paper provide a review of ten major evaluation category and available model , which fall under each category , show their advantage and disadvantage in handle the above difficulty . this paper describe strategic implication involve in the selection decision , and the inherent difficulty in : -LRB- 1 -RRB- choose or develop a model , -LRB- 2 -RRB- obtain realistic input for the model , and -LRB- 3 -RRB- make tradeoff among the conflict factor . it propose a conceptual framework to help the decision maker in choose the most appropriate methodology in the evaluation process . it also offer a new model , call gahp , for the evaluation problem combine integer goal linear programming and analytic hierarchy process -LRB- ahp -RRB- in a single hybrid multiple objective multi-criteria model . a goal programming methodology , with zero-one integer variable and mixed integer constraint , be use to set goal target value against which information technology alternative be evaluate and select . ahp be use to structure the evaluation process provide pairwise comparison mechanism to quantify subjective , nonmonetary , intangible benefit and risk factor , in derive data for the model . a case illustration be provide show how gahp can be formulate and solve",238,0.842105263
7062,Computers and IT,"Over 50 years ago, the 100, 000 workers at Ford's Rouge automobile factory turned out 1200 cars per day. Nowadays, Ford's plant on that same site still produces 800 cars each day but with just 3000 workers. Similar stories abound in the manufacturing industries; technology revolution and evolution; a shift from vertical integration, better business and production practices and improved industrial relations-all have changed manufacturing beyond recognition. So what are the current challenges and trends in manufacturing? Certainly, the relentless advance of technology will continue, as will user pressure for more customized design or improved environmental friendliness. Some trends are already with us and more, as yet indiscernible, will come. But one major, fundamental shift now resounding throughout industry is the way in which information involving every single aspect of the manufacturing process is being integrated into one seamless system","over 50 year ago , the 100 , 000 worker at ford 's rouge automobile factory turn out 1200 car per day . nowadays , ford 's plant on that same site still produce 800 car each day but with just 3000 worker . similar story abound in the manufacturing industry ; technology revolution and evolution ; a shift from vertical integration , better business and production practice and improve industrial relations-all have change manufacture beyond recognition . so what be the current challenge and trend in manufacturing ? certainly , the relentless advance of technology will continue , as will user pressure for more customize design or improve environmental friendliness . some trend be already with us and more , as yet indiscernible , will come . but one major , fundamental shift now resounding throughout industry be the way in which information involve every single aspect of the manufacturing process be be integrate into one seamless system",140,0.6
7063,Computers and IT,"Let L be one of the intuitionistic modal logics. As in the classical modal case, we define two different forms of the Beth property for L, which are denoted by B1 and B2; in this paper we study the relation among B1, B2 and the interpolation properties C1 and C2. It turns out that C1 implies B1, but contrary to the boolean case, is not equivalent to B1. It is shown that B2 and C2 are independent, and moreover it comes out that, in contrast to classical case, there exists an extension of the intuitionistic modal logic of S/sub 4/-type, that has not the property B2. Finally we give two algebraic properties, that characterize respectively B1 and B2","let l be one of the intuitionistic modal logic . as in the classical modal case , we define two different form of the beth property for l , which be denote by b1 and b2 ; in this paper we study the relation among b1 , b2 and the interpolation property c1 and c2 . it turn out that c1 imply b1 , but contrary to the boolean case , be not equivalent to b1 . it be show that b2 and c2 be independent , and moreover it come out that , in contrast to classical case , there exist an extension of the intuitionistic modal logic of s/sub 4 / - type , that have not the property b2 . finally we give two algebraic property , that characterize respectively b1 and b2",118,1
7064,Computers and IT,"We construct Boolean algebras with prescribed behaviour concerning depth for the free product of two Boolean algebras over a third, in ZFC using pcf; assuming squares we get results on ultraproducts. We also deal with the family of cardinalities and topological density of homomorphic images of Boolean algebras (you can translate it to topology-on the cardinalities of closed subspaces); and lastly we deal with inequalities between cardinal invariants, mainly d(B)/sup kappa //sup kappa /V Depth(B)or=log(|B|)","we construct boolean algebra with prescribed behavior concern depth for the free product of two boolean algebra over a third , in zfc use pcf ; assume square we get result on ultraproduct . we also deal with the family of cardinality and topological density of homomorphic image of boolean algebra -LRB- you can translate it to topology-on the cardinality of closed subspace -RRB- ; and lastly we deal with inequality between cardinal invariant , mainly d -LRB- b -RRB- / sup kappa / / sup kappa / v depth -LRB- b -RRB- or = log -LRB- b -RRB-",75,0.857142857
7065,Computers and IT,"Professional services firms have traditionally been able to thrive in virtually any market conditions. They have been consistently successful for several decades without ever needing to reexamine or change their basic operating model. However, gradual but inexorable change in client expectations and the business environment over recent years now means that more of the same is no longer enough. In future, law firms will increasingly need to exploit IT more effectively in order to remain competitive. To do this, they will need to ensure that all their information systems function as an integrated whole and are available to their staff, clients and business partners. The authors set out the lessons to be learned for law firms in the light of the recent PA Consulting survey","professional service firm have traditionally be able to thrive in virtually any market condition . they have be consistently successful for several decade without ever need to reexamine or change their basic operating model . however , gradual but inexorable change in client expectation and the business environment over recent year now mean that more of the same be no longer enough . in future , law firm will increasingly need to exploit it more effectively in order to remain competitive . to do this , they will need to ensure that all their information system function as an integrate whole and be available to their staff , client and business partner . the author set out the lesson to be learn for law firm in the light of the recent pa consult survey",125,1
7066,Computers and IT,"Whilst the market may be having a crisis of confidence regarding the prospects for e-commerce, the EU and the Government continue apace to develop the legal framework. Most recently, this has resulted in the Electronic Signatures Regulations 2002. These Regulations were made on 13 February 2002 and came into force on 8 March 2002. The Regulations implement the European Electronic Signatures Directive (1999/93/EC). Critics may say that the Regulations were implemented too late (they were due to have been implemented by 19 July 2001), with too short a consultation period (25 January 2002 to 12 February 2002) and with an unconvincing case as to what they add to English law (as to which, read on). The author explains the latest development on e-signatures and the significance of Certification Service Providers (CSPs)","whilst the market may be have a crisis of confidence regard the prospect for e-commerce , the eu and the government continue apace to develop the legal framework . most recently , this have result in the electronic signature regulation 2002 . these regulation be make on 13 february 2002 and come into force on 8 march 2002 . the regulation implement the european electronic signature directive -LRB- 1999/93/ec -RRB- . critic may say that the regulation be implement too late -LRB- they be due to have be implement by 19 july 2001 -RRB- , with too short a consultation period -LRB- 25 january 2002 to 12 february 2002 -RRB- and with an unconvincing case as to what they add to english law -LRB- as to which , read on -RRB- . the author explain the late development on e-signature and the significance of certification service provider -LRB- csp -RRB-",131,1
7067,Computers and IT,"In the first case of its kind, Naomi Campbell successfully sued Mirror Group Newspapers for damage and distress caused by breach of the Data Protection Act 1998. Partner N. Wildish and assistant M. Turle of City law firm Field Fisher Waterhouse discuss the case and the legal implications of which online publishers should be aware","in the first case of its kind , naomi campbell successfully sue mirror group newspaper for damage and distress cause by breach of the data protection act 1998 . partner n. wildish and assistant m. turle of city law firm field fisher waterhouse discuss the case and the legal implication of which online publisher should be aware",55,0.8
7068,Computers and IT,"On 20 May 2002, Mr Justice Pumfrey gave judgment in the case of (1) Reed Executive Plc (2) Reed Solutions Plc versus (1) Reed Business Information Limited (2) Reed Elsevier (UK) Limited (3) totaljobs. com Limited. The case explored for the first time in any detail the extent to which the use of various optimisation techniques for Web sites could give rise to new forms of trade mark infringement and passing off. The author reports on the case and offers his comments","on 20 may 2002 , mr justice pumfrey give judgment in the case of -LRB- 1 -RRB- re executive plc -LRB- 2 -RRB- re solution plc versus -LRB- 1 -RRB- re business information limit -LRB- 2 -RRB- re elsevi -LRB- uk -RRB- limited -LRB- 3 -RRB- totaljob . com limit . the case explore for the first time in any detail the extent to which the use of various optimisation technique for web site could give rise to new form of trade mark infringement and pass off . the author report on the case and offer his comment",82,0.666666667
7069,Computers and IT,The European Commission has formally tabled a draft Directive on the Protection by Patents of Computer-Implemented Inventions. The aim of this very important Directive is to harmonise national patent laws relating to inventions using software. It follows an extensive consultation launched by the Commission in October 2000. The impetus behind the Directive was the recognition at EU level of a total lack of unity between the European Patent Office and European national courts in deciding what was or was not deemed patentable when it came to the subject of computer programs,the european commission have formally table a draft directive on the protection by patent of computer-implemented invention . the aim of this very important directive be to harmonise national patent law relate to invention use software . it follow an extensive consultation launch by the commission in october 2000 . the impetus behind the directive be the recognition at eu level of a total lack of unity between the european patent office and european national court in decide what be or be not deem patentable when it come to the subject of computer program,91,0.875
7070,Computers and IT,"The author looks at a recent case and questions the Court of Appeal's approach. In the author's submission, the Court of Appeal's decision in Perrin was wrong. P published no material in England and Wales, and should not have been convicted of any offence under English law, even if it were proved that he sought to attract English subscribers to his site. That may be an unpalatable conclusion but, if the content of foreign-hosted Internet sites is to be controlled, the only sensible way forward is through international agreement and cooperation. The Council of Europe's Cybercrime Convention provides some indication of the limited areas over which widespread international agreement might be achieved","the author look at a recent case and question the court of appeal 's approach . in the author 's submission , the court of appeal 's decision in perrin be wrong . p publish no material in england and wale , and should not have be convict of any offence under english law , even if it be prove that he seek to attract english subscriber to his site . that may be an unpalatable conclusion but , if the content of foreign-hosted internet site be to be control , the only sensible way forward be through international agreement and cooperation . the council of europe 's cybercrime convention provide some indication of the limited area over which widespread international agreement might be achieve",112,0.75
7071,Computers and IT,"The author provides an introduction to the main issues surrounding E-government modernisation and electronic delivery of all public services by 2005. The author makes it clear that E-government is about transformation, not computers and hints at the special legal issues which may arise","the author provide an introduction to the main issue surround e-government modernisation and electronic delivery of all public service by 2005 . the author make it clear that e-government be about transformation , not computer and hint at the special legal issue which may arise",43,1
7072,Computers and IT,"A new computer program is developed based on the T-matrix method to generate a large number of total (extinction) cross sections (TCS) values of the realistic raindrops that are deformed due to a balance of the forces that act on a drop failing under gravity, and were described in shape by Pruppacher and Pitter (1971). These data for various dimensions of the raindrops (mean effective radius from 0 to 3. 25 mm), frequencies (10 to 80 GHz), (horizontal and vertical) polarizations, and temperatures (0, 10 and 20 degrees C) are stored to establish a data bank. Furthermore, a curve fitting technique, i. e. , interpolation of order 3, is implemented for the TCS values in the data bank. Therefore, the interpolated TCS results can be obtained readily from the interpolation process with negligible or even null computational time and efforts. Error analysis is carried out to show the high accuracy of the present analysis and applicability of the interpolation. At three operating frequencies of 15, 21. 225, and 38 GHz locally used in Singapore, some new TCS values are obtained from the new fast and efficient interpolation with a good accuracy","a new computer program be develop base on the t-matrix method to generate a large number of total -LRB- extinction -RRB- cross section -LRB- tc -RRB- value of the realistic raindrop that be deform due to a balance of the force that act on a drop fail under gravity , and be describe in shape by pruppacher and pitter -LRB- 1971 -RRB- . these data for various dimension of the raindrop -LRB- mean effective radius from 0 to 3 . 25 mm -RRB- , frequency -LRB- 10 to 80 ghz -RRB- , -LRB- horizontal and vertical -RRB- polarization , and temperature -LRB- 0 , 10 and 20 degree c -RRB- be store to establish a data bank . furthermore , a curve fitting technique , i. e. , interpolation of order 3 , be implement for the tc value in the data bank . therefore , the interpolated tc result can be obtain readily from the interpolation process with negligible or even null computational time and effort . error analysis be carry out to show the high accuracy of the present analysis and applicability of the interpolation . at three operate frequency of 15 , 21 . 225 , and 38 ghz locally use in singapore , some new tc value be obtain from the new fast and efficient interpolation with a good accuracy",191,0.464285714
7073,Computers and IT,"For original paper see ibid. , vol. 12, no. 6: ""The E-mail of the Species"". The author responds to that paper and argues that printing, scanning and imaging E-mails or other electronic (rather than paper) documents prior to listing and disclosure seems to be unnecessary, not 'proportionate' (from a costs point of view) and not particularly helpful, to either side. He asks how litigation support systems might evolve to help and support the legal team in their task","for original paper see ibid . , vol . 12 , no. 6 : `` the e-mail of the specie '' . the author respond to that paper and argue that printing , scan and imaging e-mail or other electronic -LRB- rather than paper -RRB- document prior to listing and disclosure seem to be unnecessary , not ` proportionate ' -LRB- from a cost point of view -RRB- and not particularly helpful , to either side . he ask how litigation support system might evolve to help and support the legal team in their task",78,1
7074,Computers and IT,"Having espoused the principle of the paperless office some time ago, we decided to apply it to our stored files. First we consulted the Law Society rules governing storage of files on electronic media. The next step was for us to draw up a protocol for scanning the files. The benefits of the exercise have been significant. The area previously used for storage has been freed for other use. Files are now available online, instantaneously. When we have needed to send out files to the client or following a change of solicitor, we have been able to do so almost immediately, by E-mail, retaining a copy for our future reference. The files are protected from loss or deterioration, back-up copies having been taken which are stored off site. The complete stored file archive can be put in your pocket (in CD-ROM format) or on a laptop, facilitating remote working","have espouse the principle of the paperless office some time ago , we decide to apply it to our store file . first we consult the law society rule govern storage of file on electronic medium . the next step be for us to draw up a protocol for scan the file . the benefit of the exercise have be significant . the area previously use for storage have be free for other use . file be now available online , instantaneously . when we have need to send out file to the client or follow a change of solicitor , we have be able to do so almost immediately , by e-mail , retain a copy for our future reference . the file be protect from loss or deterioration , back-up copy have be take which be store off site . the complete store file archive can be put in your pocket -LRB- in cd-rom format -RRB- or on a laptop , facilitate remote working",149,0.571428571
7075,Computers and IT,"With HM Land Registry's consultation now underway, no one denies that the property industry is facing a period of unprecedented change. PISCES (Property Information Systems Common Exchange) is a property-focused electronic data exchange standard. The standard is a set of definitions and rules to facilitate electronic transfer of data between key business areas and between different types of software packages that are used regularly by the property industry. It is not itself a piece of software but an enabling technology that allows software providers to prepare solutions within their own packages to transfer data between databases. This provides the attractive prospect of seamless transfer of data within and between systems and organisations","with hm land registry 's consultation now underway , no one deny that the property industry be face a period of unprecedented change . pisces -LRB- property information system common exchange -RRB- be a property-focused electronic data exchange standard . the standard be a set of definition and rule to facilitate electronic transfer of data between key business area and between different type of software package that be use regularly by the property industry . it be not itself a piece of software but an enable technology that allow software provider to prepare solution within their own package to transfer data between database . this provide the attractive prospect of seamless transfer of data within and between system and organization",112,1
7076,Computers and IT,"The widespread use of E-mail can be found in all areas of commerce, and the legal profession is one that has embraced this new medium of communication. E-mail is not without its drawbacks, however. Due to the nature of the technologies behind the medium, it is a less secure form of communication than many of those traditionally used by the legal profession, including DX, facsimile, and standard and registered post. There are a number of ways in which E-mails originating from the practice may be protected, including software encryption, hardware encryption and various methods of controlling and administering access to the E-mails","the widespread use of e-mail can be find in all area of commerce , and the legal profession be one that have embrace this new medium of communication . e-mail be not without its drawback , however . due to the nature of the technology behind the medium , it be a less secure form of communication than many of those traditionally use by the legal profession , include dx , facsimile , and standard and registered post . there be a number of way in which e-mail originate from the practice may be protect , include software encryption , hardware encryption and various method of control and administer access to the e-mail",102,0.666666667
7077,Computers and IT,"The author describes a solution to spam E-mails: disposable E-mail addresses (DEA). Mailshell's free trial Web-based E-mail service allows you, if you start getting spammed on that DEA, just to delete the DEA in Mailshell, and all E-mail thereafter sent to that address will automatically be junked (though you can later restore that address if you want). Mailshell allows any number of DEA","the author describe a solution to spam e-mail : disposable e-mail address -LRB- dea -RRB- . mailshell 's free trial web-based e-mail service allow you , if you start get spamm on that dea , just to delete the dea in mailshell , and all e-mail thereafter send to that address will automatically be junk -LRB- though you can later restore that address if you want -RRB- . mailshell allow any number of dea",63,1
7078,Computers and IT,"Most legal firms now have a Web site and are starting to evaluate the return on their investment. The paper looks at factors involved when choosing a firm to help set up or improve a Web site. (1) Look for a company that combines technical skills and business experience. (2) Look for a company that offers excellent customer service. (3) Check that the Web site firm is committed to developing and proactively updating the Web site. (4) Make sure the firm has a proven track record and a good portfolio. (5) Look for a company with both a breadth as well as depth of skills. (6) Make sure the firm can deliver work on target, in budget and to specification. (7) Ensure that you will enjoy working and feel comfortable with the Web site firm staff","most legal firm now have a web site and be start to evaluate the return on their investment . the paper look at factor involve when choose a firm to help set up or improve a web site . -LRB- 1 -RRB- look for a company that combine technical skill and business experience . -LRB- 2 -RRB- look for a company that offer excellent customer service . -LRB- 3 -RRB- check that the web site firm be commit to develop and proactively update the web site . -LRB- 4 -RRB- make sure the firm have a proven track record and a good portfolio . -LRB- 5 -RRB- look for a company with both a breadth as well as depth of skill . -LRB- 6 -RRB- make sure the firm can deliver work on target , in budget and to specification . -LRB- 7 -RRB- ensure that you will enjoy work and feel comfortable with the web site firm staff",136,0.714285714
7079,Computers and IT,"An awkward look at a few standard views from the author, who thinks that most people have got it, err, wrong. Like every other investment, when the time comes to sign the contract, the question that should be asked is not whether it is a good investment, but whether it is the best investment the firm can make with the money. the author argues that he would be surprised if any law firm Web site he has seen yet would jump that particular hurdle","an awkward look at a few standard view from the author , who think that most people have get it , err , wrong . like every other investment , when the time come to sign the contract , the question that should be ask be not whether it be a good investment , but whether it be the best investment the firm can make with the money . the author argue that he would be surprise if any law firm web site he have see yet would jump that particular hurdle",84,0.5
7080,Computers and IT,"The objective is to report on the work of Prof. Jean-Raoul Scherrer, and show how his humanist vision, medical skills and scientific background have enabled and shaped the development of medical informatics over the last 30 years. Starting with the mainframe-based patient-centred hospital information system DIOGENE in the 70s, Prof. Scherrer developed, implemented and evolved innovative concepts of man-machine interfaces, distributed and federated environments, leading the way with information systems that obstinately focused on the support of care providers and patients. Through a rigorous design of terminologies and ontologies, the DIOGENE data would then serve as a basis for the development of clinical research, data mining, and lead to innovative natural language processing techniques. In parallel, Prof. Scherrer supported the development of medical image management, ranging from a distributed picture archiving and communication systems (PACS) to molecular imaging of protein electrophoreses. Recognizing the need for improving the quality and trustworthiness of medical information of the Web, Prof. Scherrer created the Health-On-the Net (HON) foundation. These achievements, made possible thanks to his visionary mind, deep humanism, creativity, generosity and determination, have made of Prof. Scherrer a true pioneer and leader of the human-centered, patient-oriented application of information technology for improving healthcare","the objective be to report on the work of prof. jean-raoul scherrer , and show how his humanist vision , medical skill and scientific background have enable and shape the development of medical informatics over the last 30 year . start with the mainframe-based patient-centred hospital information system diogene in the 70 , prof. scherrer develop , implement and evolve innovative concept of man-machine interface , distribute and federate environment , lead the way with information system that obstinately focus on the support of care provider and patient . through a rigorous design of terminology and ontology , the diogene data would then serve as a basis for the development of clinical research , data mining , and lead to innovative natural language processing technique . in parallel , prof. scherrer support the development of medical image management , range from a distribute picture archive and communication system -LRB- pac -RRB- to molecular imaging of protein electrophores . recognize the need for improve the quality and trustworthiness of medical information of the web , prof. scherrer create the health-on-the net -LRB- hon -RRB- foundation . these achievement , make possible thanks to his visionary mind , deep humanism , creativity , generosity and determination , have make of prof. scherrer a true pioneer and leader of the human-centered , patient-oriented application of information technology for improve healthcare",200,0.5
7081,Computers and IT,"The objectives are to discuss application areas of information, technology in medicine and health care on the occasion of the opening of the Private Universitat fur Medizinische Informatik and Technik Tirol/University for Health Informatics and Technology Tyrol (LIMIT) at Innsbruck, Tyrol, Austria. Important application areas of information technology in medicine and health are appropriate individual access to medical knowledge, new engineering developments such as new radiant imaging methods and the implantable pacemaker/defibrillator devices, mathematical modeling for understanding the workings of the human body, the computer-based patient record, as well as new knowledge in molecular biology, human genetics, and biotechnology. Challenges and responsibilities for medical informatics research include medical data privacy and intellectual property rights inherent in the content of the information systems","the objective be to discuss application area of information , technology in medicine and health care on the occasion of the opening of the private universitat fur medizinische informatik and technik tirol/university for health informatics and technology tyrol -LRB- limit -RRB- at innsbruck , tyrol , austria . important application area of information technology in medicine and health be appropriate individual access to medical knowledge , new engineering development such as new radiant imaging method and the implantable pacemaker/defibrillator device , mathematical modeling for understand the working of the human body , the computer-based patient record , as well as new knowledge in molecular biology , human genetics , and biotechnology . challenge and responsibility for medical informatics research include medical data privacy and intellectual property right inherent in the content of the information system",122,0.833333333
7082,Computers and IT,"The objectives are to summarize the insights gained in collaborative research in a Canadian Network of Centres of Excellence, devoted to the promotion of evidence-based practice, and to relate this experience to Internet support of health promotion and consumer health informatics. A subjective review of insights is undertaken. Work directed the development of systems incorporating guidelines, care maps, etc. , for use by professionals met with limited acceptance. Evidence-based tools for health care consumers are a desirable complement but require radically different content and delivery modes. In addition to evidence-based material offered by professionals, a wide array of Internet-based products and services provided by consumers for consumers emerged and proved a beneficial complement. The consumer-driven products and services provided via the Internet are a potentially important and beneficial complement of traditional health services. They affect the health consumer-provider roles and require changes in healthcare practices","the objective be to summarize the insight gain in collaborative research in a canadian network of centre of excellence , devote to the promotion of evidence-based practice , and to relate this experience to internet support of health promotion and consumer health informatics . a subjective review of insight be undertake . work direct the development of system incorporate guideline , care map , etc. , for use by professional meet with limited acceptance . evidence-based tool for health care consumer be a desirable complement but require radically different content and delivery mode . in addition to evidence-based material offer by professional , a wide array of internet-based product and service provide by consumer for consumer emerge and prove a beneficial complement . the consumer-driven product and service provide via the internet be a potentially important and beneficial complement of traditional health service . they affect the health consumer-provider role and require change in healthcare practice",145,0.875
7083,Computers and IT,"In some cases, vendor-run accreditation schemes can offer an objective measure of a job applicant's skills, but they do not always indicate the true extent of practical abilities","in some case , vendor-run accreditation scheme can offer an objective measure of a job applicant 's skill , but they do not always indicate the true extent of practical ability",28,0.6
7084,Computers and IT,"The objectives are to develop a health/medical data interchange model for efficient electronic exchange of data among health-checkup facilities. A Health-checkup Data Markup Language (HDML) was developed on the basis of the Standard Generalized Markup Language (SGML), and a feasibility study carried out, involving data exchange between two health checkup facilities. The structure of HDML is described. The transfer of numerical lab data, summary findings and health status assessment was successful. HDML is an improvement to laboratory data exchange. Further work has to address the exchange of qualitative and textual data","the objective be to develop a health/medical data interchange model for efficient electronic exchange of data among health-checkup facility . a health-checkup data markup language -LRB- hdml -RRB- be develop on the basis of the standard generalize markup language -LRB- sgml -RRB- , and a feasibility study carry out , involve data exchange between two health checkup facility . the structure of hdml be describe . the transfer of numerical lab data , summary finding and health status assessment be successful . hdml be an improvement to laboratory data exchange . far work have to address the exchange of qualitative and textual data",91,0.857142857
7085,Computers and IT,"The objective is to provide automated advice for lifestyle adjustment based on an assessment of the results of a questionnaire and medical examination or health checkup data. A system was developed that gathers data based on questions regarding weight gain, exercise, smoking, sleep, eating habits, salt intake, animal fat intake, snacks, alcohol, and oral hygiene, body mass index, resting blood pressure, fasting blood sugar, total cholesterol, triglycerides, uric acid and liver function tests. Based on the relationships between the lifestyle data and the health checkup data, a health assessment sheet was generated for persons being allocated to a multiple-risk factor syndrome group. Health assessment and useful advice for lifestyle improvement were automatically extracted with the system, toward the high risk group for life style related diseases. The system is operational. In comparison with conventional, limited advice methods, we developed a practical system that defined the necessity for lifestyle improvement more clearly, and made giving advice easier","the objective be to provide automated advice for lifestyle adjustment base on an assessment of the result of a questionnaire and medical examination or health checkup data . a system be develop that gather data base on question regard weight gain , exercise , smoking , sleep , eat habit , salt intake , animal fat intake , snack , alcohol , and oral hygiene , body mass index , rest blood pressure , fast blood sugar , total cholesterol , triglyceride , uric acid and liver function test . base on the relationship between the lifestyle data and the health checkup data , a health assessment sheet be generate for person be allocate to a multiple-risk factor syndrome group . health assessment and useful advice for lifestyle improvement be automatically extract with the system , toward the high risk group for life style relate disease . the system be operational . in comparison with conventional , limited advice method , we develop a practical system that define the necessity for lifestyle improvement more clearly , and make give advice easy",156,0.954545455
7086,Computers and IT,"Drawing from an information processing perspective, this paper examines how information technology (IT) has been a catalyst in the development of new forms of organizational structures. The article draws a historical linkage between the relative stability of an organization's task environment starting after the Second World War to the present environmental instability that now characterizes many industries. Specifically, the authors suggest that advances in IT have enabled managers to adapt existing forms and create new models for organizational design that better fit requirements of an unstable environment. Time has seemingly borne out this hypothesis as the bureaucratic structure evolved to the matrix to the network and now to the emerging shadow structure. IT has gone from a support mechanism to a substitute for organizational structures in the form of the shadow structure. The article suggests that the evolving and expanding role of IT will continue for organizations that face unstable environments","draw from an information processing perspective , this paper examine how information technology -LRB- it -RRB- have be a catalyst in the development of new form of organizational structure . the article draw a historical linkage between the relative stability of an organization 's task environment start after the second world war to the present environmental instability that now characterize many industry . specifically , the author suggest that advance in it have enable manager to adapt exist form and create new model for organizational design that better fit requirement of an unstable environment . time have seemingly bear out this hypothesis as the bureaucratic structure evolve to the matrix to the network and now to the emerge shadow structure . it have go from a support mechanism to a substitute for organizational structure in the form of the shadow structure . the article suggest that the evolve and expand role of it will continue for organization that face unstable environment",151,0.666666667
7087,Computers and IT,"Organisational commitment, the emotional attachment of an employee to the employing organisation, has attracted a substantial body of literature, relating the concept to various antecedents, including organisational structure, and to a range of consequences, including financially important performance factors such as productivity and staff turnover. The new areas of knowledge management and learning organisations offer substantial promise as imperatives for the organisation of business enterprises. As organisations in the contemporary environment adopt knowledge-based structures to improve their competitive position, there is value in examining these structures against other performance related factors. Theoretical knowledge-based structures put forward by R. Miles et al. (1997) and J. Quinn et al. (1996) and an existing implementation are examined to determine common features inherent in these approaches. These features are posited as a typical form and their impact on organisational commitment and hence on individual and organisational performance is examined","organisational commitment , the emotional attachment of an employee to the employ organization , have attract a substantial body of literature , relate the concept to various antecedent , include organisational structure , and to a range of consequence , include financially important performance factor such as productivity and staff turnover . the new area of knowledge management and learn organization offer substantial promise as imperative for the organization of business enterprise . as organization in the contemporary environment adopt knowledge-based structure to improve their competitive position , there be value in examine these structure against other performance relate factor . theoretical knowledge-based structure put forward by r. mile et al. -LRB- 1997 -RRB- and j. quinn et al. -LRB- 1996 -RRB- and an exist implementation be examine to determine common feature inherent in these approach . these feature be posit as a typical form and their impact on organisational commitment and hence on individual and organisational performance be examine",145,1
7088,Computers and IT,"Information systems and organization structures have been highly interconnected with each other. Over the years, information systems architectures as well as organization structures have evolved from centralized to more decentralized forms. This research looks at the evolution of both information systems and organization structures. In the process, it looks into the impact of computers on organizations, and examines the ways organization structures have changed, in association with changes in information system architectures. It also suggests logical linkages between information system architectures and their ""fit"" with certain organization structures and strategies. It concludes with some implications for emerging and future organizational forms, and provides a quick review of the effect of the Internet on small businesses traditionally using stand-alone computers","information system and organization structure have be highly interconnect with each other . over the year , information system architectur as well as organization structure have evolve from centralize to more decentralized form . this research look at the evolution of both information system and organization structure . in the process , it look into the impact of computer on organization , and examine the way organization structure have change , in association with change in information system architecture . it also suggest logical linkage between information system architecture and their `` fit '' with certain organization structure and strategy . it conclude with some implication for emerge and future organizational form , and provide a quick review of the effect of the internet on small business traditionally use stand-alone computer",119,0.5
7089,Computers and IT,"Many organisations, particularly SMEs, are reluctant to invest time and money in models to support decision making. Such reluctance could be overcome if a model could be used for several purposes rather than using a traditional ""single perspective"" model. This requires the development of a ""general enterprise model"" (GEM), which can be applied to a wide range of problem domains with unlimited scope. Current enterprise modelling frameworks only deal effectively with nondynamic modelling issues whilst dynamic modelling issues have traditionally only been addressed at the operational level. Although the majority of research in this area relates to manufacturing companies, the framework for a GEM must be equally applicable to service and public sector organisations. The paper identifies five key design issues that need to be considered when constructing a GEM. A framework for such a GEM is presented based on a ""plug and play"" methodology and demonstrated by a simple case study","many organization , particularly sm , be reluctant to invest time and money in model to support decision making . such reluctance could be overcome if a model could be use for several purpose rather than use a traditional `` single perspective '' model . this require the development of a `` general enterprise model '' -LRB- gem -RRB- , which can be apply to a wide range of problem domain with unlimited scope . current enterprise model framework only deal effectively with nondynamic modelling issue whilst dynamic model issue have traditionally only be address at the operational level . although the majority of research in this area relate to manufacture company , the framework for a gem must be equally applicable to service and public sector organization . the paper identify five key design issue that need to be consider when construct a gem . a framework for such a gem be present base on a `` plug and play '' methodology and demonstrate by a simple case study",152,0.571428571
7090,Computers and IT,"The design and redesign of high throughput experiments for zeolite synthesis are addressed. A model that relates materials function to the chemical composition of the zeolite and the structure directing agent is introduced. Using this model, several Monte Carlo-like design protocols are evaluated. Multi-round protocols are bound to be effective, and strategies that use a priori information about the structure-directing libraries are found to be the best","the design and redesign of high throughput experiment for zeolite synthesis be address . a model that relate material function to the chemical composition of the zeolite and the structure direct agent be introduce . use this model , several monte carlo-like design protocol be evaluate . multi-round protocol be bind to be effective , and strategy that use a priori information about the structure-directing library be find to be the best",67,0.238095238
7091,Computers and IT,The variable structure control (VSC) of discrete time systems based on intelligent control is presented in this paper. A novel approach is proposed for the state estimation. A linear observer is firstly designed. Then a neural network is used for compensating uncertainty. The parameter of the VSC scheme is adjusted online by a neural network. Practical operating results from a PM synchronous motor (PMSM) illustrate the effectiveness and practicability of the proposed approach,the variable structure control -LRB- vsc -RRB- of discrete time system base on intelligent control be present in this paper . a novel approach be propose for the state estimation . a linear observer be firstly design . then a neural network be use for compensate uncertainty . the parameter of the vsc scheme be adjust online by a neural network . practical operating result from a pm synchronous motor -LRB- pmsm -RRB- illustrate the effectiveness and practicability of the proposed approach,73,0.444444444
7092,Computers and IT,"A nonlinear control strategy to improve transient stability of a multi-machine AC power system with several DC links terminated in the presence of large disturbances is presented. The approach proposed in this paper is based on differential geometric theory, and the HVDC systems are taken as a variable admittance connected at the inverter or rectifier AC bus. After deriving the analytical description of the relationship between the variable admittance and active power flows of each generator, the traditional generator dynamic equations can thus be expressed with the variable admittance of HVDC systems as an additional state variable and changed to an affine form, which is suitable for global linearization method being used to determine its control variable. An important feature of the proposed method is that, the modulated DC power is an adaptive and non-linear function of AC system states, and it can be realized by local feedback and less transmitted data from, adjacent generators. The design procedure is tested on a dual-infeed hybrid AC/DC system","a nonlinear control strategy to improve transient stability of a multi-machine ac power system with several dc link terminate in the presence of large disturbance be present . the approach propose in this paper be base on differential geometric theory , and the hvdc system be take as a variable admittance connect at the inverter or rectifier ac bus . after derive the analytical description of the relationship between the variable admittance and active power flow of each generator , the traditional generator dynamic equation can thus be express with the variable admittance of hvdc system as an additional state variable and change to an affine form , which be suitable for global linearization method be use to determine its control variable . an important feature of the propose method be that , the modulated dc power be an adaptive and non-linear function of ac system state , and it can be realize by local feedback and less transmitted data from , adjacent generator . the design procedure be test on a dual-infeed hybrid ac/dc system",166,0.888888889
7093,Computers and IT,"Design competitions offer students an excellent way to gain hands-on experience in engineering and computer science courses. The University of Florida, in partnership with Motorola, has held two mobile computing design competitions. In Spring and Fall 2001, students in Abdelsalam Helal's Mobile Computing class designed killer apps for a Motorola smart phone","design competition offer student an excellent way to gain hands-on experience in engineering and computer science course . the university of florida , in partnership with motorola , have hold two mobile computing design competition . in spring and fall 2001 , student in abdelsalam helal 's mobile computing class design killer app for a motorola smart phone",52,1
7094,Computers and IT,IT managers building storage area networks or expanding their capacity may be able to save money by using iSCSI and IP systems rather than Fibre Channel technologies,it manager build storage area network or expand their capacity may be able to save money by use iscsi and ip system rather than fiber channel technology,27,0.75
7095,Computers and IT,"For the past five years, competing industries and standards developers have been hotly pursuing automatic configuration, now coined the broader term service discovery. Jini, Universal Plug and Play (UPnP), Salutation, and Service Location Protocol are among the front-runners in this new race. However, choosing service discovery as the topic of the hour goes beyond the need for plug-and-play solutions or support for the SOHO (small office/home office) user. Service discovery's potential in mobile and pervasive computing environments motivated my choice","for the past five year , compete industry and standard developer have be hotly pursue automatic configuration , now coin the broad term service discovery . jini , universal plug and play -LRB- upnp -RRB- , salutation , and service location protocol be among the front-runner in this new race . however , choose service discovery as the topic of the hour go beyond the need for plug-and-play solution or support for the soho -LRB- small office/home office -RRB- user . service discovery 's potential in mobile and pervasive computing environment motivate my choice",80,0.857142857
7096,Computers and IT,"Speech recognition seems like an attractive input mechanism for wearable computers, and as we saw in this magazine's first issue, several companies are promoting products that use limited speech interfaces for specific tasks. However, we must overcome several challenges to using speech recognition in more general contexts, and interface designers must be wary of applying the technology to situations where speech is inappropriate","speech recognition seem like an attractive input mechanism for wearable computer , and as we saw in this magazine 's first issue , several company be promote product that use limited speech interface for specific task . however , we must overcome several challenge to use speech recognition in more general context , and interface designer must be wary of apply the technology to situation where speech be inappropriate",63,0.375
7097,Computers and IT,"Advances in mobile telecommunications and device miniaturization call for providing both standard and novel location- and context-dependent Internet services to mobile clients. Mobile agents are dynamic, asynchronous, and autonomous, making the MA programming paradigm suitable for developing novel middleware for mobility-enabled services","advance in mobile telecommunication and device miniaturization call for provide both standard and novel location - and context-dependent internet service to mobile client . mobile agent be dynamic , asynchronous , and autonomous , make the ma programming paradigm suitable for develop novel middleware for mobility-enabled service",42,1
7098,Computers and IT,"The Kimura system augments and integrates independent tools into a pervasive computing system that monitors a user's interactions with the computer, an electronic whiteboard, and a variety of networked peripheral devices and data sources","the kimura system augment and integrate independent tool into a pervasive computing system that monitor a user 's interaction with the computer , an electronic whiteboard , and a variety of networked peripheral device and data source",34,0.833333333
7099,Computers and IT,"Location-dependent information services have great promise for mobile and pervasive computing environments. They can provide local and nonlocal news, weather, and traffic reports as well as directory services. Before they can be implemented on a large scale, however, several research issues must be addressed","location-dependent information service have great promise for mobile and pervasive computing environment . they can provide local and nonlocal news , weather , and traffic report as well as directory service . before they can be implement on a large scale , however , several research issue must be address",44,0.666666667
7100,Computers and IT,"Significant complexity issues challenge designers of context-aware systems with privacy control. Information spaces provide a way to organize information, resources, and services around important privacy-relevant contextual factors. In this article, we describe a theoretical model for privacy control in context-aware systems based on a core abstraction of information spaces. We have previously focused on deriving socially based privacy objectives in pervasive computing environments. Building on Ravi Sandhu's four-layer OM-AM (objectives, models, architectures, and mechanisms) idea, we aim to use information spaces to construct a model for privacy control that supports our socially based privacy objectives. We also discuss how we can introduce decentralization, a desirable property for many pervasive computing systems, into our information space model, using unified privacy tagging","significant complexity issue challenge designer of context-aware system with privacy control . information space provide a way to organize information , resource , and service around important privacy-relevant contextual factor . in this article , we describe a theoretical model for privacy control in context-aware system base on a core abstraction of information space . we have previously focus on derive socially base privacy objective in pervasive computing environment . build on ravi sandhu 's four-lay om-am -LRB- objective , model , architecture , and mechanism -RRB- idea , we aim to use information space to construct a model for privacy control that support our socially base privacy objective . we also discuss how we can introduce decentralization , a desirable property for many pervasive computing system , into our information space model , use unify privacy tag",120,0.8
7101,Computers and IT,"ConChat is a context-aware chat program that enriches electronic communication by providing contextual information and resolving potential semantic conflicts between users. ConChat uses contextual information to improve electronic communication. Using contextual cues, users can infer during a conversation what the other person is doing and what is happening in his or her immediate surroundings. For example, if a user learns that the other person is talking with somebody else or is involved in some urgent activity, he or she knows to expect a slower response. Conversely, if the user learns that the other person is sitting in a meeting directly related to the conversation, he or she then knows to respond more quickly. Also, by informing users about the other person's context and tagging potentially ambiguous chat messages, ConChat explores how context can improve electronic communication by reducing semantic conflicts","conchat be a context-aware chat program that enrich electronic communication by provide contextual information and resolve potential semantic conflict between user . conchat use contextual information to improve electronic communication . use contextual cue , user can infer during a conversation what the other person be do and what be happen in his or her immediate surroundings . for example , if a user learn that the other person be talk with somebody else or be involve in some urgent activity , he or she know to expect a slow response . conversely , if the user learn that the other person be sit in a meeting directly relate to the conversation , he or she then know to respond more quickly . also , by inform user about the other person 's context and tag potentially ambiguous chat message , conchat explore how context can improve electronic communication by reduce semantic conflict",140,1
7102,Computers and IT,"Building a good content adaptation service for mobile devices poses many challenges. To meet these challenges, this quality-of-service-aware decision engine automatically negotiates for the appropriate adaptation decision for synthesizing an optimal content version","build a good content adaptation service for mobile device pose many challenge . to meet these challenge , this quality-of-service-aware decision engine automatically negotiate for the appropriate adaptation decision for synthesize an optimal content version",33,1
7103,Computers and IT,"Context-sensitive applications need data from sensors, devices, and user actions, and might need ad hoc communication support to dynamically discover new devices and engage in spontaneous information exchange. Reconfigurable Context-Sensitive Middleware facilitates the development and runtime operations of context-sensitive pervasive computing software","context-sensitive application need data from sensor , device , and user action , and might need ad hoc communication support to dynamically discover new device and engage in spontaneous information exchange . reconfigurable context-sensitive middleware facilitate the development and runtime operation of context-sensitive pervasive computing software",42,1
7104,Computers and IT,"Using measured acceleration and angular velocity data gathered through inexpensive, wearable sensors, this dead-reckoning method can determine a user's location, detect transitions between preselected locations, and recognize and classify sitting, standing, and walking behaviors. Experiments demonstrate the proposed method's effectiveness","use measure acceleration and angular velocity data gather through inexpensive , wearable sensor , this dead-reckoning method can determine a user 's location , detect transition between preselected location , and recognize and classify sit , stand , and walk behavior . experiment demonstrate the propose method 's effectiveness",40,0.8
7105,Computers and IT,"The SlotShield 3000 firewall on a PCI card saves power and space, but might not offer enough security for large networks","the slotshield 3000 firewall on a pci card save power and space , but might not offer enough security for large network",21,1
7106,Computers and IT,"Labscape is a smart environment that we designed to improve the experience of people who work in a cell biology laboratory. Our goal in creating it was to simplify, laboratory work by making information available where it is needed and by collecting and organizing data where and when it is created into a formal representation that others can understand and process. By helping biologists produce a more complete record of their work with less effort, Labscape is designed to foster improved collaboration in conjunction with increased individual efficiency and satisfaction. A user-driven system, although technologically conservative, embraces a central goal of ubiquitous computing: to enhance the ability to perform domain tasks through fluid interaction with computational resources. Smart environments could soon replace the pen and paper commonly used in the laboratory setting","labscape be a smart environment that we design to improve the experience of people who work in a cell biology laboratory . our goal in create it be to simplify , laboratory work by make information available where it be need and by collect and organize data where and when it be create into a formal representation that other can understand and process . by help biologist produce a more complete record of their work with less effort , labscape be design to foster improved collaboration in conjunction with increase individual efficiency and satisfaction . a user-driven system , although technologically conservative , embrace a central goal of ubiquitous computing : to enhance the ability to perform domain task through fluid interaction with computational resource . smart environment could soon replace the pen and paper commonly use in the laboratory setting",132,0.714285714
7107,Computers and IT,Paul Diamond of consultancy KPMG explains why careful IT asset management is crucial to the success of mergers,paul diamond of consultancy kpmg explain why careful it asset management be crucial to the success of merger,18,1
7108,Computers and IT,"Mark Hawkins, chief operating officer at UK-based streaming media specialist Twofourtv, explains how firms can benefit by linking their corporate intranets to broadcasting technology","mark hawkins , chief operate officer at uk-based stream medium specialist twofourtv , explain how firm can benefit by link their corporate intranet to broadcast technology",24,1
7109,Computers and IT,"Sun Microsystems' recently launched Java Verification Program aims to enable companies to assess the cross-platform portability of applications written in Java, and to help software vendors ensure that their solutions can run in heterogenous J2EE application server environments","sun microsystem ' recently launch java verification program aim to enable company to assess the cross-platform portability of application write in java , and to help software vendor ensure that their solution can run in heterogenous j2ee application server environment",38,1
7110,Computers and IT,"CCTV systems can help lodging establishments accomplish a range of objectives, from deterring criminals to observing staff interactions with clientele. But pitfalls can arise if the CCTV system has not been properly integrated into the overall hotel security plan. CCTV system designs at new hotel properties are often too sophisticated, too complicated, and too costly, and do not take into consideration the security realities of site management. These problems arise when the professionals designing or installing the system, including architects, construction engineers, integrators, and consultants, are not familiar with a hotel's operating strategies or security standards","cctv system can help lodge establishment accomplish a range of objective , from deter criminal to observe staff interaction with clientele . but pitfall can arise if the cctv system have not be properly integrate into the overall hotel security plan . cctv system design at new hotel property be often too sophisticated , too complicated , and too costly , and do not take into consideration the security reality of site management . these problem arise when the professional design or instal the system , include architect , construction engineer , integrator , and consultant , be not familiar with a hotel 's operating strategy or security standard",96,0.75
7111,Computers and IT,E-mails carrying viruses like the recent Klez worm use deceptively simple techniques and known vulnerabilities to spread from one computer to another with ease,e-mail carry virus like the recent klez worm use deceptively simple technique and know vulnerability to spread from one computer to another with ease,24,1
7112,Computers and IT,"The constraints imposed by special relativity on the distinguishability of quantum states are discussed. An explicit expression relating the probability of an error in distinguishing two orthogonal single-photon states to their structure, the time t at which a measurement starts, and the interval of time T elapsed from the start of the measurement until the time at which the outcome is obtained by an observer is given as an example","the constraint impose by special relativity on the distinguishability of quantum state be discuss . an explicit expression relate the probability of an error in distinguish two orthogonal single-photon state to their structure , the time t at which a measurement start , and the interval of time t elapse from the start of the measurement until the time at which the outcome be obtain by an observer be give as an example",70,0.333333333
7113,Computers and IT,"Large-scale genotyping, mapping and expression profiling require affordable, fully automated high-throughput devices enabling rapid, high-performance analysis using minute quantities of reagents. In this paper, we describe a new combination of microwell polymerase chain reaction (PCR) based DNA amplification technique with automated ultrathin-layer gel electrophoresis analysis of the resulting products. This technique decreases the reagent consumption (total reaction volume 0. 75-1 mu L), the time requirement of the PCR (15-20 min) and subsequent ultrathin-layer gel electrophoresis based fragment analysis (5 min) by automating the current manual procedure and reducing the human intervention using sample loading robots and computerized real time data analysis. Small aliquots (0. 2 mu L) of the submicroliter size PCR reaction were transferred onto loading membranes and analyzed by ultrathin-layer gel electrophoresis which is a novel, high-performance and automated microseparation technique. This system employs integrated scanning laser-induced fluorescence-avalanche photodiode detection and combines the advantages of conventional slab and capillary gel electrophoresis. Visualization of the DNA fragments was accomplished by ""in migratio"" complexation with ethidium bromide during the electrophoresis process also enabling real time imaging and data analysis","large-scale genotyping , mapping and expression profiling require affordable , fully automate high-throughput device enable rapid , high-performance analysis use minute quantity of reagent . in this paper , we describe a new combination of microwell polymerase chain reaction -LRB- pcr -RRB- base dna amplification technique with automated ultrathin-lay gel electrophoresis analysis of the result product . this technique decrease the reagent consumption -LRB- total reaction volume 0 . 75-1 mu l -RRB- , the time requirement of the pcr -LRB- 15-20 min -RRB- and subsequent ultrathin-layer gel electrophoresis base fragment analysis -LRB- 5 min -RRB- by automate the current manual procedure and reduce the human intervention use sample load robot and computerized real time data analysis . small aliquot -LRB- 0 . 2 mu l -RRB- of the submicroliter size pcr reaction be transfer onto load membrane and analyze by ultrathin-lay gel electrophoresis which be a novel , high-performance and automated microseparation technique . this system employ integrate scan laser-induced fluorescence-avalanche photodiode detection and combine the advantage of conventional slab and capillary gel electrophoresis . visualization of the dna fragment be accomplish by `` in migratio '' complexation with ethidium bromide during the electrophoresis process also enable real time imaging and data analysis",179,0.642857143
7114,Computers and IT,"A few things done properly, and soon, is the short-term strategy for the UK NHS IT programme. Can it deliver this time?","a few thing do properly , and soon , be the short-term strategy for the uk nh it program . can it deliver this time ?",22,0.666666667
7115,Computers and IT,"While the need for automation in 300 mm fabs is not debated, the form and performance of such automation is still in question. Software simulation that compares conveyor-based continuous flow transport technology to conventional car-based wafer-lot delivery has detailed delivery time and throughput advantages to the former","while the need for automation in 300 mm fab be not debate , the form and performance of such automation be still in question . software simulation that compare conveyor-based continuous flow transport technology to conventional car-based wafer-lot delivery have detail delivery time and throughput advantage to the former",47,0.666666667
7116,Computers and IT,CM's 13th annual survey of in-house fulfillment system suppliers brings you up to date on the current capabilities of the leading publication software packages,cm 's 13th annual survey of in-house fulfillment system supplier bring you up to date on the current capability of the lead publication software package,24,1
7117,Computers and IT,"For the uninitiated, writing a request for proposal can seem both mysterious and daunting. Here's a format that will make you look like a pro the first time out","for the uninitiated , write a request for proposal can seem both mysterious and daunting . here ' a format that will make you look like a pro the first time out",29,0.333333333
7118,Computers and IT,"This article is based on the emerging experience associated with a digital library of instructional resources, iLumina, in which the contributors of resources and the users of those resources are the same-an open community of instructors in science, mathematics, engineering, and technology. Moreover, it is not the resources, most of which will be distributed across the Internet, but metadata about the resources that is the focus of the central iLumina repository and its support services for resource contributors and users. The distributed iLumina library is a community-sharing library for repurposing and adding value to potentially useful, mostly non-commercial instructional resources that are typically more granular in nature than commercially developed course materials. The experience of developing iLumina is raising a range of issues that have nothing to do with the place and time characteristics of the instructional context in which iLumina instructional resources are created or used. The issues instead have their locus in the democratization of both the professional roles of librarians and the quality assurance mechanisms associated with traditional peer review","this article be base on the emerge experience associate with a digital library of instructional resource , ilumina , in which the contributor of resource and the user of those resource be the same-an open community of instructor in science , mathematics , engineering , and technology . moreover , it be not the resource , most of which will be distribute across the internet , but metadata about the resource that be the focus of the central ilumina repository and its support service for resource contributor and user . the distribute ilumina library be a community-sharing library for repurpos and add value to potentially useful , mostly non-commercial instructional resource that be typically more granular in nature than commercially develop course material . the experience of develop ilumina be raise a range of issue that have nothing to do with the place and time characteristic of the instructional context in which ilumina instructional resource be create or use . the issue instead have their locus in the democratization of both the professional role of librarian and the quality assurance mechanism associate with traditional peer review",173,0.5
7119,Computers and IT,"In January 2000, a consortium of 64 universities in Canada signed a historic inter-institutional agreement that launched the Canadian National Site Licensing Project (CNSLP), a three-year pilot project aimed at bolstering the research and innovation capacity of the country's universities. CNSLP tests the feasibility of licensing, on a national scale, electronic versions of scholarly publications; in its initial phases the project is focused on full-text electronic journals and research databases in science, engineering, health and environmental disciplines. This article provides an overview of the CNSLP initiative, summarizes organizational and licensing accomplishments to date, and offers preliminary observations on challenges and opportunities for subsequent phases of the project","in january 2000 , a consortium of 64 university in canada sign a historic inter-institutional agreement that launch the canadian national site licensing project -LRB- cnslp -RRB- , a three-year pilot project aim at bolster the research and innovation capacity of the country 's university . cnslp test the feasibility of licensing , on a national scale , electronic version of scholarly publication ; in its initial phase the project be focus on full-text electronic journal and research database in science , engineering , health and environmental discipline . this article provide an overview of the cnslp initiative , summarize organizational and licensing accomplishment to date , and offer preliminary observation on challenge and opportunity for subsequent phase of the project",107,0.666666667
7120,Computers and IT,In 1998 the UK created the National Electronic Site Licensing Initiative (NESLI) to increase and improve access to electronic journals and to negotiate license agreements on behalf of academic libraries. The use of a model license agreement and the success of site licensing is discussed. Highlights from an interim evaluation by the Joint Information Systems Committee (JISC) are noted and key issues and questions arising from the evaluation are identified,in 1998 the uk create the national electronic site licensing initiative -LRB- nesli -RRB- to increase and improve access to electronic journal and to negotiate license agreement on behalf of academic library . the use of a model license agreement and the success of site licensing be discuss . highlight from an interim evaluation by the joint information system committee -LRB- jisc -RRB- be note and key issue and question arise from the evaluation be identify,70,0.777777778
7121,Computers and IT,"The Council of Australian University Librarians, constituted in 1965 for the purposes of cooperative action and the sharing of information, assumed the role of consortial purchasing agent in 1996 on behalf of its members and associate organisations in Australia and New Zealand. This role continues to grow in tandem with the burgeoning of electronic publication and the acceptance of publishers of the advantages of dealing with consortia. The needs of the Australian university community overlap significantly with consortia in North America and Europe, but important differences are highlighted","the council of australian university librarian , constitute in 1965 for the purpose of cooperative action and the sharing of information , assume the role of consortial purchasing agent in 1996 on behalf of its member and associate organization in australia and new zealand . this role continue to grow in tandem with the burgeon of electronic publication and the acceptance of publisher of the advantage of deal with consortium . the need of the australian university community overlap significantly with consortium in north america and europe , but important difference be highlight",88,0.888888889
7122,Computers and IT,"The licensing strategy of university libraries in the Netherlands is closely connected with university policies to develop document servers and to make research publications available on the Web. National agreements have been made with major publishers, such as Elsevier Science and Kluwer Academic, to provide access to a wide range of scientific information and to experiment with new ways of providing information and new business models","the licensing strategy of university library in the netherlands be closely connect with university policy to develop document server and to make research publication available on the web . national agreement have be make with major publisher , such as elsevi science and kluwer academic , to provide access to a wide range of scientific information and to experiment with new way of provide information and new business model",66,0.909090909
7123,Computers and IT,"Library consortia have grown substantially over the past ten years, both within North America and globally. As this resurgent consortial movement has begun to mature, and as publishers and vendors have begun to adapt to consortial purchasing models, consortia have expanded their agendas for action. The movement to globalize consortia is traced (including the development and current work of the International Coalition of Library Consortia-ICOLC). A methodology is explored to classify library consortia by articulating the key factors that affect and distinguish consortia as organizations within three major areas: strategic, tactical, and practical (or managerial) concerns. Common consortial values are examined, and a list of known international library consortia is presented","library consortium have grow substantially over the past ten year , both within north america and globally . as this resurgent consortial movement have begin to mature , and as publisher and vendor have begin to adapt to consortial purchasing model , consortium have expand their agenda for action . the movement to globalize consortium be trace -LRB- include the development and current work of the international coalition of library consortia-icolc -RRB- . a methodology be explore to classify library consortium by articulate the key factor that affect and distinguish consortium as organization within three major area : strategic , tactical , and practical -LRB- or managerial -RRB- concern . common consortial value be examine , and a list of known international library consortium be present",111,1
7124,Computers and IT,"The Open Archives Initiative (OAI) is dedicated to solving problems of digital library interoperability. Its focus has been on defining simple protocols, most recently for the exchange of metadata from archives. The OAI evolved out of a need to increase access to scholarly publications by supporting the creation of interoperable digital libraries. As a first step towards such interoperability, a metadata harvesting protocol was developed to support the streaming of metadata from one repository to another, ultimately to a provider of user services such as browsing, searching, or annotation. This article provides an overview of the mission, philosophy, and technical framework of the OAI","the open archive initiative -LRB- oai -RRB- be dedicate to solve problem of digital library interoperability . its focus have be on define simple protocol , most recently for the exchange of metadata from archive . the oai evolve out of a need to increase access to scholarly publication by support the creation of interoperable digital library . as a first step towards such interoperability , a metadata harvest protocol be develop to support the stream of metadata from one repository to another , ultimately to a provider of user service such as browsing , search , or annotation . this article provide an overview of the mission , philosophy , and technical framework of the oai",104,0.636363636
7125,Computers and IT,"In the emerging world of electronic publishing how we create, distribute, and read books will be in a large part determined by an underlying framework of content standards that establishes the range of technological opportunities and constraints for publishing and reading systems. But efforts to develop content standards based on sound engineering models must skillfully negotiate competing and sometimes apparently irreconcilable objectives if they are to produce results relevant to the rapidly changing course of technology. The Open eBook Forum's Publication Structure, an XML-based specification for electronic books, is an example of the sort of timely and innovative problem solving required for successful real-world standards development. As a result of this effort, the electronic book industry will not only happen sooner and on a larger scale than it would have otherwise, but the electronic books it produces will be more functional, more interoperable, and more accessible to all readers. Public interest participants have a critical role in this process","in the emerge world of electronic publishing how we create , distribute , and read book will be in a large part determine by an underlying framework of content standard that establish the range of technological opportunity and constraint for publishing and read system . but effort to develop content standard base on sound engineering model must skillfully negotiate compete and sometimes apparently irreconcilable objective if they be to produce result relevant to the rapidly change course of technology . the open ebook forum 's publication structure , an xml-based specification for electronic book , be an example of the sort of timely and innovative problem solve require for successful real-world standard development . as a result of this effort , the electronic book industry will not only happen sooner and on a large scale than it would have otherwise , but the electronic book it produce will be more functional , more interoperable , and more accessible to all reader . public interest participant have a critical role in this process",159,0.571428571
7126,Computers and IT,"Using simple acoustical and mechanical models, we consider the conceptual possibility of designing an active absorbing (nonreflecting) coating in the form of a thin layer with small-scale stratification and fast time modulation of parameters. Algorithms for space-time modulation of the controlled-layer structure are studied in detail for a one-dimensional boundary-value problem. These algorithms do not require wave-field measurements, which eliminates the self-excitation problem that is characteristic of active systems. The majority of the considered algorithms of parametric control transform the low-frequency incident wave to high-frequency waves of the technological band for which the waveguiding medium inside the layer is assumed to be opaque (absorbing). The efficient use conditions are found for all the algorithms. It is shown that the absorbing layer can be as thin as desired with respect to the minimum spatial scale of the incident wave and ensures efficient absorption in a wide frequency interval (starting from zero frequency) that is bounded from above only by a finite space-time resolution of the parameter-control operations. The structure of a three-dimensional parametric ""'black"" coating whose efficiency is independent of the angle of incidence of an incoming wave is developed on the basis of the studied one-dimensional problems. The general solution of the problem of diffraction of incident waves from such a coating is obtained. This solution is analyzed in detail for the case of a disk-shaped element","use simple acoustical and mechanical model , we consider the conceptual possibility of design an active absorbing -LRB- nonreflecting -RRB- coating in the form of a thin layer with small-scale stratification and fast time modulation of parameter . algorithm for space-time modulation of the controlled-layer structure be study in detail for a one-dimensional boundary-value problem . these algorithm do not require wave-field measurement , which eliminate the self-excitation problem that be characteristic of active system . the majority of the consider algorithm of parametric control transform the low-frequency incident wave to high-frequency wave of the technological band for which the waveguid medium inside the layer be assume to be opaque -LRB- absorbing -RRB- . the efficient use condition be find for all the algorithm . it be show that the absorbing layer can be as thin as desire with respect to the minimum spatial scale of the incident wave and ensure efficient absorption in a wide frequency interval -LRB- start from zero frequency -RRB- that be bound from above only by a finite space-time resolution of the parameter-control operation . the structure of a three-dimensional parametric '' ` black '' coating whose efficiency be independent of the angle of incidence of an incoming wave be develop on the basis of the study one-dimensional problem . the general solution of the problem of diffraction of incident wave from such a coating be obtain . this solution be analyze in detail for the case of a disk-shaped element",227,0.789473684
7127,Computers and IT,"Project Euclid, a joint electronic journal publishing initiative of Cornell University Library and Duke University Press is discussed in the broader contexts of the changing patterns of scholarly communication and the publishing scene of mathematics. Specific aspects of the project such as partnerships and the creation of an economic model are presented as well as what it takes to be a publisher. Libraries have gained important and relevant experience through the creation and management of digital libraries, but they need to develop further skills if they want to adopt a new role in the life cycle of scholarly communication","project euclid , a joint electronic journal publishing initiative of cornell university library and duke university press be discuss in the broad context of the change pattern of scholarly communication and the publishing scene of mathematics . specific aspect of the project such as partnership and the creation of an economic model be present as well as what it take to be a publisher . library have gain important and relevant experience through the creation and management of digital library , but they need to develop further skill if they want to adopt a new role in the life cycle of scholarly communication",99,0.8
7128,Computers and IT,"The Online Books Evaluation Project at Columbia University studied the potential for scholarly online books from 1995 to 1999. Issues included scholars' interest in using online books, the role they might play in scholarly life, features that scholars and librarians sought in online books, the costs of producing and owning print and online books, and potential marketplace arrangements. Scholars see potential for online books to make their research, learning, and teaching more efficient and effective. Librarians see potential to serve their scholars better. Librarians may face lower costs if they can serve their scholars with online books instead of print books. Publishers may be able to offer scholars greater opportunities to use their books while enhancing their own profitability","the online book evaluation project at columbia university study the potential for scholarly online book from 1995 to 1999 . issue include scholar ' interest in use online book , the role they might play in scholarly life , feature that scholar and librarian seek in online book , the cost of produce and own print and online book , and potential marketplace arrangement . scholar see potential for online book to make their research , learn , and teaching more efficient and effective . librarian see potential to serve their scholar better . librarian may face low cost if they can serve their scholar with online book instead of print book . publisher may be able to offer scholar great opportunity to use their book while enhance their own profitability",119,0.857142857
7129,Computers and IT,"The eScholarship program was launched in 2000 to foster faculty-led innovation in scholarly publishing. An initiative of the University of California (UC) and a program of the California Digital Library, the eScholarship program has stimulated significant interest in its short life. Its modest but visible accomplishments garner praise from many quarters, within and beyond the University of California. In perhaps the best indication of its timeliness and momentum, there are more proposals submitted to eScholarship today than the CDL can manage. This early success is due in part to the sheer power of an idea whose time has come, but also to the unique approach on which CDL was founded and the eScholarship initiative was first launched","the escholarship program be launch in 2000 to foster faculty-led innovation in scholarly publishing . an initiative of the university of california -LRB- uc -RRB- and a program of the california digital library , the escholarship program have stimulate significant interest in its short life . its modest but visible accomplishment garner praise from many quarter , within and beyond the university of california . in perhaps the best indication of its timeliness and momentum , there be more proposal submit to escholarship today than the cdl can manage . this early success be due in part to the sheer power of an idea whose time have come , but also to the unique approach on which cdl be found and the escholarship initiative be first launch",117,1
7130,Computers and IT,"This article describes a unique electronic journal publishing project involving the University of Kansas, the Big 12 Plus Libraries Consortium, the American Institute of Biological Sciences, Allen Press, and SPARC, the Scholarly Publishing and Academic Resources Coalition. This partnership has created BioOne, a database of 40 full-text society journals in the biological and environmental sciences, which was launched in April, 2001. The genesis and development of the project is described and financial, technical, and intellectual property models for the project are discussed. Collaborative strategies for the project are described","this article describe a unique electronic journal publishing project involve the university of kansa , the big 12 plus library consortium , the american institute of biological science , allen press , and sparc , the scholarly publishing and academic resource coalition . this partnership have create bioone , a database of 40 full-text society journal in the biological and environmental science , which be launch in april , 2001 . the genesis and development of the project be describe and financial , technical , and intellectual property model for the project be discuss . collaborative strategy for the project be describe",89,0.733333333
7131,Computers and IT,"University presses and research libraries have a long tradition of collaboration. The rapidly expanding electronic scholarly communication environment offers important new opportunities for cooperation and for innovative new models of publishing. The economics of libraries and scholarly publishers have strained the working relationship and promoted debates on important information policy issues. This article explores the context for advancing the partnership, cites examples of joint efforts in electronic publishing, and presents an action plan for working together","university press and research library have a long tradition of collaboration . the rapidly expand electronic scholarly communication environment offer important new opportunity for cooperation and for innovative new model of publishing . the economics of library and scholarly publisher have strain the work relationship and promote debate on important information policy issue . this article explore the context for advance the partnership , cite example of joint effort in electronic publishing , and present an action plan for work together",76,0.8
7132,Computers and IT,"This paper addresses a change in the concept of machine tool thermal error prediction which has been hitherto carried out by directly mapping them with the temperature of critical elements on the machine. The model developed herein using support vector machines, a powerful data-training algorithm, seeks to account for the impact of specific operating conditions, in addition to temperature variation, on the effective prediction of thermal errors. Several experiments were conducted to study the error pattern, which was found to change significantly with variation in operating conditions. This model attempts to classify the error based on operating conditions. Once classified, the error is then predicted based on the temperature states. This paper also briefly describes the concept of the implementation of such a comprehensive model along with an on-line error assessment and calibration system in a PC-based open-architecture controller environment, so that it could be employed in regular production for the purpose of periodic calibration of machine tools","this paper address a change in the concept of machine tool thermal error prediction which have be hitherto carry out by directly map them with the temperature of critical element on the machine . the model develop herein use support vector machine , a powerful data-training algorithm , seek to account for the impact of specific operating condition , in addition to temperature variation , on the effective prediction of thermal error . several experiment be conduct to study the error pattern , which be find to change significantly with variation in operating condition . this model attempt to classify the error base on operating condition . once classify , the error be then predict base on the temperature state . this paper also briefly describe the concept of the implementation of such a comprehensive model along with an on-line error assessment and calibration system in a pc-based open-architecture controller environment , so that it could be employ in regular production for the purpose of periodic calibration of machine tool",158,0.3
7133,Computers and IT,"The paper presents adaptive algorithms for mutual exclusion using only read and write operations; the performance of the algorithms depends only on the point contention, i. e. , the number of processes that are concurrently active during algorithm execution (and not on n, the total number of processes). Our algorithm has O(k) remote step complexity and O(log k) system response time, where k is the point contention. The remote step complexity is the maximal number of steps performed by a process where a wait is counted as one step. The system response time is the time interval between subsequent entries to the critical section, where one time unit is the minimal interval in which every active process performs at least one step. The space complexity of this algorithm is O(N log n), where N is the range of process names. We show how to make the space complexity of our algorithm depend solely on n, while preserving the other performance measures of the algorithm","the paper present adaptive algorithm for mutual exclusion use only read and write operation ; the performance of the algorithm depend only on the point contention , i. e. , the number of process that be concurrently active during algorithm execution -LRB- and not on n , the total number of process -RRB- . our algorithm have o -LRB- k -RRB- remote step complexity and o -LRB- log k -RRB- system response time , where k be the point contention . the remote step complexity be the maximal number of step perform by a process where a wait be count as one step . the system response time be the time interval between subsequent entry to the critical section , where one time unit be the minimal interval in which every active process perform at least one step . the space complexity of this algorithm be o -LRB- n log n -RRB- , where n be the range of process name . we show how to make the space complexity of our algorithm depend solely on n , while preserve the other performance measure of the algorithm",164,0.846153846
7134,Computers and IT,"Group mutual exclusion occurs naturally in situations where a resource can be shared by processes of the same group, but not by processes of different groups. For example, suppose data is stored in a CD-jukebox. Then, when a disc is loaded for access, users that need data on the disc can concurrently access the disc, while users that need data on a different disc have to wait until the current disc is unloaded. The design issues for group mutual exclusion have been modeled as the Congenial Talking Philosophers problem, and solutions for shared memory models have been proposed (Y. -J. Young, 2000; P. Keane and M. Moir, 1999). As in ordinary mutual exclusion and many other problems in distributed systems, however, techniques developed for shared memory do not necessarily apply to message passing (and vice versa). We investigate solutions for Congenial Talking Philosophers in computer networks where processes communicate by asynchronous message passing. We first present a solution that is a straightforward adaptation from G. Ricart and A. K. Agrawala's (1981) algorithm for ordinary mutual exclusion. Then we show that the simple modification suffers a severe performance degradation that could cause the system to behave as though only one process of a group can be in the critical section at a time. We then present a more efficient and highly concurrent distributed algorithm for the problem, the first such solution in computer networks","group mutual exclusion occur naturally in situation where a resource can be share by process of the same group , but not by process of different group . for example , suppose data be store in a cd-jukebox . then , when a disc be load for access , user that need data on the disc can concurrently access the disc , while user that need data on a different disc have to wait until the current disc be unloaded . the design issue for group mutual exclusion have be model as the congenial talk philosopher problem , and solution for shared memory model have be propose -LRB- y. - j. young , 2000 ; p. keane and m. moir , 1999 -RRB- . as in ordinary mutual exclusion and many other problem in distribute system , however , technique develop for shared memory do not necessarily apply to message passing -LRB- and vice versa -RRB- . we investigate solution for congenial talk philosopher in computer network where process communicate by asynchronous message pass . we first present a solution that be a straightforward adaptation from g. ricart and a. k. agrawala 's -LRB- 1981 -RRB- algorithm for ordinary mutual exclusion . then we show that the simple modification suffer a severe performance degradation that could cause the system to behave as though only one process of a group can be in the critical section at a time . we then present a more efficient and highly concurrent distribute algorithm for the problem , the first such solution in computer network",233,0.7
7135,Computers and IT,"We prove the existence of a ""universal"" synchronous self-stabilizing protocol, that is, a protocol that allows a distributed system to stabilize to a desired nonreactive behaviour (as long as a protocol stabilizing to that behaviour exists). Previous proposals required drastic increases in asymmetry and knowledge to work, whereas our protocol does not use any additional knowledge, and does not require more symmetry-breaking conditions than available; thus, it is also stabilizing with respect to dynamic changes in the topology. We prove an optimal quiescence time n + D for a synchronous network of n processors and diameter D; the protocol can be made finite state with a negligible loss in quiescence time. Moreover, an optimal D + 1 protocol is given for the case of unique identifiers. As a consequence, we provide an effective proof technique that allows one to show whether self-stabilization to a certain behaviour is possible under a wide range of models","we prove the existence of a `` universal '' synchronous self-stabilizing protocol , that be , a protocol that allow a distribute system to stabilize to a desire nonreactive behavior -LRB- as long as a protocol stabilize to that behavior exist -RRB- . previous proposal require drastic increase in asymmetry and knowledge to work , whereas our protocol do not use any additional knowledge , and do not require more symmetry-breaking condition than available ; thus , it be also stabilize with respect to dynamic change in the topology . we prove an optimal quiescence time n + d for a synchronous network of n processor and diameter d ; the protocol can be make finite state with a negligible loss in quiescence time . moreover , an optimal d + 1 protocol be give for the case of unique identifier . as a consequence , we provide an effective proof technique that allow one to show whether self-stabilization to a certain behavior be possible under a wide range of model",154,0.75
7136,Computers and IT,"We present the first explicit, and currently simplest, randomized algorithm for two-process wait-free test-and-set. It is implemented with two 4-valued single writer single reader atomic variables. A test-and-set takes at most 11 expected elementary steps, while a reset takes exactly 1 elementary step. Based on a finite-state analysis, the proofs of correctness and expected length are compressed into one table","we present the first explicit , and currently simple , randomize algorithm for two-process wait-free test-and-set . it be implement with two 4-valued single writer single reader atomic variable . a test-and-set take at most 11 expect elementary step , while a reset take exactly 1 elementary step . base on a finite-state analysis , the proof of correctness and expect length be compress into one table",60,0.363636364
7137,Computers and IT,"An approach to fuzzy modeling based on the tuning of parametric conjunction operations is proposed. First, some methods for the construction of parametric generalized conjunction operations simpler than the known parametric classes of conjunctions are considered and discussed. Second, several examples of function approximation by fuzzy models, based on the tuning of the parameters of the new conjunction operations, are given and their approximation performances are compared with the approaches based on a tuning of membership functions and other approaches proposed in the literature. It is seen that the tuning of the conjunction operations can be used for obtaining fuzzy models with a sufficiently good performance when the tuning of membership functions is not possible or not desirable","an approach to fuzzy modeling base on the tuning of parametric conjunction operation be propose . first , some method for the construction of parametric generalize conjunction operation simple than the know parametric class of conjunction be consider and discuss . second , several example of function approximation by fuzzy model , base on the tuning of the parameter of the new conjunction operation , be give and their approximation performance be compare with the approach base on a tuning of membership function and other approach propose in the literature . it be see that the tuning of the conjunction operation can be use for obtain fuzzy model with a sufficiently good performance when the tuning of membership function be not possible or not desirable",118,0.625
7138,Computers and IT,"A long-time favorite of project managers, Microsoft Project 2002 is making its enterprise debut. Its new Web-based collaboration tools and improved scalability with OLAP support make it much easier to manage multiple Web projects with disparate workgroups and budgets","a long-time favorite of project manager , microsoft project 2002 be make its enterprise debut . its new web-based collaboration tool and improve scalability with olap support make it much easy to manage multiple web project with disparate workgroup and budget",39,0.857142857
7139,Computers and IT,"Adobe GoLive is a strong contender for Web authoring and publishing. Version 6. 0 features a flexible GUI environment combined with a comprehensive workgroup and collaboration server, plus tight integration with leading design tools","adobe golive be a strong contender for web authoring and publishing . version 6 . 0 feature a flexible gui environment combine with a comprehensive workgroup and collaboration server , plus tight integration with lead design tool",34,0.2
7140,Computers and IT,"Every Web admin's dream is achieving the fabled five nines-99. 999 percent uptime. To attain such availability, your Web site must be down no more than about five minutes per year. Technologies like RAID, clustering, and load balancing make this easier, but to actually track uptime, maintain auditable records, and discover patterns in failures to prevent downtime in the future, you'll need to set up external monitoring. Because your Internet connection is a key factor in measuring uptime, you must monitor your site from the Internet itself, beyond your firewall. You could monitor with custom software on remote hosts, or you could use one of the two reasonably priced services available: Mercury Interactive's ActiveWatch and Freshwater Software's SiteSeer. (Freshwater Software has been a subsidiary of Mercury Interactive for about a year now. ) The two services offer a slightly different mix of features and target different markets. Both services offer availability and performance monitoring from several remote locations, alerts to email or pager, and periodic reports. They differ in what's most easily monitored, and in the way you interact with the services","every web admin 's dream be achieve the fabled five nines-99 . 999 percent uptime . to attain such availability , your web site must be down no more than about five minute per year . technology like raid , cluster , and load balancing make this easy , but to actually track uptime , maintain auditable record , and discover pattern in failure to prevent downtime in the future , you 'll need to set up external monitoring . because your internet connection be a key factor in measure uptime , you must monitor your site from the internet itself , beyond your firewall . you could monitor with custom software on remote host , or you could use one of the two reasonably price service available : mercury interactive 's activewatch and freshwater software 's siteseer . -LRB- freshwater software have be a subsidiary of mercury interactive for about a year now . -RRB- the two service offer a slightly different mix of feature and target different market . both service offer availability and performance monitoring from several remote location , alert to email or pager , and periodic report . they differ in what ' most easily monitored , and in the way you interact with the service",182,0.533333333
7141,Computers and IT,"Make sure your Web site is offering quality service to all your users. The article provides some tips and tactics for making your streaming media accessible. Accessibility of streaming content for people with disabilities is often not part of the spec for multimedia projects, but it certainly affects your quality of service. Most of the resources available on Web accessibility deal with HTML. Fortunately, rich media and streaming content developers have a growing number of experts to turn to for information and assistance. The essentials of providing accessible streaming content are simple: blind and visually impaired people need audio to discern important visual detail and interface elements, while deaf and hard-of-hearing people need text to access sound effects and dialog. Actually implementing these principles is quite a challenge, though. Now due to a relatively new law in the US, known as Section 508, dealing with accessibility issues is becoming an essential part of publishing on the Web","make sure your web site be offer quality service to all your user . the article provide some tip and tactic for make your stream medium accessible . accessibility of stream content for people with disability be often not part of the spec for multimedia project , but it certainly affect your quality of service . most of the resource available on web accessibility deal with html . fortunately , rich medium and stream content developer have a grow number of expert to turn to for information and assistance . the essential of provide accessible stream content be simple : blind and visually impair people need audio to discern important visual detail and interface element , while deaf and hard-of-hearing people need text to access sound effect and dialog . actually implement these principle be quite a challenge , though . now due to a relatively new law in the us , know as section 508 , deal with accessibility issue be become an essential part of publishing on the web",157,0.714285714
7142,Computers and IT,"To get the best possible performance from your Web infrastructure, you'll need a complete view. Don't neglect the big picture because you're too busy concentrating on details. The increasing complexity of Web sites and the content they provide has consequently increased the complexity of the infrastructure that supports them. But with some knowledge of networking, a handful of useful tools, and the insight that those tools provide, designing and operating for optimal performance and reliability is within your grasp","to get the best possible performance from your web infrastructure , you 'll need a complete view . do n't neglect the big picture because you 're too busy concentrate on detail . the increase complexity of web site and the content they provide have consequently increase the complexity of the infrastructure that support them . but with some knowledge of networking , a handful of useful tool , and the insight that those tool provide , design and operate for optimal performance and reliability be within your grasp",79,0.8
7143,Computers and IT,"Now that most of us agree that usability testing is an integral investment in site development, it's time to recognize that the standard approach falls short. It is possible to do less work and get better results while spending less money. By bringing usability testing in-house and breaking tests into more manageable sessions, you can vastly improve your online offering without affecting your profit margin","now that most of us agree that usability testing be an integral investment in site development , it ' time to recognize that the standard approach fall short . it be possible to do less work and get better result while spend less money . by bring usability testing in-house and breaking test into more manageable session , you can vastly improve your online offering without affect your profit margin",65,0
7144,Computers and IT,The author considers how one can save time tracking down bugs in Web-based applications by arming yourself with the right tools and programming practices. A wide variety of debugging tools have been written with Web developers in mind,the author consider how one can save time track down bug in web-based application by arm yourself with the right tool and programming practice . a wide variety of debugging tool have be write with web developer in mind,38,0.5
7145,Computers and IT,"While Sun prides itself on Java's secure sandbox programming model, Microsoft takes a looser approach. Its C# language incorporates C-like concepts, including pointers and memory management. But is unsafe code really a boon to programmers, or is it a step backward?","while sun pride itself on java 's secure sandbox programming model , microsoft take a loose approach . its c # language incorporate c-like concept , include pointer and memory management . but be unsafe code really a boon to programmer , or be it a step backward ?",41,0.6
7146,Computers and IT,"Providing a context for the exploration of user defined virtual collections, the article describes the history and recent development of the Online Archive of California (OAC). Stating that usability and user needs are primary factors in digital resource development, issues explored include collaborations to build digital collections, reliance upon professional standards for description and encoding, system architecture, interface design, the need for user tools, and the role of archivists as interpreters in the digital environment","provide a context for the exploration of user define virtual collection , the article describe the history and recent development of the online archive of california -LRB- oac -RRB- . state that usability and user need be primary factor in digital resource development , issue explore include collaboration to build digital collection , reliance upon professional standard for description and encoding , system architecture , interface design , the need for user tool , and the role of archivist as interpreter in the digital environment",75,0.666666667
7147,Computers and IT,"To date, online archival information systems have relied heavily on legacy finding aids for data to encode and provide to end users, despite fairly strong indications in the archival literature that such legacy data is problematic even as a mediated access tool. Archivists have only just begun to study the utility of archival descriptive data for end users in unmediated settings such as via the Web. The ability of future archival information systems to respond to the expectations and needs of end users is inextricably linked to archivists getting their collective data house in order. The General International Standard Archival Description (ISAD(G)) offers the profession a place from which to start extricating ourselves from the idiosyncracies of our legacy data and description practices","to date , online archival information system have rely heavily on legacy finding aid for data to encode and provide to end user , despite fairly strong indication in the archival literature that such legacy data be problematic even as a mediated access tool . archivist have only just begin to study the utility of archival descriptive data for end user in unmediated setting such as via the web . the ability of future archival information system to respond to the expectation and need of end user be inextricably link to archivist get their collective data house in order . the general international standard archival description -LRB- isad -LRB- g -RRB- -RRB- offer the profession a place from which to start extricate ourselves from the idiosyncracie of our legacy data and description practice",123,0.733333333
7148,Computers and IT,"An approach to identification of evolving fuzzy rule-based (eR) models is proposed. eR models implement a method for the noniterative update of both the rule-base structure and parameters by incremental unsupervised learning. The rule-base evolves by adding more informative rules than those that previously formed the model. In addition, existing rules can be replaced with new rules based on ranking using the informative potential of the data. In this way, the rule-base structure is inherited and updated when new informative data become available, rather than being completely retrained. The adaptive nature of these evolving rule-based models, in combination with the highly transparent and compact form of fuzzy rules, makes them a promising candidate for modeling and control of complex processes, competitive to neural networks. The approach has been tested on a benchmark problem and on an air-conditioning component modeling application using data from an installation serving a real building. The results illustrate the viability and efficiency of the approach","an approach to identification of evolve fuzzy rule-based -LRB- er -RRB- model be propose .  model implement a method for the noniterative update of both the rule-base structure and parameter by incremental unsupervised learning . the rule-base evolve by add more informative rule than those that previously form the model . in addition , exist rule can be replace with new rule base on ranking use the informative potential of the data . in this way , the rule-base structure be inherit and update when new informative data become available , rather than be completely retrain . the adaptive nature of these evolve rule-based model , in combination with the highly transparent and compact form of fuzzy rule , make them a promising candidate for modeling and control of complex process , competitive to neural network . the approach have be test on a benchmark problem and on an air-conditioning component modeling application use data from an installation serve a real building . the result illustrate the viability and efficiency of the approach",159,0.5
7149,Computers and IT,Virtual collections are a distinct sub-species of digital collections and digital archives. Archivists and curators as archivists and curators do not construct virtual collections; rather they enable virtual collections through the application of descriptive and other standards. Virtual collections are constructed by end users,virtual collection be a distinct sub-specie of digital collection and digital archive . archivist and curator as archivist and curator do not construct virtual collection ; rather they enable virtual collection through the application of descriptive and other standard . virtual collection be construct by end user,44,0.75
7150,Computers and IT,"As the American labor movement continues on its path toward reorganization and rejuvenation, archivists are challenged to ensure that the organizational, political, and cultural changes labor unions are experiencing are fully documented. The article examines the need for labor archivists to reach out actively to unions and the problems they face in getting their message across, not only to union leadership but also to union members. Outreach by labor archivists is vital on three critical fronts: the need to secure union funding in support of labor archival programs; obtaining union cooperation in reviewing and amending obsolete deposit agreements; and coordinating efforts with unions to save the records of closing district and local union offices. Attempting to resolve these outstanding issues, labor archivists are pulled between two distinct institutional cultures (one academic in nature, the other enmeshed in a union bureaucracy) and often have their own labor archival programs compromised by the internal dynamics and politics inherent in administering large academic libraries and unions. If labor archivists are to be successful, they must find their collective voice within the labor movement and establish their relevancy to unions during a period of momentous change and restructuring. Moreover, archivists need to give greater thought to designing and implementing outreach programs that bridge the fundamental ""disconnect"" between union bureaucracies and the rank and file, and unions and the public","as the american labor movement continue on its path toward reorganization and rejuvenation , archivist be challenge to ensure that the organizational , political , and cultural change labor union be experience be fully document . the article examine the need for labor archivist to reach out actively to union and the problem they face in get their message across , not only to union leadership but also to union member . outreach by labor archivist be vital on three critical front : the need to secure union funding in support of labor archival program ; obtain union cooperation in review and amend obsolete deposit agreement ; and coordinate effort with union to save the record of close district and local union office . attempt to resolve these outstanding issue , labor archivist be pull between two distinct institutional culture -LRB- one academic in nature , the other enmesh in a union bureaucracy -RRB- and often have their own labor archival program compromise by the internal dynamic and politics inherent in administer large academic library and union . if labor archivist be to be successful , they must find their collective voice within the labor movement and establish their relevancy to union during a period of momentous change and restructuring . moreover , archivist need to give great thought to design and implement outreach program that bridge the fundamental `` disconnect '' between union bureaucracy and the rank and file , and union and the public",225,0.944444444
7151,Computers and IT,"The article reports the results of a survey conducted to assess the impact that the implementation of Encoded Archival Description (EAD) has on archival programs. By gathering data related to the funding, staffing, and evaluation of EAD programs and about institutional goals for EAD implementation, the study explored how EAD has affected the operations of the institutions which are utilizing it and the extent to which EAD has become a part of regular repository functions","the article report the result of a survey conduct to assess the impact that the implementation of encoded archival description -LRB- ead -RRB- have on archival program . by gather data relate to the funding , staffing , and evaluation of ead program and about institutional goal for ead implementation , the study explore how ead have affect the operation of the institution which be utilize it and the extent to which ead have become a part of regular repository function",75,0.636363636
7152,Computers and IT,"Providing K-12 schools with digital access to archival materials can strengthen both student learning and archival practice, although it cannot replace direct physical access to records. The article compares a variety of electronic and nonelectronic projects to promote teaching with primary source materials. The article also examines some of the different historiographical and pedagogical approaches used in archival Web sites geared for K-12 instruction, focusing on differences between the educational sites sponsored by the Library of Congress and the National Archives and Records Administration","provide k-12 school with digital access to archival material can strengthen both student learning and archival practice , although it can not replace direct physical access to record . the article compare a variety of electronic and nonelectronic project to promote teaching with primary source material . the article also examine some of the different historiographical and pedagogical approach use in archival web site gear for k-12 instruction , focus on difference between the educational site sponsor by the library of congress and the national archive and record administration",84,0.933333333
7153,Computers and IT,"Many archivists regard the archival imagination evidenced in the writings of David Bearman as avant-garde. Archivist L. Henry (1998) has sharply criticized Bearman for being irreverent toward the archival theory and practice outlined by classical American archivist T. R. Schellenberg. Although Bearman is sometimes credited (and sometimes berated) for establishing ""a new paradigm"" centered on the archival management of electronic records, his methods and strategies are intended to encompass all forms of record keeping. The article provides general observations on Bearman's archival imagination, lists some of its components, and addresses elements of Henry's critique. Although the long lasting impact of Bearman's imagination upon the archival profession might be questioned, it nonetheless deserves continued consideration by archivists and inclusion as a component of graduate archival education","many archivist regard the archival imagination evidence in the writing of david bearman as avant-garde . archivist l. henry -LRB- 1998 -RRB- have sharply criticize bearman for be irreverent toward the archival theory and practice outline by classical american archivist t. r. schellenberg . although bearman be sometimes credit -LRB- and sometimes berate -RRB- for establish `` a new paradigm '' center on the archival management of electronic record , his method and strategy be intend to encompass all form of record keep . the article provide general observation on bearman 's archival imagination , list some of its component , and address element of henry 's critique . although the long lasting impact of bearman 's imagination upon the archival profession might be question , it nonetheless deserve continued consideration by archivist and inclusion as a component of graduate archival education",125,1
7154,Computers and IT,"For pt. I see ibid. , vol. 23, p. 1176-87 (2002). Fuzzy logic based algorithms for the quantitative treatment of complementarity of molecular surfaces are presented. Therein, the overlapping surface patches defined in part I of this series are used. The identification of complementary surface patches can be considered as a first step for the solution of molecular docking problems. Standard technologies can then be used for further optimization of the resulting complex structures. The algorithms are applied to 33 biomolecular complexes. After the optimization with a downhill simplex method, for all these complexes one structure was found, which is in very good agreement with the experimental results","for pt . i see ibid . , vol . 23 , p. 1176-87 -LRB- 2002 -RRB- . fuzzy logic base algorithm for the quantitative treatment of complementarity of molecular surface be present . therein , the overlap surface patch define in part i of this series be use . the identification of complementary surface patch can be consider as a first step for the solution of molecular docking problem . standard technology can then be use for further optimization of the result complex structure . the algorithm be apply to 33 biomolecular complex . after the optimization with a downhill simplex method , for all these complex one structure be find , which be in very good agreement with the experimental result",108,0.777777778
7155,Computers and IT,"A new method for the characterization of molecules based on the model approach of molecular surfaces is presented. We use the topographical properties of the surface as well as the electrostatic potential, the local lipophilicity/hydrophilicity, and the hydrogen bond density on the surface for characterization. The definition and the calculation method for these properties are reviewed. The surface is segmented into overlapping patches with similar molecular properties. These patches can be used to represent the characteristic local features of the molecule in a way that is beyond the atomistic resolution but can nevertheless be applied for the analysis of partial similarities of different molecules as well as for the identification of molecular complementarity in a very general sense. The patch representation can be used for different applications, which will be demonstrated in subsequent articles","a new method for the characterization of molecule base on the model approach of molecular surface be present . we use the topographical property of the surface as well as the electrostatic potential , the local lipophilicity/hydrophilicity , and the hydrogen bond density on the surface for characterization . the definition and the calculation method for these property be review . the surface be segmented into overlap patch with similar molecular property . these patch can be use to represent the characteristic local feature of the molecule in a way that be beyond the atomistic resolution but can nevertheless be apply for the analysis of partial similarity of different molecule as well as for the identification of molecular complementarity in a very general sense . the patch representation can be use for different application , which will be demonstrate in subsequent article",134,0.789473684
7156,Computers and IT,"We present the parallel version of a previous serial algorithm for the efficient calculation of canonical MP2 energies. It is based on the Saebo-Almlof direct-integral transformation, coupled with an efficient prescreening of the AO integrals. The parallel algorithm avoids synchronization delays by spawning a second set of slaves during the bin-sort prior to the second half-transformation. Results are presented for systems with up to 2000 basis functions. MP2 energies for molecules with 400-500 basis functions can be routinely calculated to microhartree accuracy on a small number of processors (6-8) in a matter of minutes with modern PC-based parallel computers","we present the parallel version of a previous serial algorithm for the efficient calculation of canonical mp2 energy . it be base on the saebo-almlof direct-integral transformation , couple with an efficient prescreening of the ao integral . the parallel algorithm avoid synchronization delay by spawn a second set of slave during the bin-sort prior to the second half-transformation . result be present for system with up to 2000 basis function . mp2 energy for molecule with 400-500 basis function can be routinely calculate to microhartree accuracy on a small number of processor -LRB- 6-8 -RRB- in a matter of minute with modern pc-based parallel computer",99,1
7157,Computers and IT,"We describe a new method to analyze multiple correlations between subsets of coordinates that represent a sample. The correlation is established only between specific regions of interest at the coordinates. First, the region(s) of interest are selected at each molecular coordinate. Next, a correlation matrix is constructed for the selected regions. The matrix is subject to further analysis, illuminating the multidimensional structural characteristics that exist in the conformational space. The method's abilities are demonstrated in several examples: it is used to analyze the conformational space of complex molecules, it is successfully applied to compare related conformational spaces, and it is used to analyze a diverse set of protein folding trajectories","we describe a new method to analyze multiple correlation between subset of coordinate that represent a sample . the correlation be establish only between specific region of interest at the coordinate . first , the region -LRB- s -RRB- of interest be select at each molecular coordinate . next , a correlation matrix be construct for the select region . the matrix be subject to further analysis , illuminate the multidimensional structural characteristic that exist in the conformational space . the method 's ability be demonstrate in several example : it be use to analyze the conformational space of complex molecule , it be successfully apply to compare related conformational space , and it be use to analyze a diverse set of protein folding trajectory",110,0.777777778
7158,Computers and IT,"A novel genetic algorithm guided selection method, GAS, has been described. The method utilizes a simple encoding scheme which can represent both compounds and variables used to construct a QSAR/QSPR model. A genetic algorithm is then utilized to simultaneously optimize the encoded variables that include both descriptors and compound subsets. The GAS method generates multiple models each applying to a subset of the compounds. Typically the subsets represent clusters with different chemotypes. Also a procedure based on molecular similarity is presented to determine which model should be applied to a given test set compound. The variable selection method implemented in GAS has been tested and compared using the Selwood data set (n = 31 compounds; nu = 53 descriptors). The results showed that the method is comparable to other published methods. The subset selection method implemented in GAS has been first tested using an artificial data set (n = 100 points; nu = 1 descriptor) to examine its ability to subset data points and second applied to analyze the XLOGP data set (n = 1831 compounds; nu = 126 descriptors). The method is able to correctly identify artificial data points belonging to various subsets. The analysis of the XLOGP data set shows that the subset selection method can be useful in improving a QSAR/QSPR model when the variable selection method fails","a novel genetic algorithm guide selection method , gas , have be describe . the method utilize a simple encode scheme which can represent both compound and variable use to construct a qsar/qspr model . a genetic algorithm be then utilize to simultaneously optimize the encoded variable that include both descriptor and compound subset . the gas method generate multiple model each apply to a subset of the compound . typically the subset represent cluster with different chemotype . also a procedure base on molecular similarity be present to determine which model should be apply to a give test set compound . the variable selection method implement in gas have be test and compare use the selwood data set -LRB- n = 31 compound ; nu = 53 descriptor -RRB- . the result show that the method be comparable to other publish method . the subset selection method implement in gas have be first test use an artificial data set -LRB- n = 100 point ; nu = 1 descriptor -RRB- to examine its ability to subset data point and second apply to analyze the xlogp data set -LRB- n = 1831 compound ; nu = 126 descriptor -RRB- . the method be able to correctly identify artificial data point belong to various subset . the analysis of the xlogp data set show that the subset selection method can be useful in improve a qsar/qspr model when the variable selection method fail",221,0.941176471
7159,Computers and IT,"We study the determination of weights for quasi-weighted means (also called quasi-linear means) when a set of examples is given. We consider first a simple case, the learning of weights for weighted means, and then we extend the approach to the more general case of a quasi-weighted mean. We consider the case of a known arbitrary generator f. The paper finishes considering the use of parametric functions that are suitable when the values to aggregate are measure values or ratio","we study the determination of weight for quasi-weighted mean -LRB- also call quasi-linear mean -RRB- when a set of example be give . we consider first a simple case , the learning of weight for weighted mean , and then we extend the approach to the more general case of a quasi-weighted mean . we consider the case of a know arbitrary generator f. the paper finish consider the use of parametric function that be suitable when the value to aggregate be measure value or ratio",80,0.833333333
7160,Computers and IT,"A molecular equivalence number (meqnum) classifies a molecule with respect to a class of structural features or topological shapes such as its cyclic system or its set of functional groups. Meqnums can be used to organize molecular structures into nonoverlapping, yet highly relatable classes. We illustrate the construction of some different types of meqnums and present via examples some methods of comparing diverse chemical libraries based on meqnums. In the examples we compare a library which is a random sample from the MDL Drug Data Report (MDDR) with a library which is a random sample from the Available Chemical Directory (ACD). In our analyses, we discover some interesting features of the topological shape of a molecule and its set of functional groups that are strongly linked with compounds occurring in the MDDR but not in the ACD. We also illustrate the utility of molecular equivalence indices in delineating the structural domain over which an SAR conclusion is valid","a molecular equivalence number -LRB- meqnum -RRB- classify a molecule with respect to a class of structural feature or topological shape such as its cyclic system or its set of functional group . meqnum can be use to organize molecular structure into nonoverlapping , yet highly relatable class . we illustrate the construction of some different type of meqnum and present via example some method of compare diverse chemical library base on meqnum . in the example we compare a library which be a random sample from the mdl drug data report -LRB- mddr -RRB- with a library which be a random sample from the available chemical directory -LRB- acd -RRB- . in our analysis , we discover some interesting feature of the topological shape of a molecule and its set of functional group that be strongly link with compound occur in the mddr but not in the acd . we also illustrate the utility of molecular equivalence index in delineate the structural domain over which an sar conclusion be valid",158,0.818181818
7161,Computers and IT,"Despite their growing popularity among neural network practitioners, ensemble methods have not been widely adopted in structure-activity and structure-property correlation. Neural networks are inherently unstable, in that small changes in the training set and/or training parameters can lead to large changes in their generalization performance. Recent research has shown that by capitalizing on the diversity of the individual models, ensemble techniques can minimize uncertainty and produce more stable and accurate predictors. In this work, we present a critical assessment of the most common ensemble technique known as bootstrap aggregation, or bagging, as applied to QSAR and QSPR. Although aggregation does offer definitive advantages, we demonstrate that bagging may not be the best possible choice and that simpler techniques such as retraining with the full sample can often produce superior results. These findings are rationalized using Krogh and Vedelsby's (1995) decomposition of the generalization error into a term that measures the average generalization performance of the individual networks and a term that measures the diversity among them. For networks that are designed to resist over-fitting, the benefits of aggregation are clear but not overwhelming","despite their grow popularity among neural network practitioner , ensemble method have not be widely adopt in structure-activity and structure-property correlation . neural network be inherently unstable , in that small change in the training set and/or training parameter can lead to large change in their generalization performance . recent research have show that by capitalize on the diversity of the individual model , ensemble technique can minimize uncertainty and produce more stable and accurate predictor . in this work , we present a critical assessment of the most common ensemble technique know as bootstrap aggregation , or bagging , as apply to qsar and qspr . although aggregation do offer definitive advantage , we demonstrate that bag may not be the best possible choice and that simple technique such as retrain with the full sample can often produce superior result . these finding be rationalize use krogh and vedelsby 's -LRB- 1995 -RRB- decomposition of the generalization error into a term that measure the average generalization performance of the individual network and a term that measure the diversity among them . for network that be design to resist over-fitting , the benefit of aggregation be clear but not overwhelming",183,0.769230769
7162,Computers and IT,"A method termed median partitioning (MP) has been developed to select diverse sets of molecules from large compound pools. Unlike many other methods for subset selection, the MP approach does not depend on pairwise comparison of molecules and can therefore be applied to very large compound collections. The only time limiting step is the calculation of molecular descriptors for database compounds. MP employs arrays of property descriptors with little correlation to divide large compound pools into partitions from which representative molecules can be selected. In each of n subsequent steps, a population of molecules is divided into subpopulations above and below the median value of a property descriptor until a desired number of 2/sup n/ partitions are obtained. For descriptor evaluation and selection, an entropy formulation was embedded in a genetic algorithm. MP has been applied to generate a subset of the Available Chemicals Directory, and the results have been compared with cell-based partitioning","a method term median partitioning -LRB- mp -RRB- have be develop to select diverse set of molecule from large compound pool . unlike many other method for subset selection , the mp approach do not depend on pairwise comparison of molecule and can therefore be apply to very large compound collection . the only time limit step be the calculation of molecular descriptor for database compound . mp employ array of property descriptor with little correlation to divide large compound pool into partition from which representative molecule can be select . in each of n subsequent step , a population of molecule be divide into subpopulation above and below the median value of a property descriptor until a desire number of 2/sup n / partition be obtain . for descriptor evaluation and selection , an entropy formulation be embed in a genetic algorithm . mp have be apply to generate a subset of the available chemical directory , and the result have be compare with cell-based partitioning",154,0.833333333
7163,Computers and IT,"Scaling is a difficult issue for any analysis of chemical properties or molecular topology when disparate descriptors are involved. To compare properties across different data sets, a common scale must be defined. Using several publicly available databases (ACD, CMC, MDDR, and NCI) as a basis, we propose to define chemically meaningful scales for a number of molecular properties and topology descriptors. These chemically derived scaling functions have several advantages. First, it is possible to define chemically relevant scales, greatly simplifying similarity and diversity analyses across data sets. Second, this approach provides a convenient method for setting descriptor boundaries that define chemically reasonable topology spaces. For example, descriptors can be scaled so that compounds with little potential for biological activity, bioavailability, or other drug-like characteristics are easily identified as outliers. We have compiled scaling values for 314 molecular descriptors. In addition the 10th and 90th percentile values for each descriptor have been calculated for use in outlier filtering","scale be a difficult issue for any analysis of chemical property or molecular topology when disparate descriptor be involve . to compare property across different data set , a common scale must be define . use several publicly available database -LRB- acd , cmc , mddr , and nci -RRB- as a basis , we propose to define chemically meaningful scale for a number of molecular property and topology descriptor . these chemically derive scaling function have several advantage . first , it be possible to define chemically relevant scale , greatly simplify similarity and diversity analysis across data set . second , this approach provide a convenient method for set descriptor boundary that define chemically reasonable topology space . for example , descriptor can be scale so that compound with little potential for biological activity , bioavailability , or other drug-like characteristic be easily identify as outlier . we have compile scale value for 314 molecular descriptor . in addition the 10th and 90th percentile value for each descriptor have be calculate for use in outli filter",157,0.6875
7164,Computers and IT,"The PLS variant of the MTD method (T. I. Oprea et al. , SAR QSAR Environ. Res. 2001, 12, 75-92) was applied to a series of 25 acetylcholinesterase hydrolysis substrates. Statistically significant MTD-PLS models (q/sup 2/ between 0. 7 and 0. 8) are in agreement with previous MTD models, with the advantage that local contributions are understood beyond the occupancy/nonoccupancy interpretation in MTD. A ""chemically intuitive"" approach further forces MTD-PLS coefficients to assume only negative (or zero) values for fragmental volume descriptors and positive (or zero) values for fragmental hydrophobicity descriptors. This further separates the various kinds of local interactions at each vertex of the MTD hypermolecule, making this method suitable for medicinal chemistry synthesis planning","the pl variant of the mtd method -LRB- t. i. oprea et al. , sar qsar environ . re . 2001 , 12 , 75-92 -RRB- be apply to a series of 25 acetylcholinesterase hydrolysis substrat . statistically significant mtd-pl model -LRB- q/sup 2 / between 0 . 7 and 0 . 8 -RRB- be in agreement with previous mtd model , with the advantage that local contribution be understand beyond the occupancy/nonoccupancy interpretation in mtd . a `` chemically intuitive '' approach further force mtd-pls coefficient to assume only negative -LRB- or zero -RRB- value for fragmental volume descriptor and positive -LRB- or zero -RRB- value for fragmental hydrophobicity descriptor . this further separate the various kind of local interaction at each vertex of the mtd hypermolecule , make this method suitable for medicinal chemistry synthesis planning",116,0.263157895
7165,Computers and IT,High performance liquid chromatography (HPLC) with ultraviolet (UV) spectrophotometric detection is a common method for analyzing reaction products in organic chemistry. This procedure would benefit from a computational model for predicting the relative response of organic molecules. Models are now reported for the prediction of the integrated UV absorbance for a diverse set of organic compounds using a quantitative structure-property relationship (QSPR) approach. A seven-descriptor linear correlation with a squared correlation coefficient (R/sup 2/) of 0. 815 is reported for a data set of 521. compounds. Using the sum of ZINDO oscillator strengths in the integration range as an additional descriptor allowed reduction in the number of descriptors producing a robust model for 460 compounds with five descriptors and a squared correlation coefficient 0. 857. The descriptors used in the models are discussed with respect to the physical nature of the UV absorption process,high performance liquid chromatography -LRB- hplc -RRB- with ultraviolet -LRB- uv -RRB- spectrophotometric detection be a common method for analyze reaction product in organic chemistry . this procedure would benefit from a computational model for predict the relative response of organic molecule . model be now report for the prediction of the integrate uv absorbance for a diverse set of organic compound use a quantitative structure-property relationship -LRB- qspr -RRB- approach . a seven-descriptor linear correlation with a square correlation coefficient -LRB- r/sup 2 / -RRB- of 0 . 815 be report for a data set of 521 . compound . use the sum of zindo oscillator strength in the integration range as an additional descriptor allow reduction in the number of descriptor produce a robust model for 460 compound with five descriptor and a square correlation coefficient 0 . 857 . the descriptor use in the model be discuss with respect to the physical nature of the uv absorption process,144,0.5625
7166,Computers and IT,"The Substructural Molecular Fragments method (Solov'ev, V. P. ; Varnek, A. A. ; Wipff, G. J. Chem. Inf. Comput. Sci. 2000, 40, 847-858) was applied to assess stability constants (logK) of the complexes of crown-ethers, polyethers, and glymes with Na/sup +/, K/sup +/, and Cs/sup +/ in methanol. One hundred forty-seven computational models including different fragment sets coupled with linear or nonlinear fitting equations were applied for the data sets containing 69 (Na/sup +/), 123 (K/sup +/), and 31 (Cs/sup +/) compounds. To account for the ""macrocyclic effect"" for crown-ethers, an additional ""cyclicity"" descriptor was used. ""Predicted"" stability constants both for macrocyclic compounds and for their open-chain analogues are in good agreement with the experimental data reported earlier and with those studied experimentally in this work. The macrocyclic effect as a function of cation and ligand is quantitatively estimated for all studied crown-ethers","the substructural molecular fragment method -LRB- solov ` ev , v. p. ; varnek , a. a. ; wipff , g. j. chem . inf . comput . sci . 2000 , 40 , 847-858 -RRB- be apply to assess stability constant -LRB- logk -RRB- of the complex of crown-ether , polyether , and glyme with na/sup + / , k/sup + / , and cs/sup + / in methanol . one hundred forty-seven computational model include different fragment set couple with linear or nonlinear fitting equation be apply for the data set contain 69 -LRB- na/sup + / -RRB- , 123 -LRB- k/sup + / -RRB- , and 31 -LRB- cs/sup + / -RRB- compound . to account for the `` macrocyclic effect '' for crown-ether , an additional `` cyclicity '' descriptor be use . `` predict '' stability constant both for macrocyclic compound and for their open-chain analog be in good agreement with the experimental data report earlier and with those study experimentally in this work . the macrocyclic effect as a function of cation and ligand be quantitatively estimate for all study crown-ether",143,0.45
7167,Computers and IT,"Partial order theory (POT) is an attractive and operationally simple method that allows ordering of compounds, based on selected structural and/or electronic descriptors (modeled order), or based on their end points, e. g. , solubility (experimental order). If the modeled order resembles the experimental order, compounds that are not experimentally investigated can be assigned a position in the model that eventually might lead to a prediction of an end-point value. However, in the application of POT in quantitative structure-activity relationship modeling, only the compounds directly comparable to the noninvestigated compounds are applied. To explore the possibilities of improving the methodology, the theory is extended by application of the so-called linear extensions of the model order. The study show that partial ordering combined with linear extensions appears as a promising tool providing probability distribution curves in the range of possible end-point values for compounds not being experimentally investigated","partial order theory -LRB- pot -RRB- be an attractive and operationally simple method that allow order of compound , base on select structural and/or electronic descriptor -LRB- model order -RRB- , or base on their end point , e. g. , solubility -LRB- experimental order -RRB- . if the model order resemble the experimental order , compound that be not experimentally investigate can be assign a position in the model that eventually might lead to a prediction of an end-point value . however , in the application of pot in quantitative structure-activity relationship modeling , only the compound directly comparable to the noninvestigated compound be apply . to explore the possibility of improve the methodology , the theory be extend by application of the so-called linear extension of the model order . the study show that partial order combine with linear extension appear as a promising tool provide probability distribution curve in the range of possible end-point value for compound not be experimentally investigate",147,0.466666667
7168,Computers and IT,"We introduce several series of novel ZE-isomerism descriptors derived directly from two-dimensional molecular topology. These descriptors make use of a quantity named ZE-isomerism correction, which is added to the vertex degrees of atoms connected by double bonds in Z and E configurations. This approach is similar to the one described previously for topological chirality descriptors (Golbraikh, A. , et al. J. Chem. Inf. Comput. Sci. 2001, 41, 147-158). The ZE-isomerism descriptors include modified molecular connectivity indices, overall Zagreb indices, extended connectivity, overall connectivity, and topological charge indices. They can be either real or complex numbers. Mathematical properties of different subgroups of ZE-isomerism descriptors are discussed. These descriptors circumvent the inability of conventional topological indices to distinguish between Z and E isomers. The applicability of ZE-isomerism descriptors to QSAR analysis is demonstrated in the studies of a series of 131 anticancer agents inhibiting tubulin polymerization","we introduce several series of novel ze-isomerism descriptor derive directly from two-dimensional molecular topology . these descriptor make use of a quantity name ze-isomerism correction , which be add to the vertex degree of atom connect by double bond in z and e configuration . this approach be similar to the one describe previously for topological chirality descriptor -LRB- golbraikh , a. , et al. j. chem . inf . comput . sci . 2001 , 41 , 147-158 -RRB- . the ze-isomerism descriptor include modify molecular connectivity index , overall zagreb index , extend connectivity , overall connectivity , and topological charge index . they can be either real or complex number . mathematical property of different subgroup of ze-isomerism descriptor be discuss . these descriptor circumvent the inability of conventional topological index to distinguish between z and e isomer . the applicability of ze-isomerism descriptor to qsar analysis be demonstrate in the study of a series of 131 anticancer agent inhibit tubulin polymerization",144,0.571428571
7169,Computers and IT,The design for the preliminary study presented was based on the experiences of the international students and faculty members of a small southwest university being surveyed and interviewed. The data collection procedure blends qualitative and quantitative data. A strong consensus was found that supports the study's premise that there is an association between the use of computer mediated communication (CMC) and teaching and learning performance of international students. Both groups believe CMC to be an effective teaching and learning tool by: increasing the frequency and quality of communication between students and instructors; improving language skills through increased writing and communication opportunities; allowing students and instructors to stay current and to compete effectively; providing alternative teaching and learning methods to increase students' confidence in their ability to communicate effectively with peers and instructors; and improving the instructors' pedagogical focus and questioning techniques,the design for the preliminary study present be base on the experience of the international student and faculty member of a small southwest university be survey and interview . the data collection procedure blend qualitative and quantitative data . a strong consensus be find that support the study 's premise that there be an association between the use of computer mediate communication -LRB- cmc -RRB- and teaching and learn performance of international student . both group believe cmc to be an effective teaching and learn tool by : increase the frequency and quality of communication between student and instructor ; improve language skill through increase writing and communication opportunity ; allow student and instructor to stay current and to compete effectively ; provide alternative teaching and learn method to increase student ' confidence in their ability to communicate effectively with peer and instructor ; and improve the instructor ' pedagogical focus and question technique,141,0.823529412
7170,Computers and IT,"Classical automata are formal models of computing with values. Fuzzy automata are generalizations of classical automata where the knowledge about the system's next state is vague or uncertain. It is worth noting that like classical automata, fuzzy automata can only process strings of input symbols. Therefore, such fuzzy automata are still (abstract) devices for computing with values, although a certain vagueness or uncertainty are involved in the process of computation. We introduce a new kind of fuzzy automata whose inputs are instead strings of fuzzy subsets of the input alphabet. These new fuzzy automata may serve as formal models of computing with words. We establish an extension principle from computing with values to computing with words. This principle indicates that computing with words can be implemented with computing with values with the price of a big amount of extra computations","classical automaton be formal model of compute with value . fuzzy automaton be generalization of classical automaton where the knowledge about the system 's next state be vague or uncertain . it be worth note that like classical automaton , fuzzy automaton can only process string of input symbol . therefore , such fuzzy automaton be still -LRB- abstract -RRB- device for compute with value , although a certain vagueness or uncertainty be involve in the process of computation . we introduce a new kind of fuzzy automaton whose input be instead string of fuzzy subset of the input alphabet . these new fuzzy automaton may serve as formal model of compute with word . we establish an extension principle from compute with value to compute with word . this principle indicate that compute with word can be implement with computing with value with the price of a big amount of extra computation",140,0.857142857
7171,Computers and IT,"Much of the traditional schooling in America is built around systems of compliance and control, characteristics which stifle the creative and entrepreneurial instincts of the children who are subjected to these tactics. The article explores a different approach to education, one that involves capturing the interest of the student through the use of problem and project-based instruction delivered via the Internet. Called Entrepreneurs in Action, this program seeks to involve students in a problem at the outset and to promote the learning of traditional subject areas as a process of the problem-solving activities that are undertaken. The program's details are explained, from elementary school through university level courses, and the authors outline their plans to test the efficacy of the program at each level","much of the traditional schooling in america be build around system of compliance and control , characteristic which stifle the creative and entrepreneurial instinct of the child who be subject to these tactic . the article explore a different approach to education , one that involve capture the interest of the student through the use of problem and project-based instruction deliver via the internet . call entrepreneur in action , this program seek to involve student in a problem at the outset and to promote the learning of traditional subject area as a process of the problem-solving activity that be undertake . the program 's detail be explain , from elementary school through university level course , and the author outline their plan to test the efficacy of the program at each level",124,0.909090909
7172,Computers and IT,"A report is given of a qualitative emergent design study of a Science, Technology, Society Interaction (STS) Web-enhanced course. Students' discomfort during the pilot test provided insight into the intellectual scaffolding that preservice secondary science teachers needed to optimize their performance when required to develop understanding through open-ended inquiry in a Web environment. Eight factors identified contributed to student discomfort: computer skills, paradigm shifts, trust, time management, thinking about their own thinking, systematic inquiry, self-assessment, and scientific discourse. These factors suggested developing understanding through inquiry by conducting a self-designed, open-ended, systematic inquiry required autonomous learning involving metacognitive skills and time management skills. To the extent in which students either came into the course with this scaffolding, or developed it during the course, they were successful in learning about STS and its relationship to science teaching. Changes in the Web site made to accommodate learners' needs as they surfaced are described","a report be give of a qualitative emergent design study of a science , technology , society interaction -LRB- st -RRB- web-enhanced course . student ' discomfort during the pilot test provide insight into the intellectual scaffolding that preservice secondary science teacher need to optimize their performance when require to develop understand through open-ended inquiry in a web environment . eight factor identify contribute to student discomfort : computer skill , paradigm shift , trust , time management , think about their own thinking , systematic inquiry , self-assessment , and scientific discourse . these factor suggest develop understand through inquiry by conduct a self-designed , open-ended , systematic inquiry require autonomous learning involve metacognitive skill and time management skill . to the extent in which student either come into the course with this scaffolding , or develop it during the course , they be successful in learn about st and its relationship to science teaching . change in the web site make to accommodate learner ' need as they surface be describe",150,0.869565217
7173,Computers and IT,"The purpose of the study presented was to provide recommendations to teachers who are interested in implementing Internet inquiry projects. Four classes of ninth- and tenth-grade honors students (N = 100) participated in an Internet inquiry project in which they were presented with an ecology question that required them to make a decision based on information that they gathered, analyzed, and synthesized from the Internet and their textbook. Students then composed papers with a rationale for their decision. Students in one group had access to pre-selected relevant Web sites, access to the entire Internet, and were provided with less online support. Students in the other group had access to only pre-selected relevant Web sites, but were provided with more online support. Two of the most important recommendations were: 1) to provide students with more online support; and 2) to provide students with pre-selected relevant Web sites and allow them to search the Internet for information","the purpose of the study present be to provide recommendation to teacher who be interested in implement internet inquiry project . four class of ninth - and tenth-grade honor student -LRB- n = 100 -RRB- participate in an internet inquiry project in which they be present with an ecology question that require them to make a decision base on information that they gather , analyze , and synthesize from the internet and their textbook . student then compose paper with a rationale for their decision . student in one group have access to pre-selected relevant web site , access to the entire internet , and be provide with less online support . student in the other group have access to only pre-selected relevant web site , but be provide with more online support . two of the most important recommendation be : 1 -RRB- to provide student with more online support ; and 2 -RRB- to provide student with pre-selected relevant web site and allow them to search the internet for information",155,1
7174,Computers and IT,"The article describes an innovative hypermedia product for sixth graders in space science: Alien Rescue. Using a problem-based learning approach that is highly interactive, Alien Rescue engages students in scientific investigations aimed at finding solutions to complex and meaningful problems. Problem-based learning (PBL) is an instructional strategy proven to be effective in medical and business fields, and it is increasingly popular in education. However, using PBL in K-12 classrooms is challenging and requires access to rich knowledge bases and cognitive tools. Alien Rescue is designed to provide such cognitive support for successful use of PBL in sixth-grade classrooms. The design and development of Alien Rescue is guided by current educational research. Research is an integral part of this project. Results of formative evaluation and research studies are being integrated into the development and improvement of the program. Alien Rescue is designed in accordance with the National Science Standards and the Texas Essential Knowledge and Skills (TEKS) for science. So far Alien Rescue has been field-tested by approximately 1400 sixth graders. More use in middle schools is in progress and more research on its use is planned","the article describe an innovative hypermedia product for sixth grader in space science : alien rescue . use a problem-based learning approach that be highly interactive , alien rescue engage student in scientific investigation aim at find solution to complex and meaningful problem . problem-based learning -LRB- pbl -RRB- be an instructional strategy prove to be effective in medical and business field , and it be increasingly popular in education . however , use pbl in k-12 classroom be challenging and require access to rich knowledge base and cognitive tool . alien rescue be design to provide such cognitive support for successful use of pbl in sixth-grade classroom . the design and development of alien rescue be guide by current educational research . research be an integral part of this project . result of formative evaluation and research study be be integrate into the development and improvement of the program . alien rescue be design in accordance with the national science standard and the texas essential knowledge and skill -LRB- tek -RRB- for science . so far alien rescue have be field-test by approximately 1400 sixth grader . more use in middle school be in progress and more research on its use be plan",186,0.823529412
7175,Computers and IT,"Using project-based learning pedagogy in EdTc 658 Advances in Educational Technology, the author has trained inservice teachers in Southwestern Louisiana with an advanced computer multimedia program called Director(R) (Macromedia, Inc. ). The content of this course focused on modeling the project-based learning pedagogy and researching Acadian's traditions and legacy. With the multi-functions of microcomputers, new technologies were used to preserve and celebrate the local culture with superiority of text, graphics, animation, sound, and video. The article describes how several groups of school teachers in the surrounding areas of a regional state university of Louisiana learned computer multimedia using project-based learning and integrated their learning into local cultural heritage","use project-based learn pedagogy in edtc 658 advance in educational technology , the author have train inservice teacher in southwestern louisiana with an advanced computer multimedia program call director -LRB- r -RRB- -LRB- macromedia , inc. -RRB- . the content of this course focus on modeling the project-based learning pedagogy and research acadian 's tradition and legacy . with the multi-function of microcomputer , new technology be use to preserve and celebrate the local culture with superiority of text , graphic , animation , sound , and video . the article describe how several group of school teacher in the surround area of a regional state university of louisiana learn computer multimedia use project-based learning and integrate their learning into local cultural heritage",108,0.875
7176,Computers and IT,"Multimedia computing provides a variety of information presentation modality combinations. Educators have observed that visuals enhance learning which suggests that multimedia presentations should be superior to text-only and text with static pictures in facilitating optimal human information processing and, therefore, comprehension. The article reports the findings from a 3 (text-only, overhead slides, and multimedia presentation)*2 (high and low information complexity) factorial experiment. Subjects read a text script, viewed an acetate overhead slide presentation, or viewed a multimedia presentation depicting the greenhouse effect (low complexity) or photocopier operation (high complexity). Multimedia was superior to text-only and overhead slides for comprehension. Information complexity diminished comprehension and perceived presentation quality. Multimedia was able to reduce the negative impact of information complexity on comprehension and increase the extent of sustained attention to the presentation. These findings suggest that multimedia presentations invoke the use of both the verbal and visual working memory channels resulting in a reduction of the cognitive load imposed by increased information complexity. Moreover, multimedia superiority in facilitating comprehension goes beyond its ability to increase sustained attention; the quality and effectiveness of information processing attained (i. e. , use of verbal and visual working memory) is also significant","multimedia compute provide a variety of information presentation modality combination . educator have observe that visual enhance learn which suggest that multimedia presentation should be superior to text-only and text with static picture in facilitate optimal human information processing and , therefore , comprehension . the article report the finding from a 3 -LRB- text-only , overhead slide , and multimedia presentation -RRB- * 2 -LRB- high and low information complexity -RRB- factorial experiment . subject read a text script , view an acetate overhead slide presentation , or view a multimedia presentation depict the greenhouse effect -LRB- low complexity -RRB- or photocopi operation -LRB- high complexity -RRB- . multimedia be superior to text-only and overhead slide for comprehension . information complexity diminish comprehension and perceive presentation quality . multimedia be able to reduce the negative impact of information complexity on comprehension and increase the extent of sustained attention to the presentation . these finding suggest that multimedia presentation invoke the use of both the verbal and visual work memory channel result in a reduction of the cognitive load impose by increase information complexity . moreover , multimedia superiority in facilitate comprehension go beyond its ability to increase sustained attention ; the quality and effectiveness of information processing attain -LRB- i. e. , use of verbal and visual work memory -RRB- be also significant",196,0.727272727
7177,Computers and IT,"The application of in vivo Raman spectroscopy for clinical diagnosis demands dedicated software that can perform the necessary signal processing and subsequent (multivariate) data analysis, enabling clinically relevant parameters to be extracted and made available in real time. Here we describe the design and implementation of a software package that allows for real-time signal processing and data analysis of Raman spectra. The design is based on automatic data exchange between Grams, a spectroscopic data acquisition and analysis program, and Matlab, a program designed for array-based calculations. The data analysis software has a modular design providing great flexibility in developing custom data analysis routines for different applications. The implementation is illustrated by a computationally demanding application for the classification of skin spectra using principal component analysis and linear discriminant analysis","the application of in vivo raman spectroscopy for clinical diagnosis demand dedicate software that can perform the necessary signal processing and subsequent -LRB- multivariate -RRB- data analysis , enable clinically relevant parameter to be extract and make available in real time . here we describe the design and implementation of a software package that allow for real-time signal processing and data analysis of raman spectrum . the design be base on automatic data exchange between gram , a spectroscopic data acquisition and analysis program , and matlab , a program design for array-based calculation . the data analysis software have a modular design provide great flexibility in develop custom data analysis routine for different application . the implementation be illustrate by a computationally demand application for the classification of skin spectrum use principal component analysis and linear discriminant analysis",129,0.642857143
7178,Computers and IT,"When the series resistance is separated and treated as a separate element, it is shown that losses in an inductor require the ratio of the flux to MMF in the core to be frequency dependent. For small-signal operation, this dependence leads to a circuit model composed of a lossless inductor and a resistor in parallel, both of which are frequency dependent. Mathematical expressions for these elements are derived under the assumption that the ratio of core flux to MMF varies as omega /sup n-1/, where n is a constant. A linear regression technique is described for extracting the model parameters from measured data. Experimental data are presented to justify the model for the lossy inductance of a loudspeaker voice-coil. A SPICE example is presented to illustrate the effects of voice-coil inductor losses on the frequency response of a typical driver","when the series resistance be separate and treat as a separate element , it be show that loss in an inductor require the ratio of the flux to mmf in the core to be frequency dependent . for small-signal operation , this dependence lead to a circuit model compose of a lossless inductor and a resistor in parallel , both of which be frequency dependent . mathematical expression for these element be derive under the assumption that the ratio of core flux to mmf vary as omega / sup n-1 / , where n be a constant . a linear regression technique be describe for extract the model parameter from measure data . experimental data be present to justify the model for the lossy inductance of a loudspeaker voice-coil . a spice example be present to illustrate the effect of voice-coil inductor loss on the frequency response of a typical driver",140,0.666666667
7179,Computers and IT,"We study the computational complexity of a very basic problem, namely that of finding solutions to a very large set of random linear equations in a finite Galois field modulo q. Using tools from statistical mechanics we are able to identify phase transitions in the structure of the solution space and to connect them to the changes in the performance of a global algorithm, namely Gaussian elimination. Crossing phase boundaries produces a dramatic increase in memory and CPU requirements necessary for the algorithms. In turn, this causes the saturation of the upper bounds for the running time. We illustrate the results on the specific problem of integer factorization, which is of central interest for deciphering messages encrypted with the RSA cryptosystem","we study the computational complexity of a very basic problem , namely that of find solution to a very large set of random linear equation in a finite galois field modulo q. use tool from statistical mechanic we be able to identify phase transition in the structure of the solution space and to connect them to the change in the performance of a global algorithm , namely gaussian elimination . cross phase boundary produce a dramatic increase in memory and cpu requirement necessary for the algorithm . in turn , this cause the saturation of the upper bound for the run time . we illustrate the result on the specific problem of integer factorization , which be of central interest for decipher message encrypt with the rsa cryptosystem",121,0.571428571
7180,Computers and IT,"We investigate some noise effect on a neural network model proposed by Araki and Aihara (1998) for the memory recall of dynamical patterns in the hippocampus and the entorhinal cortex; the noise effect is important since the release of transmitters at synaptic clefts, the operation of gate of ion channels and so on are known as stochastic phenomena. We consider two kinds of noise effect due to a deterministic noise and a stochastic noise. By numerical simulations, we find that reasonable values of noise give better performance on the memory recall of dynamical patterns. Furthermore we investigate the effect of the strength of external inputs on the memory recall","we investigate some noise effect on a neural network model propose by araki and aihara -LRB- 1998 -RRB- for the memory recall of dynamical pattern in the hippocampus and the entorhinal cortex ; the noise effect be important since the release of transmitter at synaptic cleft , the operation of gate of ion channel and so on be know as stochastic phenomenon . we consider two kind of noise effect due to a deterministic noise and a stochastic noise . by numerical simulation , we find that reasonable value of noise give better performance on the memory recall of dynamical pattern . furthermore we investigate the effect of the strength of external input on the memory recall",109,0.733333333
7181,Computers and IT,"We derive inner- and outer-bound sets for the type-reduced set of an interval type-2 fuzzy logic system (FLS), based on a new mathematical interpretation of the Karnik-Mendel iterative procedure for computing the type-reduced set. The bound sets can not only provide estimates about the uncertainty contained in the output of an interval type-2 FLS, but can also be used to design an interval type-2 FLS. We demonstrate, by means of a simulation experiment, that the resulting system can operate without type-reduction and can achieve similar performance to one that uses type-reduction. Therefore, our new design method, based on the bound sets, can relieve the computation burden of an interval type-2 FLS during its operation, which makes an interval type-2 FLS useful for real-time applications","we derive inner - and outer-bound set for the type-reduced set of an interval type-2 fuzzy logic system -LRB- fl -RRB- , base on a new mathematical interpretation of the karnik-mendel iterative procedure for compute the type-reduced set . the bind set can not only provide estimate about the uncertainty contain in the output of an interval type-2 fl , but can also be use to design an interval type-2 fl . we demonstrate , by mean of a simulation experiment , that the result system can operate without type-reduction and can achieve similar performance to one that use type-reduction . therefore , our new design method , base on the bind set , can relieve the computation burden of an interval type-2 fl during its operation , which make an interval type-2 fl useful for real-time application",124,0.625
7182,Computers and IT,"We present a decoupled discrete time pole placement design method, which can be combined with a self-tuning scheme to compensate variations in the microactuator's (MA's) resonance mode. Section I of the paper describes the design and fabrication of a prototype microactuator with an integrated gimbal structure. Section II presents a decoupled track-following controller design and a self-tuning control scheme to compensate for the MA's resonance mode variations","we present a decoupled discrete time pole placement design method , which can be combine with a self-tuning scheme to compensate variation in the microactuator 's -LRB- ma 's -RRB- resonance mode . section i of the paper describe the design and fabrication of a prototype microactuator with an integrate gimbal structure . section ii present a decoupled track-following controller design and a self-tuning control scheme to compensate for the ma 's resonance mode variation",67,0.4
7183,Computers and IT,"A procedure is described for storing a two-dimensional (2D) pattern consisting of 32*32=1024 bits in a spin state of a molecular system and then retrieving the stored information as a stack of nuclear magnetic resonance spectra. The system used is a nematic liquid crystal, the protons of which act as spin clusters with strong intramolecular interactions. The technique used is a programmable multifrequency irradiation with low amplitude. When it is applied to the liquid crystal, a large number of coherent long-lived /sup 1/H response signals can be excited, resulting in a spectrum showing many sharp peaks with controllable frequencies and amplitudes. The spectral resolution is enhanced by using a second weak pulse with a 90 degrees phase shift, so that the 1024 bits of information can be retrieved as a set of well-resolved pseudo-2D spectra reproducing the input pattern","a procedure be describe for store a two-dimensional -LRB- 2d -RRB- pattern consist of 32 * 32 = 1024 bit in a spin state of a molecular system and then retrieve the store information as a stack of nuclear magnetic resonance spectrum . the system use be a nematic liquid crystal , the proton of which act as spin cluster with strong intramolecular interaction . the technique use be a programmable multifrequency irradiation with low amplitude . when it be apply to the liquid crystal , a large number of coherent long-lived / sup 1/h response signal can be excite , result in a spectrum show many sharp peak with controllable frequency and amplitude . the spectral resolution be enhance by use a second weak pulse with a 90 degree phase shift , so that the 1024 bit of information can be retrieve as a set of well-resolved pseudo-2d spectrum reproduce the input pattern",139,0.454545455
7184,Computers and IT,"Active noise-reducing (ANR) headsets are available commercially in applications varying from aviation communication to consumer audio. Current ANR systems use passive attenuation at high frequencies and loudspeaker-based active noise control at low frequencies to achieve broadband noise reduction. This paper presents a novel ANR headset in which the external noise transmitted to the user's ear via earshell vibration is reduced by controlling the vibration of the earshell using force actuators acting against an inertial mass or the earshell headband. Model-based theoretical analysis using velocity feedback control showed that current piezoelectric actuators provide sufficient force but require lower stiffness for improved low-frequency performance. Control simulations based on experimental data from a laboratory headset showed that good performance can potentially be achieved in practice by a robust feedback controller, while a single-frequency real-time control experiment verified that noise reduction can be achieved using earshell vibration control","active noise-reducing -LRB- anr -RRB- headset be available commercially in application vary from aviation communication to consumer audio . current anr system use passive attenuation at high frequency and loudspeaker-based active noise control at low frequency to achieve broadband noise reduction . this paper present a novel anr headset in which the external noise transmit to the user 's ear via earshell vibration be reduce by control the vibration of the earshell use force actuator act against an inertial mass or the earshell headband . model-based theoretical analysis use velocity feedback control show that current piezoelectric actuator provide sufficient force but require low stiffness for improve low-frequency performance . control simulation base on experimental data from a laboratory headset show that good performance can potentially be achieve in practice by a robust feedback controller , while a single-frequency real-time control experiment verify that noise reduction can be achieve use earshell vibration control",144,0.857142857
7185,Computers and IT,"high-rise buildings A method for theoretically calculating the coherence between sound pressure inside a rectangular room in a high-rise building and that outside the open window of the room is proposed. The traffic noise transmitted into a room is generally dominated by low-frequency components, to which active noise control (ANC) technology may find an application. However, good coherence between reference and error signals is essential for an effective noise reduction and should be checked first. Based on traffic noise prediction methods, wave theory, and mode coupling theory, the results of this paper enabled one to determine the potentials and limitations of ANC used to reduce such a transmission. Experimental coherence results are shown for two similar, empty rectangular rooms located on the 17th and 30th floors of a 34 floor high-rise building. The calculated results with the proposed method are generally in good agreement with the experimental results and demonstrate the usefulness of the method for predicting the coherence","high-rise building a method for theoretically calculate the coherence between sound pressure inside a rectangular room in a high-rise building and that outside the open window of the room be propose . the traffic noise transmit into a room be generally dominate by low-frequency component , to which active noise control -LRB- anc -RRB- technology may find an application . however , good coherence between reference and error signal be essential for an effective noise reduction and should be check first . base on traffic noise prediction method , wave theory , and mode coupling theory , the result of this paper enable one to determine the potential and limitation of anc use to reduce such a transmission . experimental coherence result be show for two similar , empty rectangular room locate on the 17th and 30th floor of a 34 floor high-rise building . the calculated result with the propose method be generally in good agreement with the experimental result and demonstrate the usefulness of the method for predict the coherence",159,0.8
7186,Computers and IT,"The article describes a high-density off-site book storage facility operated by the Ohio State University Libraries. Opened in 1995, it has the capacity to house nearly 1. 5 million items in only 9000 square feet by shelving books by size on 30-foot tall shelving. A sophisticated climate control system extends the life of stored materials up to 12 times. An online catalog record for each item informs patrons that the item is located in a remote location. Regular courier deliveries from the storage facility bring requested materials to patrons with minimal delay","the article describe a high-density off-site book storage facility operate by the ohio state university library . open in 1995 , it have the capacity to house nearly 1 . 5 million item in only 9000 square foot by shelve book by size on 30-foot tall shelving . a sophisticated climate control system extend the life of store material up to 12 time . an online catalog record for each item inform patron that the item be locate in a remote location . regular courier delivery from the storage facility bring request material to patron with minimal delay",92,0.818181818
7187,Computers and IT,"In an effort toward establishing a standard for academic library hours, the article surveys and compares hours of operation and service for ARL libraries and IPEDS survey respondents. The article ranks the ARL (Association for Research Libraries) libraries according to hours of operation and reference hours and then briefly discusses such issues as libraries offering twenty-four access and factors affecting service hour decisions","in an effort toward establish a standard for academic library hour , the article survey and compare hour of operation and service for arl library and iped survey respondent . the article rank the arl -LRB- association for research library -RRB- library accord to hour of operation and reference hour and then briefly discuss such issue as library offer twenty-four access and factor affect service hour decision",63,0.666666667
7188,Computers and IT,"In an effort to help non-law librarians with basic legal reference questions, the author highlights three basic legal Web sites and outlines useful subject-specific Web sites that focus on statutes and regulations, case law and attorney directories","in an effort to help non-law librarian with basic legal reference question , the author highlight three basic legal web site and outline useful subject-specific web site that focus on statute and regulation , case law and attorney directory",37,0.6
7189,Computers and IT,"Describes the role of a systems librarian at a small academic library. Although online catalogs and the Internet are making library accessibility more convenient, the need for library buildings and professionals has not diminished. Typical duties of a systems librarian and the effects of new technology on librarianship are discussed. Services provided to other constituencies on campus and the blurring relationship between the library and computer services are also presented","describe the role of a system librarian at a small academic library . although online catalog and the internet be make library accessibility more convenient , the need for library building and professional have not diminish . typical duty of a system librarian and the effect of new technology on librarianship be discuss . service provide to other constituency on campus and the blur relationship between the library and computer service be also present",70,0.6
7190,Computers and IT,"Advances in technology create dramatic changes within libraries. The complex issues surrounding this new electronic, end-user environment have major ramifications and require expert knowledge. Electronic services librarians and electronic resources librarians are two specialized titles that have recently emerged within the field of librarianship to fill this niche. Job advertisements listed in American Libraries from January 1989 to December 1998 were examined to identify responsibilities, qualifications, organizational and salary information relating to the newly emerging role of electronic librarian","advance in technology create dramatic change within library . the complex issue surround this new electronic , end-us environment have major ramification and require expert knowledge . electronic service librarian and electronic resource librarian be two specialized title that have recently emerge within the field of librarianship to fill this niche . job advertisement list in american library from january 1989 to december 1998 be examine to identify responsibility , qualification , organizational and salary information relate to the newly emerge role of electronic librarian",79,0.636363636
7191,Computers and IT,"Libraries have walls. Recognizing this fact, the Interlibrary Loan Department at Virginia Tech is creating systems and services that enable our customers to reach past our walls at anytime from anywhere. Customer in-reach enables Virginia Tech faculty, students, and staff anywhere in the world to obtain information and services heretofore available only to our on-campus customers. ILLiad, Virginia Tech's interlibrary borrowing system, is the library strategic system that attains this goal. The principles that guided development of ILLiad are widely applicable","library have wall . recognize this fact , the interlibrary loan department at virginia tech be create system and service that enable our customer to reach past our wall at anytime from anywhere . customer in-reach enable virginia tech faculty , student , and staff anywhere in the world to obtain information and service heretofore available only to our on-campus customer . illiad , virginia tech 's interlibrary borrowing system , be the library strategic system that attain this goal . the principle that guide development of illiad be widely applicable",81,1
7192,Computers and IT,"We introduce a concept of fuzzy polynomial neural networks (FPNNs), a hybrid modeling architecture combining polynomial neural networks (PNNs) and fuzzy neural networks (FNNs). The development of the FPNNs dwells on the technologies of computational intelligence (CI), namely fuzzy sets, neural networks, and genetic algorithms. The structure of the FPNN results from a synergistic usage of FNN and PNN. FNNs contribute to the formation of the premise part of the rule-based structure of the FPNN. The consequence part of the FPNN is designed using PNNs. The structure of the PNN is not fixed in advance as it usually takes place in the case of conventional neural networks, but becomes organized dynamically to meet the required approximation error. We exploit a group method of data handling (GMDH) to produce this dynamic topology of the network. The performance of the FPNN is quantified through experimentation that exploits standard data already used in fuzzy modeling. The obtained experimental results reveal that the proposed networks exhibit high accuracy and generalization capabilities in comparison to other similar fuzzy models","we introduce a concept of fuzzy polynomial neural network -LRB- fpnn -RRB- , a hybrid modeling architecture combine polynomial neural network -LRB- pnn -RRB- and fuzzy neural network -LRB- fnn -RRB- . the development of the fpnn dwell on the technology of computational intelligence -LRB- ci -RRB- , namely fuzzy set , neural network , and genetic algorithm . the structure of the fpnn result from a synergistic usage of fnn and pnn . fnn contribute to the formation of the premise part of the rule-based structure of the fpnn . the consequence part of the fpnn be design use pnn . the structure of the pnn be not fix in advance as it usually take place in the case of conventional neural network , but become organize dynamically to meet the required approximation error . we exploit a group method of data handle -LRB- gmdh -RRB- to produce this dynamic topology of the network . the performance of the fpnn be quantify through experimentation that exploit standard data already use in fuzzy modeling . the obtain experimental result reveal that the propose network exhibit high accuracy and generalization capability in comparison to other similar fuzzy model",174,0.470588235
7193,Computers and IT,"Wavelength services have been hyped ad nauseam for years. But despite their quick turn-up time and impressive margins, such services have yet to live up to the industry's expectations. The reasons for this lukewarm reception are many, not the least of which is the confusion that still surrounds the technology, but most industry observers are still convinced that wavelength services with ultimately flourish","wavelength service have be hype ad nauseam for year . but despite their quick turn-up time and impressive margin , such service have yet to live up to the industry 's expectation . the reason for this lukewarm reception be many , not the least of which be the confusion that still surround the technology , but most industry observer be still convince that wavelength service with ultimately flourish",63,0.25
7194,Computers and IT,"The few libraries that have tried thin client architectures have noted a number of compelling reasons to do so. For starters, thin client devices are far less expensive than most PCs. More importantly, thin client computing devices are believed to be far less expensive to manage and support than traditional PCs","the few library that have try thin client architecture have note a number of compelling reason to do so . for starter , thin client device be far less expensive than most pc . more importantly , thin client computing device be believe to be far less expensive to manage and support than traditional pc",51,0
7195,Computers and IT,"I explore the theme of academic libraries serving and reaching out to the broader community. I highlight interesting projects reported on in the literature (such as the Through Our Parents' Eyes project) and report on others. I look at challenges to community partnerships and recommendations for making them succeed. Although I focus on links with the broader community, I also took at methods for increasing cooperation among various units on campus, so that the needs of campus community groups-such as distance education students or disabled students-are effectively addressed. Though academic libraries are my focus, we can learn a lot from the community building efforts of public libraries","i explore the theme of academic library serve and reach out to the broad community . i highlight interesting project report on in the literature -LRB- such as the through our parent ' eye project -RRB- and report on other . i look at challenge to community partnership and recommendation for make them succeed . although i focus on link with the broad community , i also take at method for increase cooperation among various unit on campus , so that the need of campus community groups-such as distance education student or disabled students-are effectively address . though academic library be my focus , we can learn a lot from the community building effort of public library",107,1
7196,Computers and IT,"The present research investigated Internet search engines as a rapid, cost-effective alternative for estimating word frequencies. Frequency estimates for 382 words were obtained and compared across four methods: (1) Internet search engines, (2) the Kucera and Francis (1967) analysis of a traditional linguistic corpus, (3) the CELEX English linguistic database (Baayen et al. , 1995), and (4) participant ratings of familiarity. The results showed that Internet search engines produced frequency estimates that were highly consistent with those reported by Kucera and Francis and those calculated from CELEX, highly consistent across search engines, and very reliable over a 6 month period of time. Additional results suggested that Internet search engines are an excellent option when traditional word frequency analyses do not contain the necessary data (e. g. , estimates for forenames and slang). In contrast, participants' familiarity judgments did not correspond well with the more objective estimates of word frequency. Researchers are advised to use search engines with large databases (e. g. , AltaVista) to ensure the greatest representativeness of the frequency estimates","the present research investigate internet search engine as a rapid , cost-effective alternative for estimate word frequency . frequency estimate for 382 word be obtain and compare across four method : -LRB- 1 -RRB- internet search engine , -LRB- 2 -RRB- the kucera and franci -LRB- 1967 -RRB- analysis of a traditional linguistic corpus , -LRB- 3 -RRB- the celex english linguistic database -LRB- baayen et al. , 1995 -RRB- , and -LRB- 4 -RRB- participant rating of familiarity . the result show that internet search engine produce frequency estimate that be highly consistent with those report by kucera and franci and those calculate from celex , highly consistent across search engine , and very reliable over a 6 month period of time . additional result suggest that internet search engine be an excellent option when traditional word frequency analysis do not contain the necessary data -LRB- e. g. , estimate for forename and slang -RRB- . in contrast , participant ' familiarity judgment do not correspond well with the more objective estimate of word frequency . researcher be advise to use search engine with large database -LRB- e. g. , altavista -RRB- to ensure the great representativenes of the frequency estimate",172,0.666666667
7197,Computers and IT,"Word difficulty varies from language to language; therefore, normative data of verbal stimuli cannot be imported directly from another language. We present mean identification thresholds for the 260 screen-fragmented words corresponding to the total set of Snodgrass and Vanderwart (1980) pictures. Individual words were fragmented in eight levels using Turbo Pascal, and the resulting program was implemented on a PC microcomputer. The words were presented individually to a group of 40 Spanish observers, using a controlled time procedure. An unspecific learning effect was found showing that performance improved due to practice with the task. Finally, of the 11 psycholinguistic variables that previous researchers have shown to affect word identification, only imagery accounted for a significant amount of variance in the threshold values","word difficulty vary from language to language ; therefore , normative data of verbal stimulus can not be import directly from another language . we present mean identification threshold for the 260 screen-fragmented word corresponding to the total set of snodgras and vanderwart -LRB- 1980 -RRB- picture . individual word be fragment in eight level use turbo pascal , and the result program be implement on a pc microcomputer . the word be present individually to a group of 40 spanish observer , use a controlled time procedure . an unspecific learning effect be find show that performance improve due to practice with the task . finally , of the 11 psycholinguistic variable that previous researcher have show to affect word identification , only imagery account for a significant amount of variance in the threshold value",122,0.785714286
7198,Computers and IT,"In 1981, the Japanese government published a list of the 1, 945 basic Japanese kanji (Jooyoo Kanji-hyo), including specifications of pronunciation. This list was established as the standard for kanji usage in print. The database for 1, 945 basic Japanese kanji provides 30 cells that explain in detail the various characteristics of kanji. Means, standard deviations, distributions, and information related to previous research concerning these kanji are provided in this paper. The database is saved as a Microsoft Excel 2000 file for Windows. This kanji database is accessible on the Web site of the Oxford Text Archive, Oxford University (http://ota. ahds. ac. uk). Using this database, researchers and educators will be able to conduct planned experiments and organize classroom instruction on the basis of the known characteristics of selected kanji","in 1981 , the japanese government publish a list of the 1 , 945 basic japanese kanji -LRB- jooyoo kanji-hyo -RRB- , include specification of pronunciation . this list be establish as the standard for kanji usage in print . the database for 1 , 945 basic japanese kanji provide 30 cell that explain in detail the various characteristic of kanji . mean , standard deviation , distribution , and information relate to previous research concern these kanji be provide in this paper . the database be save as a microsoft excel 2000 file for window . this kanji database be accessible on the web site of the oxford text archive , oxford university -LRB- http://ota . ahd . ac . uk -RRB- . use this database , researcher and educator will be able to conduct planned experiment and organize classroom instruction on the basis of the know characteristic of select kanji",130,0.75
7199,Computers and IT,"Fast full-screen presentation of stimuli is necessary in psychological research. Although Spitczok von Brisinski (1994) introduced a method that achieved ultrafast display by reprogramming the registers, he could not produce an acceptable full-screen display. In this report, the author introduces a new method combining VESA routine calling with register reprogramming that can yield a display at 640 * 480 resolution, with a refresh rate of about 150 Hz","fast full-screen presentation of stimulus be necessary in psychological research . although spitczok von brisinski -LRB- 1994 -RRB- introduce a method that achieve ultrafast display by reprogramm the register , he could not produce an acceptable full-screen display . in this report , the author introduce a new method combine vesa routine call with register reprogramm that can yield a display at 640 * 480 resolution , with a refresh rate of about 150 hz",68,0.333333333
7200,Computers and IT,"The response characteristics of PC keyboards have to be identified when they are used as response devices in psychological experiments. In the past, the proposed method has been to check the characteristics independently by means of external measurement equipment. However, with the availability of different PC models and the rapid pace of model change, there is an urgent need for the development of convenient and accurate methods of checking. The method proposed consists of raising the precision of the PC's clock to the microsecond level and using a joystick connected to the MIDI terminal of a sound board to give the PC an independent timing function. Statistical processing of the data provided by this method makes it possible to estimate accurately the keyboard scanning interval time and the average keyboard delay time. The results showed that measured keyboard delay times varied from 11 to 73 msec, depending on the keyboard model, with most values being less than 30 msec","the response characteristic of pc keyboard have to be identify when they be use as response device in psychological experiment . in the past , the propose method have be to check the characteristic independently by mean of external measurement equipment . however , with the availability of different pc model and the rapid pace of model change , there be an urgent need for the development of convenient and accurate method of checking . the method propose consist of raise the precision of the pc 's clock to the microsecond level and use a joystick connect to the midi terminal of a sound board to give the pc an independent timing function . statistical processing of the data provide by this method make it possible to estimate accurately the keyboard scan interval time and the average keyboard delay time . the result show that measure keyboard delay time vary from 11 to 73 msec , depend on the keyboard model , with most value be less than 30 msec",159,0.642857143
7201,Computers and IT,"A computer program for programming schedules of reinforcement is described. Students can use the program to experience schedules of reinforcement that are typically used with nonhuman subjects. Accumulative recording of a student's response can be shown on the screen and/or printed with the computer's printer. The program can also be used to program operant schedules for animal subjects. The program was tested with human subjects experiencing fixed ratio, variable ratio, fixed interval, and variable interval schedules. Performance for human subjects on a given schedule was similar to performance for nonhuman subjects on the same schedule","a computer program for programming schedule of reinforcement be describe . student can use the program to experience schedule of reinforcement that be typically use with nonhuman subject . accumulative recording of a student 's response can be show on the screen and/or print with the computer 's printer . the program can also be use to program operant schedule for animal subject . the program be test with human subject experience fix ratio , variable ratio , fix interval , and variable interval schedule . performance for human subject on a give schedule be similar to performance for nonhuman subject on the same schedule",95,0.454545455
7202,Computers and IT,"The Homework/Quiz/Exam applet is a freely available Java program that can be used to evaluate student performance on line for any content authored by a teacher. It has database connectivity so that student scores are automatically recorded. It allows several different types of questions. Each question can be linked to images and detailed story problems. Three levels of feedback are provided to student responses. It allows teachers to randomize the sequence of questions and to randomize which of several options is the correct answer in multiple-choice questions. The creation and editing of questions involves menu selections, button presses, and the typing of content; no programming knowledge is required. The code is open source in order to encourage modifications that will meet individual pedagogical needs","the homework/quiz/exam applet be a freely available java program that can be use to evaluate student performance on line for any content author by a teacher . it have database connectivity so that student score be automatically record . it allow several different type of question . each question can be link to image and detailed story problem . three level of feedback be provide to student response . it allow teacher to randomize the sequence of question and to randomize which of several option be the correct answer in multiple-choice question . the creation and editing of question involve menu selection , button press , and the typing of content ; no programming knowledge be require . the code be open source in order to encourage modification that will meet individual pedagogical need",124,0.470588235
7203,Computers and IT,"WEXTOR is a Javascript-based experiment generator and teaching tool on the World Wide Web that can be used to design laboratory and Web experiments in a guided step-by-step process. It dynamically creates the customized Web pages and Javascripts needed for the experimental procedure and provides experimenters with a print-ready visual display of their experimental design. WEXTOR flexibly supports complete and incomplete factorial designs with between-subjects, within-subjects, and quasi-experimental factors, as well as mixed designs. The software implements client-side response time measurement and contains a content wizard for creating interactive materials, as well as dependent measures (graphical scales, multiple-choice items, etc. ), on the experiment pages. However, it does not aim to replace a full-fledged HTML editor. Several methodological features specifically needed in Web experimental design have been implemented in the Web-based tool and are described in this paper. WEXTOR is platform independent. The created Web pages can be uploaded to any type of Web server in which data may be recorded in logfiles or via a database. The current version of WEXTOR is freely available for educational and noncommercial purposes. Its Web address is http://www. genpsylab. unizh. ch/wextor/index. html","wextor be a javascript-based experiment generator and teaching tool on the world wide web that can be use to design laboratory and web experiment in a guide step-by-step process . it dynamically create the customize web page and javascript need for the experimental procedure and provide experimenter with a print-ready visual display of their experimental design . wextor flexibly support complete and incomplete factorial design with between-subject , within-subject , and quasi-experimental factor , as well as mixed design . the software implement client-side response time measurement and contain a content wizard for create interactive material , as well as dependent measure -LRB- graphical scale , multiple-choice item , etc. -RRB- , on the experiment page . however , it do not aim to replace a full-fledged html editor . several methodological feature specifically need in web experimental design have be implement in the web-based tool and be describe in this paper . wextor be platform independent . the create web page can be upload to any type of web server in which data may be record in logfile or via a database . the current version of wextor be freely available for educational and noncommercial purpose . its web address be http://www . genpsylab . unizh . ch/wextor/index . html",189,0.875
7204,Computers and IT,"Investigates Sugeno's and Yasukawa's (1993) qualitative fuzzy modeling approach. We propose some easily implementable solutions for the unclear details of the original paper, such as trapezoid approximation of membership functions, rule creation from sample data points, and selection of important variables. We further suggest an improved parameter identification algorithm to be applied instead of the original one. These details are crucial concerning the method's performance as it is shown in a comparative analysis and helps to improve the accuracy of the built-up model. Finally, we propose a possible further rule base reduction which can be applied successfully in certain cases. This improvement reduces the time requirement of the method by up to 16% in our experiments","investigate sugeno 's and yasukawa 's -LRB- 1993 -RRB- qualitative fuzzy modeling approach . we propose some easily implementable solution for the unclear detail of the original paper , such as trapezoid approximation of membership function , rule creation from sample data point , and selection of important variable . we far suggest an improve parameter identification algorithm to be apply instead of the original one . these detail be crucial concern the method 's performance as it be show in a comparative analysis and help to improve the accuracy of the built-up model . finally , we propose a possible further rule base reduction which can be apply successfully in certain case . this improvement reduce the time requirement of the method by up to 16 % in our experiment",116,0.75
7205,Computers and IT,"ePsych (http://epsych. msstate. edu), a new Web site currently under active development, is intended to teach students about the discipline of psychology. The site presumes little prior knowledge about the field and so may be used in introductory classes, but it incorporates sufficient depth of coverage to be useful in more advanced classes as well. Numerous interactive and dynamic elements are incorporated into various modules, orientations, and guidebooks. These elements include Java-based experiments and demonstrations, video clips, and animated diagrams. Rapid access to all material is provided through a layer-based navigation system that allows users to visit various ""Worlds of the Mind. "" Active learning is encouraged, by challenging students with puzzles and problems and by providing the opportunity to ""dig deeper"" to learn more about the phenomena at hand","epsych -LRB- http://epsych . msstate . edu -RRB- , a new web site currently under active development , be intend to teach student about the discipline of psychology . the site presume little prior knowledge about the field and so may be use in introductory class , but it incorporate sufficient depth of coverage to be useful in more advanced class as well . numerous interactive and dynamic element be incorporate into various module , orientation , and guidebook . these element include java-based experiment and demonstration , video clip , and animated diagram . rapid access to all material be provide through a layer-based navigation system that allow user to visit various `` world of the mind . '' active learning be encourage , by challenging student with puzzle and problem and by provide the opportunity to `` dig deep '' to learn more about the phenomenon at hand",130,0.727272727
7206,Computers and IT,"This article suggests that Information Architecture (IA) design is primarily an inductive process. Although top-level goals, user attributes and available content are periodically considered, the process involves bottom-up design activities. IA is inductive partly because it lacks internal theory, and partly because it is an activity that supports emergent phenomena (user experiences) from basic design components. The nature of IA design is well described by Constructive Induction (CI), a design process that involves locating the best representational framework for the design problem, identifying a solution within that framework and translating it back to the design problem at hand. The future of IA, if it remains inductive or develops a body of theory (or both), is considered","this article suggest that information architecture -LRB- ia -RRB- design be primarily an inductive process . although top-level goal , user attribute and available content be periodically consider , the process involve bottom-up design activity . ia be inductive partly because it lack internal theory , and partly because it be an activity that support emergent phenomenon -LRB- user experience -RRB- from basic design component . the nature of ia design be well describe by constructive induction -LRB- ci -RRB- , a design process that involve locate the best representational framework for the design problem , identify a solution within that framework and translate it back to the design problem at hand . the future of ia , if it remain inductive or develop a body of theory -LRB- or both -RRB- , be consider",116,0.714285714
7207,Computers and IT,"The article presents a matrix that can serve as a tool for designing the information architecture of a Web portal in a logical and systematic manner. The information architect begins by inputting the portal's objective, target user, and target content. The matrix then determines the most appropriate information architecture attributes for the portal by filling in the Applied Information Architecture portion of the matrix. The article discusses how the matrix works using the example of a children's Web portal to provide access to museum information","the article present a matrix that can serve as a tool for design the information architecture of a web portal in a logical and systematic manner . the information architect begin by inputt the portal 's objective , target user , and target content . the matrix then determine the most appropriate information architecture attribute for the portal by fill in the apply information architecture portion of the matrix . the article discuss how the matrix work use the example of a child 's web portal to provide access to museum information",85,0.8
7208,Computers and IT,"There are signs that information architecture is coalescing into a field of professional practice. However, if it is to become a profession, it must develop a means of educating new information architects. Lessons from other fields suggest that professional education typically evolves along a predictable path, from apprenticeships to trade schools to college- and university-level education. Information architecture education may develop more quickly to meet the growing demands of the information society. Several pedagogical approaches employed in other fields may be adopted for information architecture education, as long as the resulting curricula provide an interdisciplinary approach and balance instruction in technical and design skills with consideration of theoretical concepts. Key content areas are information organization, graphic. design, computer science, user and usability studies, and communication. Certain logistics must be worked out, including where information architecture studies should be housed and what kinds of degrees should be offered and at what levels. The successful information architecture curriculum will be flexible and adaptable in order to meet the changing needs of students and the marketplace","there be sign that information architecture be coalesce into a field of professional practice . however , if it be to become a profession , it must develop a mean of educate new information architect . lesson from other field suggest that professional education typically evolve along a predictable path , from apprenticeship to trade school to college - and university-level education . information architecture education may develop more quickly to meet the grow demand of the information society . several pedagogical approach employ in other field may be adopt for information architecture education , as long as the result curriculum provide an interdisciplinary approach and balance instruction in technical and design skill with consideration of theoretical concept . key content area be information organization , graphic . design , computer science , user and usability study , and communication . certain logistics must be work out , include where information architecture study should be house and what kind of degree should be offer and at what level . the successful information architecture curriculum will be flexible and adaptable in order to meet the change need of student and the marketplace",173,0.888888889
7209,Computers and IT,"The emergence of Information Architecture within the information systems world has been simultaneously drawn out yet rapid. Those with an eye on history are quick to point to Wurman's 1976 use of the term ""architecture of information, "" but it has only been in the last 2 years that IA has become the source of sufficient interest for people to label themselves professionally as Information Architects. The impetus for this recent emergence of IA can be traced to a historical summit, supported by ASIS&T in May 2000 at Boston. It was here that several hundred of us gathered to thrash out the questions of just what IA was and what this new field might become. At the time of the summit, invited to present a short talk on my return journey from the annual ACM SIGCHI conference, I entered the summit expecting little and convinced that IA was nothing new. I left 2 days later refreshed, not just by the enthusiasm of the attendees for this term but by IA's potential to unify the disparate perspectives and orientations of professionals from a range of disciplines. It was at this summit that the idea for the special issue took root. I proposed the idea to Don Kraft, hoping he would find someone else to run with it. AS luck would have it, I ended up taking charge of it myself, with initial support from David Blair. From the suggestion to the finished product-has been the best part of 2 years, and in that time more than 50 volunteers reviewed over 20 submissions","the emergence of information architecture within the information system world have be simultaneously draw out yet rapid . those with an eye on history be quick to point to wurman 's 1976 use of the term `` architecture of information , '' but it have only be in the last 2 year that ia have become the source of sufficient interest for people to label themselves professionally as information architect . the impetus for this recent emergence of ia can be trace to a historical summit , support by asi & t in may 2000 at boston . it be here that several hundred of us gather to thrash out the question of just what ia be and what this new field might become . at the time of the summit , invite to present a short talk on my return journey from the annual acm sigchi conference , i enter the summit expect little and convinced that ia be nothing new . i leave 2 day later refresh , not just by the enthusiasm of the attendee for this term but by ia 's potential to unify the disparate perspective and orientation of professional from a range of discipline . it be at this summit that the idea for the special issue take root . i propose the idea to don kraft , hop he would find someone else to run with it . as luck would have it , i end up take charge of it myself , with initial support from david blair . from the suggestion to the finish product-has be the best part of 2 year , and in that time more than 50 volunteer review over 20 submission",261,0.285714286
7210,Computers and IT,"The potential impact of the Internet on the public's demand for the services and resources of public libraries is an issue of critical importance. The research reported in this article provides baseline data concerning the evolving relationship between the public's use of the library and its use of the Internet. The authors developed a consumer model of the American adult market for information services and resources, segmented by use (or nonuse) of the public library and by access (or lack of access) to, and use (or nonuse) of, the Internet. A national Random Digit Dialing telephone survey collected data to estimate the size of each of six market segments, and to describe their usage choices between the public library and the Internet. The analyses presented in this article provide estimates of the size and demographics of each of the market segments; describe why people are currently using the public library and the Internet; identify the decision criteria people use in their choices of which provider to use; identify areas in which libraries and the Internet appear to be competing and areas in which they appear to be complementary; and identify reasons why people choose not to use the public library and/or the Internet. The data suggest that some differentiation between the library and the Internet is taking place, which may very well have an impact on consumer choices between the two. Longitudinal research is necessary to fully reveal trends in these usage choices, which have implications for all types of libraries in planning and policy development","the potential impact of the internet on the public 's demand for the service and resource of public library be an issue of critical importance . the research report in this article provide baseline data concern the evolve relationship between the public 's use of the library and its use of the internet . the author develop a consumer model of the american adult market for information service and resource , segmented by use -LRB- or nonuse -RRB- of the public library and by access -LRB- or lack of access -RRB- to , and use -LRB- or nonuse -RRB- of , the internet . a national random digit dial telephone survey collect data to estimate the size of each of six market segment , and to describe their usage choice between the public library and the internet . the analysis present in this article provide estimate of the size and demographic of each of the market segment ; describe why people be currently use the public library and the internet ; identify the decision criterion people use in their choice of which provider to use ; identify area in which library and the internet appear to be compete and area in which they appear to be complementary ; and identify reason why people choose not to use the public library and/or the internet . the data suggest that some differentiation between the library and the internet be take place , which may very well have an impact on consumer choice between the two . longitudinal research be necessary to fully reveal trend in these usage choice , which have implication for all type of library in planning and policy development",256,1
7211,Computers and IT,"Fractional frequency distributions of, for example, authors with a certain (fractional) number of papers are very irregular, and therefore not easy to model or to explain. The article gives a first attempt to this by as suming two simple Lotka laws (with exponent 2): one for the number of authors with n papers (total count here) and one for the number of papers with n authors, n in N. Based on an earlier made convolution model of Egghe, interpreted and reworked now for discrete scores, we are able to produce theoretical fractional frequency distributions with only one parameter, which are in very close agreement with the practical ones as found in a large dataset produced earlier by Rao (1995). The article also shows that (irregular) fractional frequency distributions are a consequence of Lotka's law, and are not examples of breakdowns of this famous historical law","fractional frequency distribution of , for example , author with a certain -LRB- fractional -RRB- number of paper be very irregular , and therefore not easy to model or to explain . the article give a first attempt to this by as sum two simple lotka law -LRB- with exponent 2 -RRB- : one for the number of author with n paper -LRB- total count here -RRB- and one for the number of paper with n author , n in n. base on an earlier make convolution model of egghe , interpret and rework now for discrete score , we be able to produce theoretical fractional frequency distribution with only one parameter , which be in very close agreement with the practical one as find in a large dataset produce earlier by rao -LRB- 1995 -RRB- . the article also show that -LRB- irregular -RRB- fractional frequency distribution be a consequence of lotka 's law , and be not example of breakdown of this famous historical law",145,0.5
7212,Computers and IT,"The dominant method currently used to improve the quality of Internet search systems is often called ""digital democracy. "" Such an approach implies the utilization of the majority opinion of Internet users to determine the most relevant documents: for example, citation index usage for sorting of search results (google. com) or an enrichment of a query with terms that are asked frequently in relation with the query's theme. ""Digital democracy"" is an effective instrument in many cases, but it has an unavoidable shortcoming, which is a matter of principle: the average intellectual and cultural level of Internet users is very low; everyone knows what kind of information is dominant in Internet query statistics. Therefore, when one searches the Internet by means of ""digital democracy"" systems, one gets answers that reflect an underlying assumption that the user's mind potential is very low, and that his cultural interests are not demanding. Thus, it is more correct to use the term ""digital ochlocracy"" to refer to Internet search systems with ""digital democracy. "" Based on the well-known mathematical mechanism of linear programming, we propose a method to solve the indicated problem","the dominant method currently use to improve the quality of internet search system be often call `` digital democracy . '' such an approach imply the utilization of the majority opinion of internet user to determine the most relevant document : for example , citation index usage for sort of search result -LRB- google . com -RRB- or an enrichment of a query with term that be ask frequently in relation with the query 's theme . `` digital democracy '' be an effective instrument in many case , but it have an unavoidable shortcoming , which be a matter of principle : the average intellectual and cultural level of internet user be very low ; everyone know what kind of information be dominant in internet query statistic . therefore , when one search the internet by mean of `` digital democracy '' system , one get answer that reflect an underlie assumption that the user 's mind potential be very low , and that his cultural interest be not demand . thus , it be more correct to use the term `` digital ochlocracy '' to refer to internet search system with `` digital democracy . '' base on the well-known mathematical mechanism of linear programming , we propose a method to solve the indicated problem",188,0.8
7213,Computers and IT,"For original paper see H. -L. Yang et al. , ibid. , vol. 48, p. 144-58 (2001). Yang et al. extended the lot-size models to allow for inflation and fluctuating demand. For this model they proved that the optimal replenishment schedule exists and is unique. They also proposed an algorithm to find the optimal policy. The present paper provides examples, which show that the optimal replenishment schedule and consequently the overall optimal policy may not exist","for original paper see h. - l. yang et al. , ibid . , vol . 48 , p. 144-58 -LRB- 2001 -RRB- . yang et al. extend the lot-size model to allow for inflation and fluctuating demand . for this model they prove that the optimal replenishment schedule exist and be unique . they also propose an algorithm to find the optimal policy . the present paper provide example , which show that the optimal replenishment schedule and consequently the overall optimal policy may not exist",76,0.333333333
7214,Computers and IT,"Within a reasonable life-testing time, how to improve the reliability of highly reliable products is one of the great challenges. By using a resolution III experiment together with degradation test, Tseng et al. (1995) presented a case study of improving the reliability of fluorescent lamps. However, in conducting such an experiment, they did not address the problem of how to choose the optimal settings of variables, such as sample size, inspection frequency, and termination time for each run, which are influential to the correct identification of significant factors and the experimental cost. Assuming that the product's degradation paths satisfy Wiener processes, this paper proposes a systematic approach to the aforementioned problem. First, an identification rule is proposed. Next, under the constraints of a minimum probability of correct decision and a maximum probability of incorrect decision of the proposed identification rule, the optimum test plan can be obtained by minimizing the total experimental cost. An example is provided to illustrate the proposed method","within a reasonable life-testing time , how to improve the reliability of highly reliable product be one of the great challenge . by use a resolution iii experiment together with degradation test , tseng et al. -LRB- 1995 -RRB- present a case study of improve the reliability of fluorescent lamp . however , in conduct such an experiment , they do not address the problem of how to choose the optimal setting of variable , such as sample size , inspection frequency , and termination time for each run , which be influential to the correct identification of significant factor and the experimental cost . assume that the product 's degradation path satisfy wien process , this paper propose a systematic approach to the aforementioned problem . first , an identification rule be propose . next , under the constraint of a minimum probability of correct decision and a maximum probability of incorrect decision of the propose identification rule , the optimum test plan can be obtain by minimize the total experimental cost . an example be provide to illustrate the propose method",162,0.75
7215,Computers and IT,"Adaptive control for nonlinear time-varying systems is of both theoretical and practical importance. We propose an adaptive control methodology for a class of nonlinear systems with a time-varying structure. This class of systems is composed of interpolations of nonlinear subsystems which are input-output feedback linearizable. Both indirect and direct adaptive control methods are developed, where the spatially localized models (in the form of Takagi-Sugeno fuzzy systems or radial basis function neural networks) are used as online approximators to learn the unknown dynamics of the system. Without assumptions on rate of change of system dynamics, the proposed adaptive control methods guarantee that all internal signals of the system are bounded and the tracking error is asymptotically stable. The performance of the adaptive controller is demonstrated using a jet engine control problem","adaptive control for nonlinear time-varying system be of both theoretical and practical importance . we propose an adaptive control methodology for a class of nonlinear system with a time-varying structure . this class of system be compose of interpolation of nonlinear subsystem which be input-output feedback linearizable . both indirect and direct adaptive control method be develop , where the spatially localize model -LRB- in the form of takagi-sugeno fuzzy system or radial basis function neural network -RRB- be use as online approximator to learn the unknown dynamic of the system . without assumption on rate of change of system dynamic , the propose adaptive control method guarantee that all internal signal of the system be bound and the tracking error be asymptotically stable . the performance of the adaptive controller be demonstrate use a jet engine control problem",130,0.5
7216,Computers and IT,"Estimation of warranty costs, in the event of product failure within the warranty period, is of importance to the manufacturer. Costs associated with replacement or repair of the product are usually drawn from a warranty reserve fund created by the manufacturer. Considering a stochastic sales process, first and second moments (and thereby the variance) are derived for the manufacturer's total discounted warranty cost of a single sale for single-component items under four different warranty policies from a manufacturer's point of view. These servicing strategies represent a renewable free-replacement, nonrenewable free-replacement, renewable pro-rata, and a nonrenewable minimal-repair warranty plans. The results are extended to determine the mean and variance of total discounted warranty costs for the total sales over the life cycle of the product. Furthermore, using a normal approximation, warranty reserves necessary for a certain protection level, so that reserves are not completely depleted, are found. Results and their managerial implications are studied through an extensive example","estimation of warranty cost , in the event of product failure within the warranty period , be of importance to the manufacturer . cost associate with replacement or repair of the product be usually draw from a warranty reserve fund create by the manufacturer . consider a stochastic sale process , first and second moment -LRB- and thereby the variance -RRB- be derive for the manufacturer 's total discounted warranty cost of a single sale for single-component item under four different warranty policy from a manufacturer 's point of view . these service strategy represent a renewable free-replacement , nonrenewable free-replacement , renewable pro-rata , and a nonrenewable minimal-repair warranty plan . the result be extend to determine the mean and variance of total discounted warranty cost for the total sale over the life cycle of the product . furthermore , use a normal approximation , warranty reserve necessary for a certain protection level , so that reserve be not completely deplete , be find . result and their managerial implication be study through an extensive example",157,0.714285714
7217,Computers and IT,"This project uses REALbasic 3. 5 in the Mac OS X environment for development of a configuration tool that builds a data collection procedure for investigating the effectiveness of sonified graphs. The advantage of using REALbasic with the Mac OS X system is that it provides rapid development of stimulus presentation, direct recording of data to files, and control over other procedural issues. The program can be made to run natively on the new Mac OS X system, older Mac OS systems, and Windows (98SE, ME, 2000 PRO). With modification, similar programs could be used to present any number of visual/auditory stimulus combinations, complete with questions for each stimulus","this project use realbasic 3 . 5 in the mac os x environment for development of a configuration tool that build a data collection procedure for investigate the effectiveness of sonified graph . the advantage of use realbasic with the mac os x system be that it provide rapid development of stimulus presentation , direct recording of data to file , and control over other procedural issue . the program can be make to run natively on the new mac o x system , old mac os system , and window -LRB- 98se , me , 2000 pro -RRB- . with modification , similar program could be use to present any number of visual/auditory stimulus combination , complete with question for each stimulus",109,0.615384615
7218,Computers and IT,Who says you can't raise cash in today's telecom market? NuVox Communications positions itself for the long run with $78. 5 million in funding and a new credit facility,who say you ca n't raise cash in today 's telecom market ? nuvox communication position itself for the long run with $ 78 . 5 million in funding and a new credit facility,29,0.5
7219,Computers and IT,"Much discussion has taken place over the relative merits of various platforms and operating systems for real-time data collection. Most would agree that, provided great care is taken, many are capable of millisecond timing precision. However, to date, much of this work has focused on the theoretical aspects of raw performance. It is our belief that researchers would be better informed if they could place confidence limits on their own specific paradigms in situ and without modification. To this end, we have developed a millisecond precision test rig that can control and time experiments on a second presentation machine. We report on the specialist hardware and software used. We elucidate the importance of the approach in relation to real-world experimentation","much discussion have take place over the relative merit of various platform and operate system for real-time data collection . most would agree that , provide great care be take , many be capable of millisecond timing precision . however , to date , much of this work have focus on the theoretical aspect of raw performance . it be our belief that researcher would be better inform if they could place confidence limit on their own specific paradigm in situ and without modification . to this end , we have develop a millisecond precision test rig that can control and time experiment on a second presentation machine . we report on the specialist hardware and software use . we elucidate the importance of the approach in relation to real-world experimentation",120,0.428571429
7220,Computers and IT,"A server-side program for animation experiments is presented. The program is capable of delivering an experiment composed of discrete animation sequences in various file formats, collecting a discrete or continuous response from the observer, evaluating the appropriateness of the response, and ensuring that the user is not proceeding at an unreasonable rate. Most parameters of the program are controllable by experimenter-edited text files or simple switches in the program code, thereby minimizing the need for programming to create new experiments. A simple demonstration experiment is discussed and is freely available","a server-side program for animation experiment be present . the program be capable of deliver an experiment compose of discrete animation sequence in various file format , collect a discrete or continuous response from the observer , evaluate the appropriateness of the response , and ensure that the user be not proceed at an unreasonable rate . most parameter of the program be controllable by experimenter-edited text file or simple switch in the program code , thereby minimize the need for programming to create new experiment . a simple demonstration experiment be discuss and be freely available",90,0.571428571
7221,Computers and IT,"Server-side experiments use the Web server, rather than the participant's browser, to handle tasks such as random assignment, eliminating inconsistencies with Java and other client-side applications. Heretofore, experimenters wishing to create server-side experiments have had to write programs to create common gateway interface (CGI) scripts in programming languages such as Perl and C++. NetCloak uses simple, HTML-like commands to create CGIs. We used NetCloak to implement an experiment on probability estimation. Measurements of time on task and participants' IP addresses assisted quality control. Without prior training, in less than 1 month, we were able to use NetCloak to design and create a Web-based experiment and to help graduate students create three Web-based experiments of their own","server-side experiment use the web server , rather than the participant 's browser , to handle task such as random assignment , eliminate inconsistency with java and other client-side application . heretofore , experimenter wish to create server-side experiment have have to write program to create common gateway interface -LRB- cgi -RRB- script in programming language such as perl and c + + . netcloak use simple , html-like command to create cgi . we use netcloak to implement an experiment on probability estimation . measurement of time on task and participant ' ip address assist quality control . without prior training , in less than 1 month , we be able to use netcloak to design and create a web-based experiment and to help graduate student create three web-based experiment of their own",116,0.611111111
7222,Computers and IT,"Most college and university campuses in the United States and much of the developed world today maintain one, two, or several learning management systems (LMSs), which are courseware products that provide students and faculty with Web-based tools to manage course-related applications. Since the mid-1990s, two predominant models of Web courseware management systems have emerged: commercial and noncommercial. Some of the commercial products available today were created in academia as noncommercial but have since become commercially encumbered. Other products remain noncommercial but are struggling to survive in a world of fierce commercial competition. This article argues for an ethics of pedagogy in higher education that would be based on the guiding assumptions of the non-proprietary, peer-to-peer, open-source software movement","most college and university campus in the unite state and much of the developed world today maintain one , two , or several learn management system -LRB- lms -RRB- , which be courseware product that provide student and faculty with web-based tool to manage course-related application . since the mid-1990 , two predominant model of web courseware management system have emerge : commercial and noncommercial . some of the commercial product available today be create in academia as noncommercial but have since become commercially encumber . other product remain noncommercial but be struggle to survive in a world of fierce commercial competition . this article argue for an ethic of pedagogy in high education that would be base on the guide assumption of the non-proprietary , peer-to-pe , open-source software movement",118,0.727272727
7223,Computers and IT,"JavaScript programs can be used to control Web experiments. This technique is illustrated by an experiment that tested the effects of advice on performance in the classic probability-learning paradigm. Previous research reported that people tested via the Web or in the lab tended to match the probabilities of their responses to the probabilities that those responses would be reinforced. The optimal strategy, however, is to consistently choose the more frequent event; probability matching produces suboptimal performance. We investigated manipulations we reasoned should improve performance. A horse race scenario in which participants predicted the winner in each of a series of races between two horses was compared with an abstract scenario used previously. Ten groups of learners received different amounts of advice, including all combinations of (1) explicit instructions concerning the optimal strategy, (2) explicit instructions concerning a monetary sum to maximize, and (3) accurate information concerning the probabilities of events. The results showed minimal effects of horse race versus abstract scenario. Both advice concerning the optimal strategy and probability information contributed significantly to performance in the task. This paper includes a brief tutorial on JavaScript, explaining with simple examples how to assemble a browser-based experiment","javascript program can be use to control web experiment . this technique be illustrate by an experiment that test the effect of advice on performance in the classic probability-learning paradigm . previous research report that people test via the web or in the lab tend to match the probability of their response to the probability that those response would be reinforce . the optimal strategy , however , be to consistently choose the more frequent event ; probability match produce suboptimal performance . we investigate manipulation we reason should improve performance . a horse race scenario in which participant predict the winner in each of a series of race between two horse be compare with an abstract scenario use previously . ten group of learner receive different amount of advice , include all combination of -LRB- 1 -RRB- explicit instruction concern the optimal strategy , -LRB- 2 -RRB- explicit instruction concern a monetary sum to maximize , and -LRB- 3 -RRB- accurate information concern the probability of event . the result show minimal effect of horse race versus abstract scenario . both advice concern the optimal strategy and probability information contribute significantly to performance in the task . this paper include a brief tutorial on javascript , explain with simple example how to assemble a browser-based experiment",195,0.625
7224,Computers and IT,"We tested a computer-based procedure for assessing reader strategies that was based on verbal protocols that utilized latent semantic analysis (LSA). Students were given self-explanation-reading training (SERT), which teaches strategies that facilitate self-explanation during reading, such as elaboration based on world knowledge and bridging between text sentences. During a computerized version of SERT practice, students read texts and typed self-explanations into a computer after each sentence. The use of SERT strategies during this practice was assessed by determining the extent to which students used the information in the current sentence versus the prior text or world knowledge in their self-explanations. This assessment was made on the basis of human judgments and LSA. Both human judgments and LSA were remarkably similar and indicated that students who were not complying with SERT tended to paraphrase the text sentences, whereas students who were compliant with SERT tended to explain the sentences in terms of what they knew about the world and of information provided in the prior text context. The similarity between human judgments and LSA indicates that LSA will be useful in accounting for reading strategies in a Web-based version of SERT","we test a computer-based procedure for assess reader strategy that be base on verbal protocol that utilize latent semantic analysis -LRB- lsa -RRB- . student be give self-explanation-reading training -LRB- sert -RRB- , which teach strategy that facilitate self-explanation during reading , such as elaboration base on world knowledge and bridge between text sentence . during a computerized version of sert practice , student read text and type self-explanation into a computer after each sentence . the use of sert strategy during this practice be assess by determine the extent to which student use the information in the current sentence versus the prior text or world knowledge in their self-explanation . this assessment be make on the basis of human judgment and lsa . both human judgment and lsa be remarkably similar and indicate that student who be not comply with sert tend to paraphrase the text sentence , whereas student who be compliant with sert tend to explain the sentence in term of what they know about the world and of information provide in the prior text context . the similarity between human judgment and lsa indicate that lsa will be useful in accounting for read strategy in a web-based version of sert",190,0.777777778
7225,Computers and IT,"Students, faculty, and researchers have become increasingly comfortable with the Internet, and many of them are interested in using the Web to collect data. Few published studies have investigated the differences between Web-based data and data collected with more traditional methods. In order to investigate these potential differences, two important factors were crossed in this study: whether the data were collected on line or not and whether the data were collected in a group setting at a fixed time or individually at a time of the respondent's choosing. The Visions of Morality scale (Shelton and McAdams, 1990) was used, and the participants were assigned to one of four conditions: in-class Web survey, in-class paper-and-pencil survey; take-home Web survey, and take-home paper-and-pencil survey. No significant differences in scores were found for any condition; however, response rates were affected by the type of survey administered, with the take-home Web-based instrument having the lowest response rate. Therefore, researchers need to be aware that different modes of administration may affect subject attrition and may, therefore, confound investigations of other independent variables","student , faculty , and researcher have become increasingly comfortable with the internet , and many of them be interested in use the web to collect data . few publish study have investigate the difference between web-based data and data collect with more traditional method . in order to investigate these potential difference , two important factor be cross in this study : whether the data be collect on line or not and whether the data be collect in a group set at a fixed time or individually at a time of the respondent 's choosing . the vision of morality scale -LRB- shelton and mcadam , 1990 -RRB- be use , and the participant be assign to one of four condition : in-class web survey , in-class paper-and-pencil survey ; take-home web survey , and take-home paper-and-pencil survey . no significant difference in score be find for any condition ; however , response rate be affect by the type of survey administer , with the take-home web-based instrument have the low response rate . therefore , researcher need to be aware that different mode of administration may affect subject attrition and may , therefore , confound investigation of other independent variable",177,0.833333333
7226,Computers and IT,"The proliferation of World Wide Web (Web) sites and the low cost of publishing information on the Web have placed a tremendous amount of information at the fingertips of millions of people. Although most of this information is at least intended to be accurate, there is much that is rumor, innuendo, urban legend, and outright falsehood. This raises problems especially for students (of all ages) trying to do research or learn about some topic. Finding accurate, credible information requires document level literacy skills, such as integration, sourcing, corroboration, and search. This paper discusses these skills and offers a list of simple ways that designers of educational Web sites can help their visitors utilize these skills","the proliferation of world wide web -LRB- web -RRB- site and the low cost of publish information on the web have place a tremendous amount of information at the fingertip of million of people . although most of this information be at least intend to be accurate , there be much that be rumor , innuendo , urban legend , and outright falsehood . this raise problem especially for student -LRB- of all age -RRB- try to do research or learn about some topic . find accurate , credible information require document level literacy skill , such as integration , source , corroboration , and search . this paper discuss these skill and offer a list of simple way that designer of educational web site can help their visitor utilize these skill",115,0.75
7227,Computers and IT,"The paper is concerned with a linguistic fuzzy c-means (FCM) algorithm with vectors of fuzzy numbers as inputs. This algorithm is based on the extension principle and the decomposition theorem. It turns out that using the extension principle to extend the capability of the standard membership update equation to deal with a linguistic vector has a huge computational complexity. In order to cope with this problem, an efficient method based on fuzzy arithmetic and optimization has been developed and analyzed. We also carefully examine and prove that the algorithm behaves in a way similar to the FCM in the degenerate linguistic case. Synthetic data sets and the iris data set have been used to illustrate the behavior of this linguistic version of the FCM","the paper be concern with a linguistic fuzzy c-mean -LRB- fcm -RRB- algorithm with vector of fuzzy number as input . this algorithm be base on the extension principle and the decomposition theorem . it turn out that use the extension principle to extend the capability of the standard membership update equation to deal with a linguistic vector have a huge computational complexity . in order to cope with this problem , an efficient method base on fuzzy arithmetic and optimization have be develop and analyze . we also carefully examine and prove that the algorithm behave in a way similar to the fcm in the degenerate linguistic case . synthetic data set and the iris data set have be use to illustrate the behavior of this linguistic version of the fcm",124,0.875
7228,Computers and IT,"Entering a user name-password combination is a widely used procedure for identification and authentication in computer systems. However, it is a notoriously weak method, in that the passwords adopted by many users are easy to crack. In an attempt to, improve security, proactive password checking may be used, in which passwords must meet several criteria to be more resistant to cracking. In two experiments, we examined the influence of proactive password restrictions on the time that it took to generate an acceptable password and to use it subsequently to log in. The required length was a minimum of five characters in experiment I and eight characters in experiment 2. In both experiments, one condition had only the length restriction, and the other had additional restrictions. The additional restrictions greatly increased the time it took to generate the password but had only a small effect on the time it took to use it subsequently to log in. For the five-character passwords, 75% were cracked when no other restrictions were imposed, and this was reduced to 33% with the additional restrictions. For the eight-character passwords, 17% were cracked with no other restrictions, and 12. 5% with restrictions. The results indicate that increasing the minimum character length reduces crackability and increases security, regardless of whether additional restrictions are imposed","enter a user name-password combination be a widely use procedure for identification and authentication in computer system . however , it be a notoriously weak method , in that the password adopt by many user be easy to crack . in an attempt to , improve security , proactive password checking may be use , in which password must meet several criterion to be more resistant to crack . in two experiment , we examine the influence of proactive password restriction on the time that it take to generate an acceptable password and to use it subsequently to log in . the required length be a minimum of five character in experiment i and eight character in experiment 2 . in both experiment , one condition have only the length restriction , and the other have additional restriction . the additional restriction greatly increase the time it take to generate the password but have only a small effect on the time it take to use it subsequently to log in . for the five-charact password , 75 % be crack when no other restriction be impose , and this be reduce to 33 % with the additional restriction . for the eight-character password , 17 % be crack with no other restriction , and 12 . 5 % with restriction . the result indicate that increase the minimum character length reduce crackability and increase security , regardless of whether additional restriction be impose",216,0.571428571
7229,Computers and IT,"Historically, data visualization has been limited primarily to two dimensions (e. g. , histograms or scatter plots). Available software packages (e. g. , Data Desk 6. 1, MatLab 6. 1, SAS-JMP 4. 04, SPSS 10. 0) are capable of producing three-dimensional scatter plots with (varying degrees of) user interactivity. We constructed our own data visualization application with the Visualization Toolkit (Schroeder et al. , 1998) and Tcl/Tk to display multivariate data through the application of glyphs (Ware, 2000). A glyph is a visual object onto which many data parameters may be mapped, each with a different visual attribute (e. g. , size or color). We used our multi-dimensional data viewer to explore data from several psycholinguistic experiments. The graphical interface provides flexibility when users dynamically explore the multidimensional image rendered from raw experimental data. We highlight advantages of multidimensional data visualization and consider some potential limitations","historically , data visualization have be limit primarily to two dimension -LRB- e. g. , histogram or scatter plot -RRB- . available software package -LRB- e. g. , data desk 6 . 1 , matlab 6 . 1 , sas-jmp 4 . 04 , sps 10 . 0 -RRB- be capable of produce three-dimensional scatter plot with -LRB- vary degree of -RRB- user interactivity . we construct our own data visualization application with the visualization toolkit -LRB- schroeder et al. , 1998 -RRB- and tcl/tk to display multivariate data through the application of glyph -LRB- ware , 2000 -RRB- . a glyph be a visual object onto which many data parameter may be map , each with a different visual attribute -LRB- e. g. , size or color -RRB- . we use our multi-dimensional data viewer to explore data from several psycholinguistic experiment . the graphical interface provide flexibility when user dynamically explore the multidimensional image render from raw experimental data . we highlight advantage of multidimensional data visualization and consider some potential limitation",146,0.857142857
7230,Computers and IT,"This paper presents an analysis of repeated ordinal outcomes arising from two psychological studies. The first case is a repeated measures analysis of variance; the second is a mixed-effects regression. in a longitudinal design. In both, the subject-specific variation is modeled by including random effects in the linear predictor (inside a link function) of a generalized linear model. The NLMIXED procedure in SAS is used to fit the mixed-effects models for the categorical response data. The presentation emphasizes the parallel between the model. specifications and the SAS statements. The purpose of this paper is to facilitate the use of mixed-effects models in the analysis of repeated ordinal outcomes","this paper present an analysis of repeat ordinal outcome arise from two psychological study . the first case be a repeat measure analysis of variance ; the second be a mixed-effects regression . in a longitudinal design . in both , the subject-specific variation be model by include random effect in the linear predictor -LRB- inside a link function -RRB- of a generalize linear model . the nlmixed procedure in sa be use to fit the mixed-effect model for the categorical response data . the presentation emphasize the parallel between the model . specification and the sas statement . the purpose of this paper be to facilitate the use of mixed-effect model in the analysis of repeat ordinal outcome",108,0.692307692
7231,Computers and IT,"For over 30 years, psychologists have relied on computers to teach experimental psychology. With the advent of experiment generators, students can create well-designed experiments and can test sophisticated hypotheses from the start of their undergraduate training. Characteristics of new Net-based experiment generators are discussed and compared with traditional stand-alone generators. A call is made to formally evaluate the instructional effectiveness of the wide range of experiment generators now available. Specifically, software should be evaluated in terms of known learning outcomes, using appropriate control groups. The many inherent differences between any two software programs should be made clear. The teacher's instructional method should be fully described and held constant between comparisons. Finally, the often complex interaction between the teacher's instructional method and the pedagogical details of the software must be considered","for over 30 year , psychologist have rely on computer to teach experimental psychology . with the advent of experiment generator , student can create well-designed experiment and can test sophisticated hypothesis from the start of their undergraduate training . characteristic of new net-based experiment generator be discuss and compare with traditional stand-alone generator . a call be make to formally evaluate the instructional effectiveness of the wide range of experiment generator now available . specifically , software should be evaluate in term of know learn outcome , use appropriate control group . the many inherent difference between any two software program should be make clear . the teacher 's instructional method should be fully describe and hold constant between comparison . finally , the often complex interaction between the teacher 's instructional method and the pedagogical detail of the software must be consider",130,0.666666667
7232,Computers and IT,"For ""last-mile access"" in niche applications, twisted copper pair may be the cable of best option to gain access and deliver desired services. The article discusses how operators can use network edge devices to serve new customers. Niche market segments represent a significant opportunity for cable TV delivery of television and high-speed Internet signals. But the existing telecommunications infrastructure in those developments frequently presents unique challenges for the service provider to overcome","for `` last-mile access '' in niche application , twist copper pair may be the cable of best option to gain access and deliver desire service . the article discuss how operator can use network edge device to serve new customer . niche market segment represent a significant opportunity for cable tv delivery of television and high-speed internet signal . but the exist telecommunication infrastructure in those development frequently present unique challenge for the service provider to overcome",72,0.6
7233,Computers and IT,IBM is matching up computer-science and MBA students with its business managers in an 11-week summer internship program and challenging them to develop innovative technology ideas,ibm be match up computer-science and mba student with its business manager in an 11-week summer internship program and challenge them to develop innovative technology idea,26,0.2
7234,Computers and IT,"Despite the second quarter's gloomy GDP report, savvy CIOs are forging ahead with big IT projects that will position their companies to succeed when the economy soars again","despite the second quarter 's gloomy gdp report , savvy cio be forge ahead with big it project that will position their company to succeed when the economy soar again",28,0
7235,Computers and IT,"With the increasing importance of multiple multiplatform remote sensing missions, fast and automatic integration of digital data from disparate sources has become critical to the success of these endeavors. Our work utilizes maxima of wavelet coefficients to form the basic features of a correlation-based automatic registration algorithm. Our wavelet-based registration algorithm is tested successfully with data from the National Oceanic and Atmospheric Administration (NOAA) Advanced Very High Resolution Radiometer (AVHRR) and the Landsat Thematic Mapper (TM), which differ by translation and/or rotation. By the choice of high-frequency wavelet features, this method is similar to an edge-based correlation method, but by exploiting the multiresolution nature of a wavelet decomposition, our method achieves higher computational speeds for comparable accuracies. This algorithm has been implemented on a single-instruction multiple-data (SIMD) massively parallel computer, the MasPar MP-2, as well as on the CrayT3D, the Cray T3E, and a Beowulf cluster of Pentium workstations","with the increase importance of multiple multiplatform remote sense mission , fast and automatic integration of digital data from disparate source have become critical to the success of these endeavor . our work utilize maximum of wavelet coefficient to form the basic feature of a correlation-based automatic registration algorithm . our wavelet-based registration algorithm be test successfully with data from the national oceanic and atmospheric administration -LRB- noaa -RRB- advance very high resolution radiometer -LRB- avhrr -RRB- and the landsat thematic mapper -LRB- tm -RRB- , which differ by translation and/or rotation . by the choice of high-frequency wavelet feature , this method be similar to an edge-based correlation method , but by exploit the multiresolution nature of a wavelet decomposition , our method achieve high computational speed for comparable accuracy . this algorithm have be implement on a single-instruction multiple-data -LRB- simd -RRB- massively parallel computer , the maspar mp-2 , as well as on the crayt3d , the cray t3e , and a beowulf cluster of pentium workstation",149,0.466666667
7236,Computers and IT,"In this paper, a control concept for the squared (equal number of inputs and outputs) multivariable process systems is given. The proposed control system consists of two parts, single loop fuzzy controllers in each loop and a centralized decoupling unit. The fuzzy control system uses feedback control to minimize the error in the loop and the decoupler uses an adaptive technique to mitigate loop interactions. The decoupler predicts the interacting loop changes and modifies the input (error) of the loop controller. The controller was tested on the simulation model of ""single component vaporizer"" process","in this paper , a control concept for the square -LRB- equal number of input and output -RRB- multivariable process system be give . the propose control system consist of two part , single loop fuzzy controller in each loop and a centralized decoupling unit . the fuzzy control system use feedback control to minimize the error in the loop and the decoupler use an adaptive technique to mitigate loop interaction . the decoupler predict the interact loop change and modify the input -LRB- error -RRB- of the loop controller . the controller be test on the simulation model of `` single component vaporizer '' process",94,0.166666667
7237,Computers and IT,Reservations about Temelin nuclear plant in the Czech Republic are political rather than technical. This paper discusses the problems of turbogenerator vibrations and how they were diagnosed. The paper also discusses some of the other problems of commissioning the power plant. The simulator used for training new staff is also mentioned,reservation about temelin nuclear plant in the czech republic be political rather than technical . this paper discuss the problem of turbogenerator vibration and how they be diagnose . the paper also discuss some of the other problem of commission the power plant . the simulator use for train new staff be also mention,51,0.6
7238,Computers and IT,"I used game theory to examine how team captains should select their slates for the final day of the Ryder Cup matches. Under the assumption that golfers have different abilities and are not influenced by pressure or momentum, I found that drawing names from a hat will do no worse than any other strategy","i use game theory to examine how team captain should select their slate for the final day of the ryder cup match . under the assumption that golfer have different ability and be not influence by pressure or momentum , i find that draw name from a hat will do no bad than any other strategy",54,0.6
7239,Computers and IT,An integer-programming model and a post-solution heuristic allocates operating room time to the five surgical divisions at Toronto's Mount Sinai Hospital. The hospital has used this approach for several years and credits it with both administrative savings and the ability to produce quickly an equitable master surgical schedule,an integer-programming model and a post-solution heuristic allocate operate room time to the five surgical division at toronto 's mount sinai hospital . the hospital have use this approach for several year and credit it with both administrative saving and the ability to produce quickly an equitable master surgical schedule,48,0.428571429
7240,Computers and IT,"The US Government's Small Business Innovation Research Program helps small businesses transform new ideas into commercial products. The program provides an ideal means for businesses and universities to obtaining funding for cooperative projects. Rules and information for the program are readily available, and I will give a few helpful hints to provide guidance","the us government 's small business innovation research program help small business transform new idea into commercial product . the program provide an ideal mean for business and university to obtain funding for cooperative project . rule and information for the program be readily available , and i will give a few helpful hint to provide guidance",53,0.75
7241,Computers and IT,"Student consulting projects require students to apply OR/MS tools to obtain insight into the activities of firms in the community. These projects benefit faculty by providing clear feedback on the real capabilities of students, a broad connection to local industry, and material for case studies and research. They benefit companies by stimulating new thinking regarding their activities and delivering results they can use. Projects provide insights into the end-user modeling mode of OR/MS practice. Projects support continuous improvement as the lessons gained from a crop of projects enable better teaching during the next course offering, which in turn leads to better projects and further insights into teaching","student consulting project require student to apply or/m tool to obtain insight into the activity of firm in the community . these project benefit faculty by provide clear feedback on the real capability of student , a broad connection to local industry , and material for case study and research . they benefit company by stimulate new think regard their activity and deliver result they can use . project provide insight into the end-user modeling mode of or/m practice . project support continuous improvement as the lesson gain from a crop of project enable better teaching during the next course offering , which in turn lead to better project and further insight into teaching",107,0.4
7242,Computers and IT,"We define strategic OR/MS as ""OR/MS work that leads to a sustainable competitive advantage. "" We found evidence of strategic OR/MS in the literature of strategic information systems (SIS) and OR/MS. We examined 30 early examples of SIS, many of which contained OR/MS work. Many of the most successful had high OR/MS content, while the least successful contained none. The inclusion of OR/MS work may be a key to sustaining an advantage from information technology. We also examined the Edelman Prize finalist articles published between 1990 and 1999. We found that 13 of the 42 private sector applications meet our definition of strategic OR/MS","we define strategic or/m as `` or/m work that lead to a sustainable competitive advantage . '' we find evidence of strategic or/m in the literature of strategic information system -LRB- si -RRB- and or/m . we examine 30 early example of si , many of which contain or/m work . many of the most successful have high or/m content , while the least successful contain none . the inclusion of or/m work may be a key to sustain an advantage from information technology . we also examine the edelman prize finalist article publish between 1990 and 1999 . we find that 13 of the 42 private sector application meet our definition of strategic or/m",104,0.6
7243,Computers and IT,"The competition for baseball play-off spots-the fabled pennant race-is one of the most closely watched American sports traditions. While play-off race statistics, such as games back and magic number, are informative, they are overly conservative and do not account for the remaining schedule of games. Using optimization techniques, one can model schedule effects explicitly and determine precisely when a team has secured a play-off spot or has been eliminated from contention. The RIOT Baseball Play-off Races Web site developed at the University of California, Berkeley, provides automatic updates of new, optimization-based play-off race statistics each day of the major league baseball season. In developing the site, we found that we could determine the first-place elimination status of all teams in a division using a single linear-programming formulation, since a minimum win threshold for teams finishing in first place applies to all teams in a division. We identified a similar (but weaker) result for the problem of play-off elimination with wildcard teams","the competition for baseball play-off spots-the fabled pennant race-i one of the most closely watch american sport tradition . while play-off race statistic , such as game back and magic number , be informative , they be overly conservative and do not account for the remain schedule of game . use optimization technique , one can model schedule effect explicitly and determine precisely when a team have secure a play-off spot or have be eliminate from contention . the riot baseball play-off race web site develop at the university of california , berkeley , provide automatic update of new , optimization-based play-off race statistic each day of the major league baseball season . in develop the site , we find that we could determine the first-place elimination status of all team in a division use a single linear-programming formulation , since a minimum win threshold for team finish in first place apply to all team in a division . we identify a similar -LRB- but weak -RRB- result for the problem of play-off elimination with wildcard team",161,0.583333333
7244,Computers and IT,"In 1999, after developing and installing over 170 revenue management (RM) systems for more than 70 airlines, PROS Revenue Management, Inc. had the opportunity to develop RM systems for three companies in nonairline industries. PROS research and design department designed the opportunity analysis study (OAS), a mix of OR/MS, consulting, and software development practices to determine the applicability of RM in new business situations. PROS executed OASs with the three companies. In all three cases, the OAS supported the value of RM and led to contracts for implementation of RM systems","in 1999 , after develop and instal over 170 revenue management -LRB- rm -RRB- system for more than 70 airline , pro revenue management , inc. have the opportunity to develop rm system for three company in nonairline industry . pro research and design department design the opportunity analysis study -LRB- oas -RRB- , a mix of or/m , consulting , and software development practice to determine the applicability of rm in new business situation . pro execute oas with the three company . in all three case , the oas support the value of rm and lead to contract for implementation of rm system",91,0.7
7245,Computers and IT,"We present some new lower bounds on the optimal information rate and on the optimal average information rate of secret sharing schemes with homogeneous access structure. These bounds are found by using some covering constructions and a new parameter, the k-degree of a participant, that is introduced in this paper. Our bounds improve the previous ones in almost all cases","we present some new low bound on the optimal information rate and on the optimal average information rate of secret share scheme with homogeneous access structure . these bound be find by use some cover construction and a new parameter , the k-degree of a participant , that be introduce in this paper . our bound improve the previous one in almost all case",60,0.875
7246,Computers and IT,"We propose and analyze a self-adjusting Quality of Service (QoS) control scheme with the goal of optimizing the system reward as a result of servicing different priority clients with varying workload, QoS and reward/penalty requirements. Our scheme is based on resource partitioning and designated ""degrade QoS areas"" such that system resources are partitioned into priority areas each of which is reserved specifically to serve only clients in a corresponding class with no QoS degradation, plus one ""degraded QoS area"" into which all clients can be admitted with QoS adjustment being applied only to the lowest priority clients. We show that the best partition is dictated by the workload and the reward/penalty characteristics of clients in difference priority classes. The analysis results can be used by a QoS manager to optimize the system total reward dynamically in response to changing workloads at run time. We demonstrate the validity of our scheme by means of simulation and comparing the proposed QoS self-adjusting scheme with those that do not use resource partitioning or designated degraded QoS areas","we propose and analyze a self-adjusting quality of service -LRB- qo -RRB- control scheme with the goal of optimize the system reward as a result of service different priority client with vary workload , qo and reward/penalty requirement . our scheme be base on resource partitioning and designate `` degrade qo area '' such that system resource be partition into priority area each of which be reserve specifically to serve only client in a corresponding class with no qo degradation , plus one `` degraded qo area '' into which all client can be admit with qo adjustment be apply only to the low priority client . we show that the best partition be dictate by the workload and the reward/penalty characteristic of client in difference priority class . the analysis result can be use by a qo manager to optimize the system total reward dynamically in response to change workload at run time . we demonstrate the validity of our scheme by mean of simulation and compare the propose qo self-adjusting scheme with those that do not use resource partitioning or designate degraded qo area",174,0.428571429
7247,Computers and IT,The design of a PID controller is a multiobjective problem. A plant and a set of specifications to be satisfied are given. The designer has to adjust the parameters of the PID controller such that the feedback interconnection of the plant and the controller satisfies the specifications. These specifications are usually competitive and any acceptable solution requires a tradeoff among them. An approach for adjusting the parameters of a PID controller based on multiobjective optimization and genetic algorithms is presented in this paper. The MRCD (multiobjective robust control design) genetic algorithm has been employed. The approach can be easily generalized to design multivariable coupled and decentralized PID loops and has been successfully validated for a large number of experimental cases,the design of a pid controller be a multiobjective problem . a plant and a set of specification to be satisfy be give . the designer have to adjust the parameter of the pid controller such that the feedback interconnection of the plant and the controller satisfy the specification . these specification be usually competitive and any acceptable solution require a tradeoff among them . an approach for adjust the parameter of a pid controller base on multiobjective optimization and genetic algorithm be present in this paper . the mrcd -LRB- multiobjective robust control design -RRB- genetic algorithm have be employ . the approach can be easily generalize to design multivariable couple and decentralize pid loop and have be successfully validate for a large number of experimental case,120,0.428571429
7248,Computers and IT,"A routing policy is the method used to select a specific output channel for a message from among a number of acceptable output channels. An optimal routing policy is a policy that maximizes the probability of a message reaching its destination without delays. Optimal routing policies have been proposed for several regular networks, including the mesh and the hypercube. An open problem in interconnection network research has been the identification of an optimal routing policy for the torus. In this paper, we show that there is no optimal routing policy for the torus. Our result is demonstrated by presenting a detailed example in which the best choice of output channel is dependent on the probability of each channel being available. This result settles, in the negative, a conjecture by J. Wu (1996) concerning an optimal routing policy for the torus","a rout policy be the method use to select a specific output channel for a message from among a number of acceptable output channel . an optimal rout policy be a policy that maximize the probability of a message reach its destination without delay . optimal rout policy have be propose for several regular network , include the mesh and the hypercube . an open problem in interconnection network research have be the identification of an optimal rout policy for the torus . in this paper , we show that there be no optimal rout policy for the torus . our result be demonstrate by present a detailed example in which the best choice of output channel be dependent on the probability of each channel be available . this result settle , in the negative , a conjecture by j. wu -LRB- 1996 -RRB- concern an optimal rout policy for the torus",140,1
7249,Computers and IT,"This paper considers the online scheduling on two identical machines with machine availability constraints for minimizing makespan. We assume that machine M/sub j/ is unavailable during period from s/sub j/ to t/sub j/ (0 or= s/sub j/ t/sub j/), j = 1, 2, and the unavailable periods of two machines do not overlap. We show that the competitive ratio of list scheduling is 3. We further give an optimal algorithm with a competitive ratio 5/2","this paper consider the online scheduling on two identical machine with machine availability constraint for minimize makespan . we assume that machine m/sub j / be unavailable during period from s/sub j / to t/sub j / -LRB- 0 or = s/sub j / t/sub j / -RRB- , j = 1 , 2 , and the unavailable period of two machine do not overlap . we show that the competitive ratio of list scheduling be 3 . we far give an optimal algorithm with a competitive ratio 5/2",75,0.4
7250,Computers and IT,"Random duplicated assignment (RDA) is an approach in which video data is stored by assigning a number of copies of each data block to different, randomly chosen disks. It has been shown that this approach results in smaller response times and lower disk and RAM costs compared to the well-known disk stripping techniques. Based on this storage approach, one has to determine, for each given batch of data blocks, from which disk each of the data blocks is to be retrieved. This is to be done in such a way that the maximum load of the disks is minimized. The problem is called the retrieval selection problem (RSP). In this paper, we propose a new efficient algorithm for RSP. This algorithm is based on the breadth-first search approach and is able to guarantee optimal solutions for RSP in O(n/sup 2/+mn), where m and n correspond to the number of data blocks and the number of disks, respectively. We show that our proposed algorithm has a lower time complexity than an existing algorithm, called the MFS algorithm","random duplicate assignment -LRB- rda -RRB- be an approach in which video data be store by assign a number of copy of each data block to different , randomly choose disk . it have be show that this approach result in small response time and low disk and ram cost compare to the well-known disk strip technique . base on this storage approach , one have to determine , for each give batch of data block , from which disk each of the data block be to be retrieve . this be to be do in such a way that the maximum load of the disk be minimize . the problem be call the retrieval selection problem -LRB- rsp -RRB- . in this paper , we propose a new efficient algorithm for rsp . this algorithm be base on the breadth-first search approach and be able to guarantee optimal solution for rsp in o -LRB- n/sup 2 / + mn -RRB- , where m and n correspond to the number of data block and the number of disk , respectively . we show that our propose algorithm have a low time complexity than an exist algorithm , call the mfs algorithm",176,0.692307692
7251,Computers and IT,"Let X and Y be two run-length encoded strings, of encoded lengths k and l, respectively. We present a simple O(|X|l+|Y|k) time algorithm that computes their edit distance","let x and y be two run-length encoded string , of encoded length k and l , respectively . we present a simple o -LRB- x l + y k -RRB- time algorithm that compute their edit distance",28,0.6
7252,Computers and IT,"It is known that every hypercube Q/sub n/ is a bipartite graph. Assume that nor=2 and F is a subset of edges with |F|or=3 and F is a subset of edges with |F|or=n-3. We prove that there exists a Hamiltonian path in Q/sub n/-{v}-F between any two vertices in the partite set without v. Furthermore, all bounds are tight","it be know that every hypercube q/sub n / be a bipartite graph . assume that nor = 2 and f be a subset of edge with f or = 3 and f be a subset of edge with f or = n-3 . we prove that there exist a hamiltonian path in q/sub n / - -LCB- v -RCB- - f between any two vertex in the partite set without v. furthermore , all bound be tight",59,0.625
7253,Computers and IT,"In this paper, we propose a new society oriented scheme, based on the Guillou-Quisquater (1989) signature scheme. The scheme is identity-based and the signatures are verified with respect to only one identity. That is, the verifier does not have to know the identity of the co-signers, but just that of the organization they represent","in this paper , we propose a new society orient scheme , base on the guillou-quisquater -LRB- 1989 -RRB- signature scheme . the scheme be identity-based and the signature be verify with respect to only one identity . that be , the verifi do not have to know the identity of the co-signer , but just that of the organization they represent",54,0
7254,Computers and IT,"Operational phase-space probability distributions are useful tools for describing quantum mechanical systems, including quantum communication and quantum information processing systems. It is shown that quantum communication channels with Gaussian noise and quantum teleportation of continuous variables are described by operational phase-space probability distributions. The relation of operational phase-space probability distribution to the extended phase-space formalism proposed by Chountasis and Vourdas (1998) is discussed","operational phase-space probability distribution be useful tool for describe quantum mechanical system , include quantum communication and quantum information process system . it be show that quantum communication channel with gaussian noise and quantum teleportation of continuous variable be describe by operational phase-space probability distribution . the relation of operational phase-space probability distribution to the extended phase-space formalism propose by chountasi and vourda -LRB- 1998 -RRB- be discuss",63,0.875
7255,Computers and IT,"In this paper we present an extension of the Minkowski embedding theorem, showing the existence of an isometric embedding between the classF/sub c/(X) of compact-convex and level-continuous fuzzy sets on a real separable Banach space X and C([0, 1] * B(X*)), the Banach space of real continuous functions defined on the cartesian product between [0, 1] and the unit ball B(X*) in the dual space X*. Also, by using this embedding, we give some applications to the characterization of relatively compact subsets of F/sub c/(X). In particular, an Ascoli-Arzela type theorem is proved and applied to solving the Cauchy problem x(t) = f(t, x(t)), x(t/sub 0/) = x/sub 0/ on F/sub c/(X)","in this paper we present an extension of the minkowski embed theorem , show the existence of an isometric embedding between the classf/sub c / -LRB- x -RRB- of compact-convex and level-continuous fuzzy set on a real separable banach space x and c -LRB- -LRB- 0 , 1 -RRB- * b -LRB- x * -RRB- -RRB- , the banach space of real continuous function define on the cartesian product between -LRB- 0 , 1 -RRB- and the unit ball b -LRB- x * -RRB- in the dual space x * . also , by use this embedding , we give some application to the characterization of relatively compact subset of f/sub c / -LRB- x -RRB- . in particular , an ascoli-arzela type theorem be prove and apply to solve the cauchy problem x -LRB- t -RRB- = f -LRB- t , x -LRB- t -RRB- -RRB- , x -LRB- t/sub 0 / -RRB- = x/sub 0 / on f/sub c / -LRB- x -RRB-",112,0.9
7256,Computers and IT,"In this paper, we propose a method to calculate the correlation coefficient of intuitionistic fuzzy sets by means of ""centroid"". This value obtained from our formula tell us not only the strength of relationship between the intuitionistic fuzzy sets, but also whether the intuitionistic fuzzy sets are positively or negatively related. This approach looks better than previous methods which only evaluate the strength of the relation. Furthermore, we extend the ""centroid"" method to interval-valued intuitionistic fuzzy sets. The value of the correlation coefficient between interval-valued intuitionistic fuzzy sets lies in the interval [-1, 1], as computed from our formula","in this paper , we propose a method to calculate the correlation coefficient of intuitionistic fuzzy set by mean of `` centroid '' . this value obtain from our formula tell us not only the strength of relationship between the intuitionistic fuzzy set , but also whether the intuitionistic fuzzy set be positively or negatively relate . this approach look better than previous method which only evaluate the strength of the relation . furthermore , we extend the `` centroid '' method to interval-valued intuitionistic fuzzy set . the value of the correlation coefficient between interval-valued intuitionistic fuzzy set lie in the interval -LRB- -1 , 1 -RRB- , as compute from our formula",99,0.75
7257,Computers and IT,"This paper presents a framework for the study of generalizing the standard notion of equivalence relation in rough set approximation space with various categories of k-step neighborhood systems. Based on a binary relation on a finite universe, six families of binary relations are obtained, and the corresponding six classes of k-step neighborhood systems are derived. Extensions of Pawlak's (1982) rough set approximation operators based on such neighborhood systems are proposed. Properties of neighborhood operator systems and rough set approximation operators are investigated, and their connections are examined","this paper present a framework for the study of generalize the standard notion of equivalence relation in rough set approximation space with various category of k-step neighborhood system . base on a binary relation on a finite universe , six family of binary relation be obtain , and the corresponding six class of k-step neighborhood system be derive . extension of pawlak 's -LRB- 1982 -RRB- rough set approximation operator base on such neighborhood system be propose . property of neighborhood operator system and rough set approximation operator be investigate , and their connection be examine",87,1
7258,Computers and IT,"In this paper, the problem of fault diagnosis via integration of genetic algorithms (GA's) and qualitative bond graphs (QBG's) is addressed. We suggest that GA's can be used to search for possible fault components among a system of qualitative equations. The QBG is adopted as the modeling scheme to generate a set of qualitative equations. The qualitative bond graph provides a unified approach for modeling engineering systems, in particular, mechatronic systems. In order to demonstrate the performance of the proposed algorithm, we have tested the proposed algorithm on an in-house designed and built floating disc experimental setup. Results from fault diagnosis in the floating disc system are presented and discussed. Additional measurements will be required to localize the fault when more than one fault candidate is inferred. Fault diagnosis is activated by a fault detection mechanism when a discrepancy between measured abnormal behavior and predicted system behavior is observed. The fault detection mechanism is not presented here","in this paper , the problem of fault diagnosis via integration of genetic algorithm -LRB- ga 's -RRB- and qualitative bond graph -LRB- qbg 's -RRB- be address . we suggest that ga 's can be use to search for possible fault component among a system of qualitative equation . the qbg be adopt as the modeling scheme to generate a set of qualitative equation . the qualitative bond graph provide a unified approach for modeling engineering system , in particular , mechatronic system . in order to demonstrate the performance of the propose algorithm , we have test the propose algorithm on an in-house design and build float disc experimental setup . result from fault diagnosis in the float disc system be present and discuss . additional measurement will be require to localize the fault when more than one fault candidate be infer . fault diagnosis be activate by a fault detection mechanism when a discrepancy between measure abnormal behavior and predict system behavior be observe . the fault detection mechanism be not present here",157,1
7259,Computers and IT,"This paper studies the case of the representation of a binary relation via a numerical function with threshold (error) depending on both compared alternatives. The error is considered to be multiplicative, its value being either directly or inversely proportional to the values of the numerical function. For the first case, it is proved that a binary relation is a semiorder. Moreover, any semiorder can be represented in this form. In the second case, the corresponding binary relation is an interval order","this paper study the case of the representation of a binary relation via a numerical function with threshold -LRB- error -RRB- depend on both compare alternative . the error be consider to be multiplicative , its value be either directly or inversely proportional to the value of the numerical function . for the first case , it be prove that a binary relation be a semiorder . moreover , any semiorder can be represent in this form . in the second case , the corresponding binary relation be an interval order",81,0.75
7260,Computers and IT,"The aim of this paper is to present a methodological approach for problems encountered in structural analysis. This approach is based upon the pretopological concepts of pseudoclosure and minimal closed subsets. The advantage of this approach is that it provides a framework which is general enough to model and formulate different types of connections that exist between the elements of a population. In addition, it has enabled us to develop a new structural analysis algorithm. An explanation of the definitions and properties of the pretopological concepts applied in this work is first shown and illustrated in sample settings. The structural analysis algorithm is then described and the results obtained in an economic study of the impact of geographic proximity on scientific collaborations are presented","the aim of this paper be to present a methodological approach for problem encounter in structural analysis . this approach be base upon the pretopological concept of pseudoclosure and minimal closed subset . the advantage of this approach be that it provide a framework which be general enough to model and formulate different type of connection that exist between the element of a population . in addition , it have enable us to develop a new structural analysis algorithm . an explanation of the definition and property of the pretopological concept apply in this work be first show and illustrate in sample setting . the structural analysis algorithm be then describe and the result obtain in an economic study of the impact of geographic proximity on scientific collaboration be present",124,0.75
7261,Computers and IT,"Efficient construction of indexes is very important in bulk-loading a database or adding a new index to an existing database since both of them should handle an enormous volume of data. In this paper, we propose an algorithm for batch-constructing the B/sup +/-tree, the most widely used index structure in database systems. The main characteristic of our algorithm is to simultaneously process all the key values to be placed on each B+-tree page when accessing the page. This avoids the overhead due to accessing the same page multiple times, which results from applying the B+-tree insertion algorithm repeatedly. For performance evaluation, we have analyzed our algorithm in terms of the number of disk accesses. The results show that the number of disk accesses excluding those in the relocation process is identical to the number of pages belonging to the B/sup +/-tree. Considering that the relocation process is an unavoidable preprocessing step for batch-constructing of B/sup +/-trees, our algorithm requires just one disk access per B+-tree page, and therefore turns out to be optimal. We also present the performance tendency in relation with different parameter values via simulation. Finally, we show the performance enhancement effect of our algorithm, compared with the one using repeated insertions through experiments","efficient construction of index be very important in bulk-load a database or add a new index to an exist database since both of them should handle an enormous volume of data . in this paper , we propose an algorithm for batch-construct the b/sup + / - tree , the most widely used index structure in database system . the main characteristic of our algorithm be to simultaneously process all the key value to be place on each b + - tree page when access the page . this avoid the overhead due to access the same page multiple time , which result from apply the b + - tree insertion algorithm repeatedly . for performance evaluation , we have analyze our algorithm in term of the number of disk access . the result show that the number of disk access exclude those in the relocation process be identical to the number of page belong to the b/sup + / - tree . consider that the relocation process be an unavoidable preprocessing step for batch-constructing of b/sup + / - tree , our algorithm require just one disk access per b + - tree page , and therefore turn out to be optimal . we also present the performance tendency in relation with different parameter value via simulation . finally , we show the performance enhancement effect of our algorithm , compare with the one use repeat insertion through experiment",206,0.6
7262,Computers and IT,"In control loops, each element introduces time delays. If those time delays are larger than the critical times for control of the system, a problem exists. I show a simple approach to mitigating this problem by basing the controller's decisions not on the observations themselves but on our projections as to what the observations will be at the time our controls reach the controlled system. Finally, I argue that synthetic simultaneity explains Libet's (1993) results better than Libet's explanation","in control loop , each element introduce time delay . if those time delay be large than the critical time for control of the system , a problem exist . i show a simple approach to mitigate this problem by base the controller 's decision not on the observation themselves but on our projection as to what the observation will be at the time our control reach the controlled system . finally , i argue that synthetic simultaneity explain libet 's -LRB- 1993 -RRB- result better than libet 's explanation",79,0.833333333
7263,Computers and IT,"Multi agent systems (MAS) have become the key technology for decomposing complex problems in order to solve them more efficiently, or for problems distributed in nature. However, many industrial applications, besides their distributed nature, also involve a large number of parameters and constraints, i. e. they are combinatorial. Solving such particularly hard problems efficiently requires programming tools that combine MAS technology with a programming schema that facilitates the modeling and solution of constraints. This paper presents MACLP (multi agent constraint logic programming), a logic programming platform for building, in a declarative way, multi agent systems with constraint-solving capabilities. MACLP extends CSPCONS, a logic programming system that permits distributed program execution through communicating sequential Prolog processes with constraints, by providing all the necessary facilities for communication between agents. These facilities abstract from the programmer all the low-level details of the communication and allow him to focus on the development of the agent itself","multi agent system -LRB- mas -RRB- have become the key technology for decompose complex problem in order to solve them more efficiently , or for problem distribute in nature . however , many industrial application , besides their distribute nature , also involve a large number of parameter and constraint , i. e. they be combinatorial . solve such particularly hard problem efficiently require programming tool that combine mas technology with a programming schema that facilitate the modeling and solution of constraint . this paper present maclp -LRB- multi agent constraint logic programming -RRB- , a logic programming platform for building , in a declarative way , multi agent system with constraint-solving capability . maclp extend cspcon , a logic programming system that permit distribute program execution through communicate sequential prolog process with constraint , by provide all the necessary facility for communication between agent . these facility abstract from the programmer all the low-level detail of the communication and allow him to focus on the development of the agent itself",152,0.75
7264,Computers and IT,"In this paper, a new method for predicting sea levels employing self-organizing feature maps is introduced. For that purpose the maps are transformed from an unsupervised learning procedure to a supervised one. Two concepts, originally developed to solve the problems of convergence of other network types, are proposed to be applied to Kohonen networks: a functional relationship between the number of neurons and the number of learning examples and a criterion to break off learning. The latter one can be shown to be conform with the process of self-organization by using U-matrices for visualization of the learning procedure. The predictions made using these neural models are compared for accuracy with observations and with the prognoses prepared using six models: two hydrodynamic models, a statistical model, a nearest neighbor model, the persistence model, and the verbal forecasts that are broadcast and kept on record by the Sea Level Forecast Service of the Federal Maritime and Hydrography Agency (BSH) in Hamburg. Before training the maps, the meteorological and oceanographic situation has to be condensed as well as possible, and the weight and learning vectors have to be made as small as possible. The self-organizing feature maps predict sea levels better than all six models of comparison","in this paper , a new method for predict sea level employ self-organizing feature map be introduce . for that purpose the map be transform from an unsupervised learning procedure to a supervised one . two concept , originally develop to solve the problem of convergence of other network type , be propose to be apply to kohonen network : a functional relationship between the number of neuron and the number of learn example and a criterion to break off learning . the latter one can be show to be conform with the process of self-organization by use u-matrice for visualization of the learn procedure . the prediction make use these neural model be compare for accuracy with observation and with the prognosis prepare use six model : two hydrodynamic model , a statistical model , a near neighbor model , the persistence model , and the verbal forecast that be broadcast and keep on record by the sea level forecast service of the federal maritime and hydrography agency -LRB- bsh -RRB- in hamburg . before train the map , the meteorological and oceanographic situation have to be condensed as well as possible , and the weight and learn vector have to be make as small as possible . the self-organizing feature map predict sea level better than all six model of comparison",204,0.882352941
7265,Computers and IT,"The Federal Railroad Administration (FRA) has developed a series of rail and rail-related analysis tools that assist FRA officials, Metropolitan Planning Organizations (MPOs), state Department of Transportation (DOT), and other constituents in evaluating the cost and benefits of potential infrastructure projects. To meet agency objectives, the FRA wants to add a high-speed rail grade crossing analysis tool to its package of rail and rail-related intermodal software products. This paper presents a conceptual decision support system (DSS) that can assist officials in achieving this goal. The paper first introduces the FRA's objectives and the role of cost benefit analysis in achieving these objectives. Next, there is a discussion of the models needed to assess the feasibility of proposed high-speed rail grade crossing investments and the presentation of a decision support system (DSS) that can deliver these models transparently to users. Then, the paper illustrates a system session and examines the potential benefits from system use","the federal railroad administration -LRB- fra -RRB- have develop a series of rail and rail-related analysis tool that assist fra official , metropolitan planning organization -LRB- mpo -RRB- , state department of transportation -LRB- dot -RRB- , and other constituent in evaluate the cost and benefit of potential infrastructure project . to meet agency objective , the fra want to add a high-speed rail grade cross analysis tool to its package of rail and rail-related intermodal software product . this paper present a conceptual decision support system -LRB- ds -RRB- that can assist official in achieve this goal . the paper first introduce the fra 's objective and the role of cost benefit analysis in achieve these objective . next , there be a discussion of the model need to assess the feasibility of propose high-speed rail grade cross investment and the presentation of a decision support system -LRB- ds -RRB- that can deliver these model transparently to user . then , the paper illustrate a system session and examine the potential benefit from system use",154,0.8
7266,Computers and IT,"This paper describes an approach to processing meaning instead of processing information in computing. Human intellectual activity is supported by linguistic activities in the brain. Therefore, processing the meaning of language instead of processing information should allow us to realize human intelligence on a computer. As an example of the proposed framework for processing meaning, we build a travel consultation dialogue system which can understand utterance by a user and retrieve information through dialogue. Through a simulation example of the system, we show that both information processing and language processing are integrated","this paper describe an approach to process meaning instead of process information in computing . human intellectual activity be support by linguistic activity in the brain . therefore , process the meaning of language instead of process information should allow us to realize human intelligence on a computer . as an example of the propose framework for process meaning , we build a travel consultation dialogue system which can understand utterance by a user and retrieve information through dialogue . through a simulation example of the system , we show that both information processing and language processing be integrate",92,0.625
7267,Computers and IT,"Endowing an autonomous system like a robot with intelligent behavior is difficult for several reasons. First, behavior is such a wide topic that a general framework paradigm of inspiration must be chosen in order to obtain a consistent model. Such a framework can be, for example, biological modeling or an artificial intelligence approach. Second, a general framework is not sufficient to determine a fully specified program to be implemented in a robot. Many choices, tuning and tests must be carried out before obtaining a robust system. A biological model is presented, based on the definition of cortex-like automata, representing elementary functions in the perceptive, motor or associative domain. These automata are connected in a network whose architecture, functioning and learning rules are described in a cortical framework. Second, the computational model derived from that biological model is specified. The way units exchange and compute variables through links is explained, with reference to corresponding biological elements. It is then easier to report experiments allowing an autonomous system to learn regularities of a simple environment and to exploit them to satisfy some internal drives. Even if additional biological hints can be added, this model allow us to better understand how a biological model can be implemented and how biological properties can emerge from a distributed set of units","endow an autonomous system like a robot with intelligent behavior be difficult for several reason . first , behavior be such a wide topic that a general framework paradigm of inspiration must be choose in order to obtain a consistent model . such a framework can be , for example , biological modeling or an artificial intelligence approach . second , a general framework be not sufficient to determine a fully specify program to be implement in a robot . many choice , tune and test must be carry out before obtain a robust system . a biological model be present , base on the definition of cortex-like automaton , represent elementary function in the perceptive , motor or associative domain . these automaton be connect in a network whose architecture , function and learn rule be describe in a cortical framework . second , the computational model derive from that biological model be specify . the way unit exchange and compute variable through link be explain , with reference to corresponding biological element . it be then easy to report experiment allow an autonomous system to learn regularity of a simple environment and to exploit them to satisfy some internal drive . even if additional biological hint can be add , this model allow us to better understand how a biological model can be implement and how biological property can emerge from a distribute set of unit",216,0.695652174
7268,Computers and IT,"Is a trademark dispute a case of David v. Goliath or a corporation fending off a greedy opportunist? This paper discusses the case of Uzi Nissan, who is locked in a multimillion-dollar legal battle over whether or not his use of the nissan. com Internet domain name infringes upon Japan's Nissan Motor Co. 's trademark. At the heart of the matter is the impact of the global Internet on trademark law, which traditionally has been strongly influenced by geographic considerations. The paper discusses the background to the case from both sides and the issues involved","be a trademark dispute a case of david v. goliath or a corporation fend off a greedy opportunist ? this paper discuss the case of uzi nissan , who be lock in a multimillion-dollar legal battle over whether or not his use of the nissan . com internet domain name infringe upon japan 's nissan motor co. 's trademark . at the heart of the matter be the impact of the global internet on trademark law , which traditionally have be strongly influence by geographic consideration . the paper discuss the background to the case from both side and the issue involve",95,0.833333333
7269,Computers and IT,"Slow temperature control is a challenging control problem. The problem becomes even more challenging when multiple zones are involved, such as in barrel temperature control for extruders. Often, strict closed-loop performance requirements (such as fast startup with no overshoot and maintaining tight temperature control during production) are given for such applications. When characteristics of the system are examined, it becomes clear that a commonly used proportional plus integral plus derivative (PID) controller cannot meet such performance specifications for this kind of system. The system either will overshoot or not maintain the temperature within the specified range during the production run. In order to achieve the required performance, a control strategy that utilizes techniques such as model predictive control, autotuning, and multiple parameter PID is formulated. This control strategy proves to be very effective in achieving the desired specifications, and is very robust","slow temperature control be a challenging control problem . the problem become even more challenging when multiple zone be involve , such as in barrel temperature control for extruder . often , strict closed-loop performance requirement -LRB- such as fast startup with no overshoot and maintain tight temperature control during production -RRB- be give for such application . when characteristic of the system be examine , it become clear that a commonly use proportional plus integral plus derivative -LRB- pid -RRB- controller can not meet such performance specification for this kind of system . the system either will overshoot or not maintain the temperature within the specify range during the production run . in order to achieve the required performance , a control strategy that utilize technique such as model predictive control , autotuning , and multiple parameter pid be formulate . this control strategy prove to be very effective in achieve the desire specification , and be very robust",142,0.666666667
7270,Computers and IT,"National governments are working to tame activity on the Internet. They have worked steadily to extend control over online activities that they believe affect their interests, even when the activities occur outside their borders. These usually involve what governments regard as their domain: protecting public order, enforcing commercial laws, and, occasionally, protecting consumer interests. Methods have included assertions or legal jurisdiction based on where material is accessible instead of where it originates, and the blocking of sites, service providers, or entire high level domains from access by citizens. Such instances are mentioned in this article. Whilst larger companies are able to defend themselves against overseas lawsuits, individuals and smaller organizations lack the resources to defend what are often normal business activities at home, but could violate the laws of local jurisdictions in countries around the world. The problems of libel are discussed as are the blocking of certain sites by certain countries. Efforts to draw up Internet treaties are also mentioned","national government be work to tame activity on the internet . they have work steadily to extend control over online activity that they believe affect their interest , even when the activity occur outside their border . these usually involve what government regard as their domain : protect public order , enforce commercial law , and , occasionally , protect consumer interest . method have include assertion or legal jurisdiction base on where material be accessible instead of where it originate , and the block of site , service provider , or entire high level domain from access by citizen . such instance be mention in this article . whilst large company be able to defend themselves against overseas lawsuit , individual and small organization lack the resource to defend what be often normal business activity at home , but could violate the law of local jurisdiction in country around the world . the problem of libel be discuss as be the block of certain site by certain country . effort to draw up internet treaty be also mention",161,0.5
7271,Computers and IT,"Election officials are examining technologies to address a wide range of voting issues. The problems observed in the November 2000 US election accelerated existing trends to get rid of lever machines, punch-cards, and hand-counted paper ballots and replace them with mark-sense balloting, Internet, and automatic teller machine (ATM) kiosk style computer-based systems. An estimated US $2-$4 billion will be spent in the United States and Canada to update voting systems during the next decade. Voting online might enable citizens to vote even if they are unable to get to the polls. Yet making these methods work right turns out to be considerably more difficult than originally thought. New electronic voting systems pose risks as well as solutions. As it turns out, many of the voting products currently for sale provide less accountability, poorer reliability, and greater opportunity for widespread fraud than those already in use. This paper discusses the technology available and how to ensure accurate ballots","election official be examine technology to address a wide range of vote issue . the problem observe in the november 2000 us election accelerate exist trend to get rid of lever machine , punch-card , and hand-counted paper ballot and replace them with mark-sense balloting , internet , and automatic teller machine -LRB- atm -RRB- kiosk style computer-based system . an estimate us $ 2 - $ 4 billion will be spend in the unite state and canada to update vote system during the next decade . vote online might enable citizen to vote even if they be unable to get to the poll . yet make these method work right turn out to be considerably more difficult than originally think . new electronic voting system pose risk as well as solution . as it turn out , many of the voting product currently for sale provide less accountability , poor reliability , and great opportunity for widespread fraud than those already in use . this paper discuss the technology available and how to ensure accurate ballot",157,0.333333333
7272,Computers and IT,"With the release of the first Tablet PCs produced to Microsoft Corp. 's general specifications, handheld computers may be about to leap into the ring with today's laptops. They will be about the size of the smaller laptops, will be at least as powerful, and maybe their biggest selling point-will be able to handle handwritten text. The Tablet PCs will be amply configured, general-purpose machines with more than enough power to run the full-blown Windows XP operating system. In particular, they will allow handwritten text to be entered onto a digitizing tablet and recognized, a functionality that's called pen-based computing. The Tablet PC will far outpace the computing power of existing small devices such as PDAs (personal digital assistants), including those variants based on Microsoft's own Pocket PC operating system","with the release of the first tablet pc produce to microsoft corp. 's general specification , handheld computer may be about to leap into the ring with today 's laptop . they will be about the size of the small laptop , will be at least as powerful , and maybe their big selling point-will be able to handle handwritten text . the tablet pc will be amply configure , general-purpose machine with more than enough power to run the full-blown window xp operate system . in particular , they will allow handwritten text to be enter onto a digitize tablet and recognize , a functionality that ' call pen-based computing . the tablet pc will far outpace the computing power of exist small device such as pda -LRB- personal digital assistant -RRB- , include those variant base on microsoft 's own pocket pc operate system",130,1
7273,Computers and IT,"A horizontal waypoint guidance algorithm is proposed by applying line-following guidance to waypoint line segments in sequence. The line-following guidance is designed using an LQR (linear quadratic regulator). Then, the optimal waypoint changing points are derived by minimizing the accelerations required for changing the waypoint line segments. Also derived is a sufficient condition for the stability bound of ground speed changes based on the Lyapunov stability theorem. Simulation results show that the proposed algorithm can effectively guide a vehicle along the sequence of waypoint line segments","a horizontal waypoint guidance algorithm be propose by apply line-following guidance to waypoint line segment in sequence . the line-following guidance be design use an lqr -LRB- linear quadratic regulator -RRB- . then , the optimal waypoint change point be derive by minimize the acceleration require for change the waypoint line segment . also derive be a sufficient condition for the stability bind of ground speed change base on the lyapunov stability theorem . simulation result show that the propose algorithm can effectively guide a vehicle along the sequence of waypoint line segment",86,0.642857143
7274,Computers and IT,"A structure for adaptively separating, enhancing and tracking uncorrelated sources with an electromagnetic vector sensor (EMVS) is presented. The structure consists of a set of parallel spatial processors, one for each individual source. Two stages of processing are involved in each spatial processor. The first preprocessing stage rejects all other sources except the one of interest, while the second stage is an adaptive one for maximizing the signal-to-noise ratio (SNR) and tracking the desired source. The preprocessings are designed using the latest source parameter estimates obtained from the source trackers, and a redesign is activated periodically or whenever any source has been detected by the source trackers to have made significant movement. Compared with conventional adaptive beamforming, the algorithm has the advantage that no a priori information on any desired signal location is needed, the sources are separated at maximum SNR, and their locations are available. The structure is also well suited for parallel implementation. Numerical examples are included to illustrate the capability and performance of the algorithm","a structure for adaptively separate , enhance and track uncorrelated source with an electromagnetic vector sensor -LRB- emv -RRB- be present . the structure consist of a set of parallel spatial processor , one for each individual source . two stage of processing be involve in each spatial processor . the first preprocessing stage reject all other source except the one of interest , while the second stage be an adaptive one for maximize the signal-to-noise ratio -LRB- snr -RRB- and track the desire source . the preprocessing be design use the late source parameter estimate obtain from the source tracker , and a redesign be activate periodically or whenever any source have be detect by the source tracker to have make significant movement . compare with conventional adaptive beamforming , the algorithm have the advantage that no a priori information on any desire signal location be need , the source be separate at maximum snr , and their location be available . the structure be also well suit for parallel implementation . numerical example be include to illustrate the capability and performance of the algorithm",168,0.428571429
7275,Computers and IT,"This work considers hybrid systems with continuous-valued target states and discrete-valued regime variable. The changes (switches) of the regime variable are modeled by a finite state Markov chain with unknown and random transition probabilities following Dirichlet distributions. Our work analytically derives the marginal posterior distribution of the states and regime variables, the transition probabilities being integrated out. This leads to a variety of recursive hybrid state estimation schemes which are an appealing intuitive and straightforward extension of standard algorithms. Their performance is illustrated by a maneuvering target tracking example","this work consider hybrid system with continuous-valued target state and discrete-valued regime variable . the change -LRB- switch -RRB- of the regime variable be model by a finite state markov chain with unknown and random transition probability follow dirichlet distribution . our work analytically derive the marginal posterior distribution of the state and regime variable , the transition probability be integrate out . this lead to a variety of recursive hybrid state estimation scheme which be an appealing intuitive and straightforward extension of standard algorithm . their performance be illustrate by a maneuver target tracking example",89,0.727272727
7276,Computers and IT,"A MATLAB code capable of plotting ambiguity functions of many different radar signals is presented. The program makes use of MATLAB's sparse matrix operations, and avoids loops. The program could be useful as a pedagogical tool in radar courses teaching pulse compression","a matlab code capable of plot ambiguity function of many different radar signal be present . the program make use of matlab 's sparse matrix operation , and avoid loop . the program could be useful as a pedagogical tool in radar course teach pulse compression",42,0.666666667
7277,Computers and IT,"In this study a particular incremental motion control problem, which is specified by the trapezoidal velocity profile using multisegment sliding mode control (MSSMC), is proposed to control a permanent magnet linear synchronous motor (PMLSM) servo drive system. First, the structure and operating principle of the PMLSM are described in detail. Second, a field-oriented control PMLSM servo drive is introduced. Then, each segment of the multisegment switching surfaces is designed to match the corresponding part of the trapezoidal velocity profile, thus the motor dynamics on the specified-segment switching surface have the desired velocity or acceleration corresponding part of the trapezoidal velocity profile. In addition, the proposed control system is implemented in a PC-based computer control system. Finally, the effectiveness of the proposed PMLSM servo drive system is demonstrated by some simulated and experimental results","in this study a particular incremental motion control problem , which be specify by the trapezoidal velocity profile use multisegment slide mode control -LRB- mssmc -RRB- , be propose to control a permanent magnet linear synchronous motor -LRB- pmlsm -RRB- servo drive system . first , the structure and operate principle of the pmlsm be describe in detail . second , a field-oriented control pmlsm servo drive be introduce . then , each segment of the multisegment switch surface be design to match the corresponding part of the trapezoidal velocity profile , thus the motor dynamic on the specified-segment switch surface have the desire velocity or acceleration corresponding part of the trapezoidal velocity profile . in addition , the propose control system be implement in a pc-based computer control system . finally , the effectiveness of the propose pmlsm servo drive system be demonstrate by some simulated and experimental result",133,0.888888889
7278,Computers and IT,"A feedforward maximum power (MP) point tracking scheme is developed for the interleaved dual boost (IDB) converter fed photovoltaic (PV) system using fuzzy controller. The tracking algorithm changes the duty ratio of the converter such that the solar cell array (SCA) voltage equals the voltage corresponding to the MP point at that solar insolation. This is done by the feedforward loop, which generates an error signal by comparing the instantaneous array voltage and reference voltage. The reference voltage for the feedforward loop, corresponding to the MP point, is obtained by an off-line trained neural network. Experimental data is used for off-line training of the neural network, which employs back-propagation algorithm. The proposed fuzzy feedforward peak power tracking effectiveness is demonstrated through the simulation and experimental results, and compared with the conventional proportional plus integral (PI) controller based system. Finally, a comparative study of interleaved boost and conventional boost converter for the PV applications is given and their suitability is discussed","a feedforward maximum power -LRB- mp -RRB- point tracking scheme be develop for the interleaved dual boost -LRB- idb -RRB- converter feed photovoltaic -LRB- pv -RRB- system use fuzzy controller . the tracking algorithm change the duty ratio of the converter such that the solar cell array -LRB- sca -RRB- voltage equal the voltage corresponding to the mp point at that solar insolation . this be do by the feedforward loop , which generate an error signal by compare the instantaneous array voltage and reference voltage . the reference voltage for the feedforward loop , corresponding to the mp point , be obtain by an off-line trained neural network . experimental data be use for off-line training of the neural network , which employ back-propagation algorithm . the propose fuzzy feedforward peak power tracking effectiveness be demonstrate through the simulation and experimental result , and compare with the conventional proportional plus integral -LRB- pi -RRB- controller base system . finally , a comparative study of interleaved boost and conventional boost converter for the pv application be give and their suitability be discuss",160,0.5625
7279,Computers and IT,"Practical requirements on the design of control systems, especially process control systems, are usually specified in terms of time-domain response, such as overshoot and rise time, or frequency-domain response, such as resonance peak and stability margin. Although numerous methods have been developed for the design of the proportional-integral-derivative (PID) controller, little work has been done in relation to the quantitative time-domain and frequency-domain responses. In this paper, we study the following problem: Given a nominal stable process with time delay, we design a suboptimal PID controller to achieve the required time-domain response or frequency-domain response for the nominal system or the uncertain system. An H/sub infinity / PID controller is developed based on optimal control theory and the parameters are derived analytically. Its properties are investigated and compared with that of two developed suboptimal controllers: an H/sub 2/ PID controller and a Maclaurin PID controller","practical requirement on the design of control system , especially process control system , be usually specify in term of time-domain response , such as overshoot and rise time , or frequency-domain response , such as resonance peak and stability margin . although numerous method have be develop for the design of the proportional-integral-derivative -LRB- pid -RRB- controller , little work have be do in relation to the quantitative time-domain and frequency-domain response . in this paper , we study the following problem : give a nominal stable process with time delay , we design a suboptimal pid controller to achieve the require time-domain response or frequency-domain response for the nominal system or the uncertain system . an h/sub infinity / pid controller be develop base on optimal control theory and the parameter be derive analytically . its property be investigate and compare with that of two develop suboptimal controller : an h/sub 2 / pid controller and a maclaurin pid controller",145,0.928571429
7280,Computers and IT,"Quantitative and robust speed control for a switched reluctance motor (SRM) drive is considered to be rather difficult and challenging owing to its highly nonlinear dynamic behavior. A speed control scheme having two-degree-of-freedom (2DOF) structure is developed here to improve the speed dynamic response of an SRM drive. In the proposed control scheme, the feedback controller is quantitatively designed to meet the desired regulation control requirements first. Then a reference model and a command feedforward controller based on an inverse plant model are employed to yield the desired tracking response at nominal case. As the variations of system parameters and operating conditions occur, the prescribed control specifications may not be satisfied any more. To improve this, the inverse model is adaptively tuned by a fuzzy control scheme so that the model-following tracking error is significantly reduced. In addition, a simple disturbance cancellation robust controller is added to improve the tracking and regulation control performances further","quantitative and robust speed control for a switch reluctance motor -LRB- srm -RRB- drive be consider to be rather difficult and challenging owing to its highly nonlinear dynamic behavior . a speed control scheme have two-degree-of-freedom -LRB- 2dof -RRB- structure be develop here to improve the speed dynamic response of an srm drive . in the propose control scheme , the feedback controller be quantitatively design to meet the desire regulation control requirement first . then a reference model and a command feedforward controller base on an inverse plant model be employ to yield the desire tracking response at nominal case . as the variation of system parameter and operating condition occur , the prescribe control specification may not be satisfy any more . to improve this , the inverse model be adaptively tune by a fuzzy control scheme so that the model-following tracking error be significantly reduce . in addition , a simple disturbance cancellation robust controller be add to improve the tracking and regulation control performance far",155,0.722222222
7281,Computers and IT,"This paper presents design and implementation of a robust fuzzy controlled photovoltaic (PV) power inverter with Taguchi tuned scaling factors. To achieve fast transient response, small steady-state error and system robustness, a robust fuzzy controller is adopted, in which its input and output scaling factors are determined efficiently by using the Taguchi-tuning algorithm. The proposed system can operate in different modes, grid-connection mode and stand-alone mode, and can accommodate wide load variations. Simulation results and hardware measurements obtained from a prototype with a microcontroller (Intel 80196KC) are presented to verify the theoretical discussions, and its adaptivity, robustness and feasibility","this paper present design and implementation of a robust fuzzy controlled photovoltaic -LRB- pv -RRB- power inverter with taguchi tune scaling factor . to achieve fast transient response , small steady-state error and system robustness , a robust fuzzy controller be adopt , in which its input and output scaling factor be determine efficiently by use the taguchi-tuning algorithm . the propose system can operate in different mode , grid-connection mode and stand-alone mode , and can accommodate wide load variation . simulation result and hardware measurement obtain from a prototype with a microcontroller -LRB- intel 80196kc -RRB- be present to verify the theoretical discussion , and its adaptivity , robustness and feasibility",99,0.769230769
7282,Computers and IT,"Design, simulation and experimental implementation of a wavelet basis function network learning controller for linear brushless dc motors (LBDCM) are considered. Stability robustness with position tracking is the primary concern. The proposed controller deals mainly with external disturbances, e. g. nonlinear friction force and payload variation in motion control of linear motors. It consists of two parts, one is a state feedback component, and the other one is a learning feedback component. The state feedback controller is designed on the basis of a simple linear model, and the learning feedback component is a wavelet neural controller. The attenuation effect of wavelet neural networks on friction force is first verified by the numerical method. The learning effect of wavelet neural networks on friction force is also shown in the numerical results. Then, a wavelet neural network is applied on a real LBDCM to on-line suppress the friction force, which may be variable due to the different lubrication. The effectiveness of the proposed control schemes is demonstrated by simulated and experimental results","design , simulation and experimental implementation of a wavelet basis function network learn controller for linear brushless dc motor -LRB- lbdcm -RRB- be consider . stability robustness with position tracking be the primary concern . the propose controller deal mainly with external disturbance , e. g. nonlinear friction force and payload variation in motion control of linear motor . it consist of two part , one be a state feedback component , and the other one be a learn feedback component . the state feedback controller be design on the basis of a simple linear model , and the learn feedback component be a wavelet neural controller . the attenuation effect of wavelet neural network on friction force be first verify by the numerical method . the learn effect of wavelet neural network on friction force be also show in the numerical result . then , a wavelet neural network be apply on a real lbdcm to on-line suppress the friction force , which may be variable due to the different lubrication . the effectiveness of the propose control scheme be demonstrate by simulated and experimental result",170,0.866666667
7283,Computers and IT,"Robust adaptive matched filtering (AMF) whereby outlier data vectors are censored from the covariance matrix estimate is considered in a maximum likelihood estimation (MLE) setting. It is known that outlier data vectors whose steering vector is highly correlated with the desired steering vector, can significantly degrade the performance of AMF algorithms such as sample matrix inversion (SMI) or fast maximum likelihood (FML). Four new algorithms that censor outliers are presented which are derived via approximation to the MLE solution. Two algorithms each are related to using the SMI or the FML to estimate the unknown underlying covariance matrix. Results are presented using computer simulations which demonstrate the relative effectiveness of the four algorithms versus each other and also versus the SMI and FML algorithms in the presence of outliers and no outliers. It is shown that one of the censoring algorithms, called the reiterative censored fast maximum likelihood (CFML) technique is significantly superior to the other three censoring methods in stressful outlier scenarios","robust adaptive match filter -LRB- amf -RRB- whereby outli data vector be censor from the covariance matrix estimate be consider in a maximum likelihood estimation -LRB- mle -RRB- setting . it be know that outli data vector whose steering vector be highly correlate with the desire steering vector , can significantly degrade the performance of amf algorithm such as sample matrix inversion -LRB- smi -RRB- or fast maximum likelihood -LRB- fml -RRB- . four new algorithm that censor outlier be present which be derive via approximation to the mle solution . two algorithm each be relate to use the smi or the fml to estimate the unknown underlie covariance matrix . result be present use computer simulation which demonstrate the relative effectiveness of the four algorithm versus each other and also versus the smi and fml algorithm in the presence of outlier and no outlier . it be show that one of the censor algorithm , call the reiterative censor fast maximum likelihood -LRB- cfml -RRB- technique be significantly superior to the other three censoring method in stressful outli scenario",163,0.625
7284,Computers and IT,"Initial attitude acquisition by a modern star tracker is investigated here. Criteria for efficient organization of the on-board database are discussed with reference to a brightness-independent initial acquisition algorithm. Star catalog generation preprocessing is described, with emphasis on the identification of minimum star brightness for detection by a sensor based on a charge coupled device (CCD) photodetector. This is a crucial step for proper evaluation of the attainable sky coverage when selecting the stars to be included in the on-board catalog. Test results are also reported, both for reliability and accuracy, even if the former is considered to be the primary target. Probability of erroneous solution is 0. 2% in the case of single runs of the procedure, while attitude determination accuracy is in the order of 0. 02 degrees in the average for the computation of the inertial pointing of the boresight axis","initial attitude acquisition by a modern star tracker be investigate here . criterion for efficient organization of the on-board database be discuss with reference to a brightness-independent initial acquisition algorithm . star catalog generation preprocessing be describe , with emphasis on the identification of minimum star brightness for detection by a sensor base on a charge couple device -LRB- ccd -RRB- photodetector . this be a crucial step for proper evaluation of the attainable sky coverage when select the star to be include in the on-board catalog . test result be also report , both for reliability and accuracy , even if the former be consider to be the primary target . probability of erroneous solution be 0 . 2 % in the case of single run of the procedure , while attitude determination accuracy be in the order of 0 . 02 degree in the average for the computation of the inertial point of the boresight axi",144,0.6
7285,Computers and IT,"Multiple model adaptive estimation (MMAE) with filter spawning is used to detect and estimate partial actuator failures on the VISTA F-16. The truth model is a full six-degree-of-freedom simulation provided by Calspan and General Dynamics. The design models are chosen as 13-state linearized models, including first order actuator models. Actuator failures are incorporated into the truth model and design model assuming a ""failure to free stream. "" Filter spawning is used to include additional filters with partial actuator failure hypotheses into the MMAE bank. The spawned filters are based on varying degrees of partial failures (in terms of effectiveness) associated with the complete-actuaton-failure hypothesis with the highest conditional probability of correctness at the current time. Thus, a blended estimate of the failure effectiveness is found using the filters' estimates based upon a no-failure hypothesis, a complete actuator failure hypothesis, and the spawned filters' partial-failure hypotheses. This yields substantial precision in effectiveness estimation, compared with what is possible without spawning additional filters, making partial failure adaptation a viable methodology","multiple model adaptive estimation -LRB- mmae -RRB- with filter spawning be use to detect and estimate partial actuator failure on the vista f-16 . the truth model be a full six-degree-of-freedom simulation provide by calspan and general dynamic . the design model be choose as 13-state linearize model , include first order actuator model . actuator failure be incorporate into the truth model and design model assume a `` failure to free stream . '' filter spawning be use to include additional filter with partial actuator failure hypothes into the mmae bank . the spawn filter be base on vary degree of partial failure -LRB- in term of effectiveness -RRB- associate with the complete-actuaton-failure hypothesis with the high conditional probability of correctness at the current time . thus , a blended estimate of the failure effectiveness be find use the filter ' estimate base upon a no-failure hypothesis , a complete actuator failure hypothesis , and the spawn filter ' partial-failure hypothesis . this yield substantial precision in effectiveness estimation , compare with what be possible without spawn additional filter , make partial failure adaptation a viable methodology",168,0.8125
7286,Computers and IT,"We have developed a two-step procedure for signal processing of fetal biomagnetic recordings that removes cardiac interference and noise. First, a modified matched filter (MF) is applied to remove maternal cardiac interference; then, a simple signal space projection (SSP) is applied to remove noise. The key difference between our MF and a conventional one is that the interference template and the template scaling are derived from a signal that has been spatially filtered to isolate the interference, rather than from the raw signal. Unlike conventional MFs, ours is able to separate maternal and fetal cardiac complexes, even when they have similar morphology and overlap strongly. When followed by a SSP that preserves only the signal subspace, the noise is reduced to a low level","we have develop a two-step procedure for signal processing of fetal biomagnetic recording that remove cardiac interference and noise . first , a modify match filter -LRB- mf -RRB- be apply to remove maternal cardiac interference ; then , a simple signal space projection -LRB- ssp -RRB- be apply to remove noise . the key difference between our mf and a conventional one be that the interference template and the template scaling be derive from a signal that have be spatially filter to isolate the interference , rather than from the raw signal . unlike conventional mf , ours be able to separate maternal and fetal cardiac complex , even when they have similar morphology and overlap strongly . when follow by a ssp that preserve only the signal subspace , the noise be reduce to a low level",124,0.545454545
7287,Computers and IT,"This paper presents a brain-computer interface (BCI) that can help users to input phone numbers. The system is based on the steady-state visual evoked potential (SSVEP). Twelve buttons illuminated at different rates were displayed on a computer monitor. The buttons constituted a virtual telephone keypad, representing the ten digits 0-9, BACKSPACE, and ENTER. Users could input phone number by gazing at these buttons. The frequency-coded SSVEP was used to judge which button the user desired. Eight of the thirteen subjects succeeded in ringing the mobile phone using the system. The average transfer rate over all subjects was 27. 15 bits/min. The attractive features of the system are noninvasive signal recording, little training required for use, and high information transfer rate. Approaches to improve the performance of the system are discussed","this paper present a brain-computer interface -LRB- bci -RRB- that can help user to input phone number . the system be base on the steady-state visual evoked potential -LRB- ssvep -RRB- . twelve button illuminate at different rate be display on a computer monitor . the button constitute a virtual telephone keypad , represent the ten digit 0-9 , backspace , and enter . user could input phone number by gaze at these button . the frequency-coded ssvep be use to judge which button the user desire . eight of the thirteen subject succeed in ring the mobile phone use the system . the average transfer rate over all subject be 27 . 15 bits/min . the attractive feature of the system be noninvasive signal recording , little training require for use , and high information transfer rate . approach to improve the performance of the system be discuss",130,0.444444444
7288,Computers and IT,"Linear approaches like the minimum-norm least-square algorithm show insufficient performance when it comes to estimating the activation time map on the surface of the heart from electrocardiographic (ECG) mapping data. Additional regularization has to be considered leading to a nonlinear problem formulation. The Gauss-Newton approach is one of the standard mathematical tools capable of solving this kind of problem. To our experience, this algorithm has specific drawbacks which are caused by the applied regularization procedure. In particular, under clinical conditions the amount of regularization cannot be determined clearly. For this reason, we have developed an iterative algorithm solving this nonlinear problem by a sequence of regularized linear problems. At each step of iteration, an individual L-curve is computed. Subsequent iteration steps are performed with the individual optimal regularization parameter. This novel approach is compared with the standard Gauss-Newton approach. Both methods are applied to simulated ECG mapping data as well as to single beat sinus rhythm data from two patients recorded in the catheter laboratory. The proposed approach shows excellent numerical and computational performance, even under clinical conditions at which the Gauss-Newton approach begins to break down","linear approach like the minimum-norm least-square algorithm show insufficient performance when it come to estimate the activation time map on the surface of the heart from electrocardiographic -LRB- ecg -RRB- mapping data . additional regularization have to be consider lead to a nonlinear problem formulation . the gauss-newton approach be one of the standard mathematical tool capable of solve this kind of problem . to our experience , this algorithm have specific drawback which be cause by the apply regularization procedure . in particular , under clinical condition the amount of regularization can not be determine clearly . for this reason , we have develop an iterative algorithm solve this nonlinear problem by a sequence of regularize linear problem . at each step of iteration , an individual l-curve be compute . subsequent iteration step be perform with the individual optimal regularization parameter . this novel approach be compare with the standard gauss-newton approach . both method be apply to simulated ecg mapping data as well as to single beat sinus rhythm data from two patient record in the catheter laboratory . the proposed approach show excellent numerical and computational performance , even under clinical condition at which the gauss-newton approach begin to break down",187,0.4
7289,Computers and IT,We describe a variational Bayesian algorithm for the estimation of a multivariate autoregressive model with time-varying coefficients that adapt according to a linear dynamical system. The algorithm allows for time and frequency domain characterization of nonstationary multivariate signals and is especially suited to the analysis of event-related data. Results are presented on synthetic data and real electroencephalogram data recorded in event-related desynchronization and photic synchronization scenarios,we describe a variational bayesian algorithm for the estimation of a multivariate autoregressive model with time-varying coefficient that adapt accord to a linear dynamical system . the algorithm allow for time and frequency domain characterization of nonstationary multivariate signal and be especially suit to the analysis of event-related data . result be present on synthetic data and real electroencephalogram data record in event-related desynchronization and photic synchronization scenario,66,0.545454545
7290,Computers and IT,"The paper is written for all who develop and use P&IDs. It will aid in solving the long existing and continuing problem of confusing information on P&IDs. The acronym P&ID is widely understood to mean the principal document used to define the details of how a process works and how it is controlled. The ISA Dictionary definition for P&ID tells what they do, ""show the interconnection of process equipment and the instrumentation used to control the process. In the process industry a standard set of symbols is used to prepare drawings of processes. The instrument symbols used in these drawings are generally based on ISA-S5. 1. "" In the paper the ISA standard is referred to as ISA-5. 1. The article develops the concept of the ""standard"" and poses some of the questions that the ""standard"" can answer","the paper be write for all who develop and use p & id . it will aid in solve the long exist and continue problem of confuse information on p & id . the acronym p & id be widely understand to mean the principal document use to define the detail of how a process work and how it be control . the isa dictionary definition for p & id tell what they do , `` show the interconnection of process equipment and the instrumentation use to control the process . in the process industry a standard set of symbol be use to prepare drawing of process . the instrument symbol use in these drawing be generally base on isa-s5 . 1 . '' in the paper the isa standard be refer to as isa-5 . 1 . the article develop the concept of the `` standard '' and pose some of the question that the `` standard '' can answer",138,0.6
7291,Computers and IT,"A new breath-detection algorithm is presented, intended to automate the analysis of respiratory data acquired during sleep. The algorithm is based on two independent artificial neural networks (ANN/sub insp/ and ANN/sub expi/) that recognize, in the original signal, windows of interest where the onset of inspiration and expiration occurs. Postprocessing consists in finding inside each of these windows of interest minimum and maximum corresponding to each inspiration and expiration. The ANN/sub insp/ and ANN/sub expi/ correctly determine respectively 98. 0% and 98. 7% of the desired windows, when compared with 29 820 inspirations and 29 819 expirations detected by a human expert, obtained from three entire-night recordings. Postprocessing allowed determination of inspiration and expiration onsets with a mean difference with respect to the same human expert of (mean +or- SD) 34 +or- 71 ms for inspiration and 5 +or- 46 ms for expiration. The method proved to be effective in detecting the onset of inspiration and expiration in full night continuous recordings. A comparison of five human experts performing the same classification task yielded that the automated algorithm was undifferentiable from these human experts, failing within the distribution of human expert results. Besides being applicable to adult respiratory volume data, the presented algorithm was also successfully applied to infant sleep data, consisting of uncalibrated rib cage and abdominal movement recordings. A comparison with two previously published algorithms for breath detection in respiratory volume signal shows that the presented algorithm has a higher specificity, while presenting similar or higher positive predictive values","a new breath-detection algorithm be present , intend to automate the analysis of respiratory data acquire during sleep . the algorithm be base on two independent artificial neural network -LRB- ann/sub insp / and ann/sub expi / -RRB- that recognize , in the original signal , window of interest where the onset of inspiration and expiration occur . postprocess consist in find inside each of these window of interest minimum and maximum corresponding to each inspiration and expiration . the ann/sub insp / and ann/sub expi / correctly determine respectively 98 . 0 % and 98 . 7 % of the desire window , when compare with 29 820 inspiration and 29 819 expiration detect by a human expert , obtain from three entire-night recording . postprocessing allow determination of inspiration and expiration onset with a mean difference with respect to the same human expert of -LRB- mean + or - sd -RRB- 34 + or - 71 m for inspiration and 5 + or - 46 m for expiration . the method prove to be effective in detect the onset of inspiration and expiration in full night continuous recording . a comparison of five human expert perform the same classification task yield that the automate algorithm be undifferentiable from these human expert , fail within the distribution of human expert result . besides be applicable to adult respiratory volume data , the present algorithm be also successfully apply to infant sleep data , consist of uncalibrated rib cage and abdominal movement recording . a comparison with two previously publish algorithm for breath detection in respiratory volume signal show that the present algorithm have a high specificity , while present similar or high positive predictive value",251,0.625
7292,Computers and IT,"In electromagnetic source analysis, it is necessary to determine how many sources are required to describe the electroencephalogram or magnetoencephalogram adequately. Model selection procedures (MSPs) or goodness of fit procedures give an estimate of the required number of sources. Existing and new MSPs are evaluated in different source and noise settings: two sources which are close or distant and noise which is uncorrelated or correlated. The commonly used MSP residual variance is seen to be ineffective, that is it often selects too many sources. Alternatives like the adjusted Hotelling's test, Bayes information criterion and the Wald test on source amplitudes are seen to be effective. The adjusted Hotelling's test is recommended if a conservative approach is taken and MSPs such as Bayes information criterion or the Wald test on source amplitudes are recommended if a more liberal approach is desirable. The MSPs are applied to empirical data (visual evoked fields)","in electromagnetic source analysis , it be necessary to determine how many source be require to describe the electroencephalogram or magnetoencephalogram adequately . model selection procedure -LRB- msp -RRB- or goodness of fit procedure give an estimate of the required number of source . exist and new msp be evaluate in different source and noise setting : two source which be close or distant and noise which be uncorrelated or correlated . the commonly use msp residual variance be see to be ineffective , that be it often select too many source . alternative like the adjusted hotelling 's test , bay information criterion and the wald test on source amplitude be see to be effective . the adjusted hotelling 's test be recommend if a conservative approach be take and msp such as bayes information criterion or the wald test on source amplitude be recommend if a more liberal approach be desirable . the msp be apply to empirical data -LRB- visual evoked field -RRB-",150,0.538461538
7293,Computers and IT,"In order to assess the possible time-varying properties of renal autoregulation, time-frequency and time-scaling methods were applied to renal blood flow under broad-band forced arterial blood pressure fluctuations and single-nephron renal blood flow with spontaneous oscillations obtained from normotensive (Sprague-Dawley, Wistar, and Long-Evans) rats, and spontaneously hypertensive rats. Time-frequency analyses of normotensive and hypertensive blood flow data obtained from either the whole kidney or the single-nephron show that indeed both the myogenic and tubuloglomerular feedback (TGF) mechanisms have time-varying characteristics. Furthermore, we utilized the Renyi entropy to measure the complexity of blood-flow dynamics in the time-frequency plane in an effort to discern differences between normotensive and hypertensive recordings. We found a clear difference in Renyi entropy between normotensive and hypertensive blood flow recordings at the whole kidney level for both forced (p 0. 037) and spontaneous arterial pressure fluctuations (p 0. 033), and at the single-nephron level (p 0. 008). Especially at the single-nephron level, the mean Renyi entropy is significantly larger for hypertensive than normotensive rats, suggesting more complex dynamics in the hypertensive condition. To further evaluate whether or not the separation of dynamics between normotensive and hypertensive rats is found in the prescribed frequency ranges of the myogenic and TGF mechanisms, we employed multiresolution wavelet transform. Our analysis revealed that exclusively over scale ranges corresponding to the frequency intervals of the myogenic and TGF mechanisms, the widths of the blood flow wavelet coefficients fall into disjoint sets for normotensive and hypertensive rats. The separation of the scales at the myogenic and TGF frequency ranges is distinct and obtained with 100% accuracy. However, this observation remains valid only for the whole kidney blood pressure/flow data. The results suggest that understanding of the time-varying properties of the two mechanisms is required for a complete description of renal autoregulation","in order to assess the possible time-varying property of renal autoregulation , time-frequency and time-scaling method be apply to renal blood flow under broad-band force arterial blood pressure fluctuation and single-nephron renal blood flow with spontaneous oscillation obtain from normotensive -LRB- sprague-dawley , wistar , and long-evan -RRB- rat , and spontaneously hypertensive rat . time-frequency analysis of normotensive and hypertensive blood flow data obtain from either the whole kidney or the single-nephron show that indeed both the myogenic and tubuloglomerular feedback -LRB- tgf -RRB- mechanism have time-varying characteristic . furthermore , we utilize the renyi entropy to measure the complexity of blood-flow dynamic in the time-frequency plane in an effort to discern difference between normotensive and hypertensive recording . we find a clear difference in renyi entropy between normotensive and hypertensive blood flow recording at the whole kidney level for both force -LRB- p 0 . 037 -RRB- and spontaneous arterial pressure fluctuation -LRB- p 0 . 033 -RRB- , and at the single-nephron level -LRB- p 0 . 008 -RRB- . especially at the single-nephron level , the mean renyi entropy be significantly large for hypertensive than normotensive rat , suggest more complex dynamic in the hypertensive condition . to far evaluate whether or not the separation of dynamic between normotensive and hypertensive rat be find in the prescribed frequency range of the myogenic and tgf mechanism , we employ multiresolution wavelet transform . our analysis reveal that exclusively over scale range corresponding to the frequency interval of the myogenic and tgf mechanism , the width of the blood flow wavelet coefficient fall into disjoint set for normotensive and hypertensive rat . the separation of the scale at the myogenic and tgf frequency range be distinct and obtain with 100 % accuracy . however , this observation remain valid only for the whole kidney blood pressure/flow data . the result suggest that understanding of the time-varying property of the two mechanism be require for a complete description of renal autoregulation",298,0.714285714
7294,Computers and IT,"The classification, monitoring, and compression of electrocardiogram (ECG) signals recorded of a single patient over a relatively long period of time is considered. The particular application we have in mind is high-resolution ECG analysis, such as late potential analysis, morphology changes in QRS during arrythmias, T-wave alternants, or the study of drug effects on ventricular activation. We propose to apply a modification of a classical method of cluster analysis or vector quantization. The novelty of our approach is that we use a new distortion measure to quantify the distance of two ECG cycles, and the class-distortion measure is defined using a min-max criterion. The new class-distortion-measure is much more sensitive to outliers than the usual distortion measures using average-distance. The price of this practical advantage is that computational complexity is significantly increased. The resulting nonsmooth optimization problem is solved by an adapted version of the simultaneous perturbation stochastic approximation (SPSA) method of J. Spall (IEEE Trans. Automat. Contr. , vol. 37, p. 332-41, Mar. 1992). The main idea is to generate a smooth approximation by a randomization procedure. The viability of the method is demonstrated on both simulated and real data. An experimental comparison with the widely used correlation method is given on real data","the classification , monitoring , and compression of electrocardiogram -LRB- ecg -RRB- signal recorded of a single patient over a relatively long period of time be consider . the particular application we have in mind be high-resolution ecg analysis , such as late potential analysis , morphology change in qr during arrythmia , t-wave alternant , or the study of drug effect on ventricular activation . we propose to apply a modification of a classical method of cluster analysis or vector quantization . the novelty of our approach be that we use a new distortion measure to quantify the distance of two ecg cycle , and the class-distortion measure be define use a min-max criterion . the new class-distortion-measure be much more sensitive to outlier than the usual distortion measure use average-distance . the price of this practical advantage be that computational complexity be significantly increase . the result nonsmooth optimization problem be solve by an adapt version of the simultaneous perturbation stochastic approximation -LRB- spsa -RRB- method of j. spall -LRB- ieee tran . automat . contr . , vol . 37 , p. 332-41 , mar. 1992 -RRB- . the main idea be to generate a smooth approximation by a randomization procedure . the viability of the method be demonstrate on both simulated and real data . an experimental comparison with the widely use correlation method be give on real data",205,0.7
7295,Computers and IT,"The ecology of the human intestinal microflora and its interaction with the host are poorly understood. Though more and more data are being acquired, in part using modern molecular methods, development of a quantitative theory has not kept pace with this increase in observing power. This is in part due to the complexity of the system and to the lack of simulation environments in which to test what the ecological effect of a hypothetical mechanism of interaction would be, before resorting to laboratory experiments. The MIMICS project attempts to address this through the development of a cellular automaton for simulation of the intestinal microflora. In this paper, the design and evaluation of this simulator is discussed","the ecology of the human intestinal microflora and its interaction with the host be poorly understand . though more and more data be be acquire , in part use modern molecular method , development of a quantitative theory have not keep pace with this increase in observe power . this be in part due to the complexity of the system and to the lack of simulation environment in which to test what the ecological effect of a hypothetical mechanism of interaction would be , before resort to laboratory experiment . the mimic project attempt to address this through the development of a cellular automaton for simulation of the intestinal microflora . in this paper , the design and evaluation of this simulator be discuss",116,0.454545455
7296,Computers and IT,"Numerical conformal mapping is exploited as a simple, accurate, and efficient tool for the analysis and design of coaxial waveguides and couplers of complex cross section. An implementation based on the Schwarz-Christoffel Toolbox, a public-domain MATLAB package, is applied to slotted coaxial cables and to symmetrical coaxial couplers, with circular or polygonal inner conductors and external shields. The effect of metallic diaphragms of arbitrary thickness, partially separating the inner conductors, is also easily taken into account. The proposed technique is validated against the results of the finite-element method, showing excellent agreement at a fraction of the computational cost, and is also extended to the case of nonsymmetrical couplers, providing the designer with important additional degrees of freedom","numerical conformal mapping be exploit as a simple , accurate , and efficient tool for the analysis and design of coaxial waveguide and coupler of complex cross section . an implementation base on the schwarz-christoffel toolbox , a public-domain matlab package , be apply to slot coaxial cable and to symmetrical coaxial coupler , with circular or polygonal inner conductor and external shield . the effect of metallic diaphragm of arbitrary thickness , partially separate the inner conductor , be also easily take into account . the propose technique be validate against the result of the finite-element method , show excellent agreement at a fraction of the computational cost , and be also extend to the case of nonsymmetrical coupler , provide the designer with important additional degree of freedom",117,0.785714286
7297,Computers and IT,A fast convolution-based time-domain approach to global photonic-circuit simulation is presented that incorporates a physical device model in the complete detector or mixer circuit. The device used in the demonstration of this technique is a GaAs metal-semiconductor-metal (MSM) photodetector that offers a high response speed for the detection and generation of millimeter waves. Global simulation greatly increases the accuracy in evaluating the complete circuit performance because it accounts for the effects of the millimeter-wave embedding circuit. Device and circuit performance are assessed by calculating optical responsivity and bandwidth. Device-only simulations using GaAs MSMs are compared with global simulations that illustrate the strong interdependence between device and external circuit,a fast convolution-based time-domain approach to global photonic-circuit simulation be present that incorporate a physical device model in the complete detector or mixer circuit . the device use in the demonstration of this technique be a gaas metal-semiconductor-metal -LRB- msm -RRB- photodetector that offer a high response speed for the detection and generation of millimeter wave . global simulation greatly increase the accuracy in evaluate the complete circuit performance because it account for the effect of the millimeter-wave embedding circuit . device and circuit performance be assess by calculate optical responsivity and bandwidth . device-only simulation use gaa msm be compare with global simulation that illustrate the strong interdependence between device and external circuit,108,0.545454545
7298,Computers and IT,"This paper discusses an efficient numerical approximation technique, called the differential quadrature method (DQM), which has been adapted to model lossy uniform and nonuniform transmission lines. The DQM can quickly compute the derivative of a function at any point within its bounded domain by estimating a weighted linear sum of values of the function at a small set of points belonging to the domain. Using the DQM, the frequency-domain Telegrapher's partial differential equations for transmission lines can be discretized into a set of easily solvable algebraic equations. DQM reduces interconnects into multiport models whose port voltages and currents are related by rational formulas in the frequency domain. Although the rationalization process in DQM is comparable with the Pade approximation of asymptotic waveform evaluation (AWE) applied to transmission lines, the derivation mechanisms in these two disparate methods are significantly different. Unlike AWE, which employs a complex moment-matching process to obtain rational approximation, the DQM requires no approximation of transcendental functions, thereby avoiding the process of moment generation and moment matching. Due to global sampling of points in the DQM approximation, it requires far fewer grid points in order to build accurate discrete models than other numerical methods do. The DQM-based time-domain model can be readily integrated in a circuit simulator like SPICE","this paper discuss an efficient numerical approximation technique , call the differential quadrature method -LRB- dqm -RRB- , which have be adapt to model lossy uniform and nonuniform transmission line . the dqm can quickly compute the derivative of a function at any point within its bounded domain by estimate a weighted linear sum of value of the function at a small set of point belong to the domain . use the dqm , the frequency-domain telegrapher 's partial differential equation for transmission line can be discretiz into a set of easily solvable algebraic equation . dqm reduce interconnect into multiport model whose port voltage and current be relate by rational formula in the frequency domain . although the rationalization process in dqm be comparable with the pade approximation of asymptotic waveform evaluation -LRB- awe -RRB- apply to transmission line , the derivation mechanism in these two disparate method be significantly different . unlike awe , which employ a complex moment-matching process to obtain rational approximation , the dqm require no approximation of transcendental function , thereby avoid the process of moment generation and moment matching . due to global sampling of point in the dqm approximation , it require far few grid point in order to build accurate discrete model than other numerical method do . the dqm-based time-domain model can be readily integrate in a circuit simulator like spice",211,0.727272727
7299,Computers and IT,"This paper proposes an extension of the unconditionally stable finite-element time-domain (FETD) method for the global electromagnetic analysis of active microwave circuits. This formulation has two advantages. First, the time-step size is no longer governed by the spatial discretization of the mesh, but rather by the Nyquist sampling criterion. Second, the implementation of the truncation by the perfectly matched layers (PML) is straightforward. An anisotropic PML absorbing material is presented for the truncation of FETD lattices. Reflection less than -50 dB is obtained numerically over the entire propagation bandwidth in waveguide and microstrip line. A benchmark test on a microwave amplifier indicates that this extended FETD algorithm is not only superior to finite-difference time-domain-based algorithm in mesh flexibility and simulation accuracy, but also reduces computation time dramatically","this paper propose an extension of the unconditionally stable finite-element time-domain -LRB- fetd -RRB- method for the global electromagnetic analysis of active microwave circuit . this formulation have two advantage . first , the time-step size be no longer govern by the spatial discretization of the mesh , but rather by the nyquist sample criterion . second , the implementation of the truncation by the perfectly match layer -LRB- pml -RRB- be straightforward . an anisotropic pml absorb material be present for the truncation of fetd lattice . reflection less than -50 db be obtain numerically over the entire propagation bandwidth in waveguide and microstrip line . a benchmark test on a microwave amplifier indicate that this extended fetd algorithm be not only superior to finite-difference time-domain-based algorithm in mesh flexibility and simulation accuracy , but also reduce computation time dramatically",127,0.529411765
7300,Computers and IT,"A novel bitline sensing scheme is proposed for low-voltage DRAM to achieve low power dissipation and compatibility with low-voltage CMOS. One of the major obstacles in low-voltage DRAM is the degradation of data-retention time due to low signal level at the memory cell, which requires power-consuming refresh operations more frequently. This paper proposes an offset-cancellation sense-amplifier scheme (OCSA) that improves data-retention time significantly even at low supply voltage. It also improves die efficiency, because the proposed scheme reduces the number of sense amplifiers by supporting more cells in each sense amplifier. Measurements show that the data-retention time of the proposed scheme at 1. 5-V supply voltage is 2. 4 times of the conventional scheme at 2. 0 V","a novel bitline sense scheme be propose for low-voltage dram to achieve low power dissipation and compatibility with low-voltage cmo . one of the major obstacle in low-voltage dram be the degradation of data-retention time due to low signal level at the memory cell , which require power-consuming refresh operation more frequently . this paper propose an offset-cancellation sense-amplifier scheme -LRB- ocsa -RRB- that improve data-retention time significantly even at low supply voltage . it also improve die efficiency , because the propose scheme reduce the number of sense amplifier by support more cell in each sense amplifier . measurement show that the data-retention time of the propose scheme at 1 . 5-v supply voltage be 2 . 4 time of the conventional scheme at 2 . 0 v",118,0.416666667
7301,Computers and IT,"This paper presents a supervisory control scheme based on hybrid systems theory and fuzzy events detection. The fuzzy event detector is a linguistic model, which synthesizes complex relations between process variables and process events incorporating experts' knowledge about the process operation. This kind of detection allows the anticipation of appropriate control actions, which depend upon the selected membership functions used to characterize the process under scrutiny. The proposed supervisory control scheme was successfully implemented for an oxichlorination reactor in a vinyl monomer plant","this paper present a supervisory control scheme base on hybrid system theory and fuzzy event detection . the fuzzy event detector be a linguistic model , which synthesize complex relation between process variable and process event incorporate expert ' knowledge about the process operation . this kind of detection allow the anticipation of appropriate control action , which depend upon the select membership function use to characterize the process under scrutiny . the propose supervisory control scheme be successfully implement for an oxichlorination reactor in a vinyl monomer plant",83,0.555555556
7302,Computers and IT,"A low-power three-dimensional (3-D) rendering engine is implemented as part of a mobile personal digital assistant (PDA) chip. Six-megabit embedded DRAM macros attached to 8-pixel-parallel rendering logic are logically localized with a 3. 2-GB/s runtime reconfigurable bus, reducing the area by 25% compared with conventional local frame-buffer architectures. The low power consumption is achieved by polygon-dependent access to the embedded DRAM macros with line-block mapping providing read-modify-write data transaction. The 3-D rendering engine with 2. 22-Mpolygons/s drawing speed was fabricated using 0. 18- mu m CMOS embedded memory logic technology. Its area is 24 mm/sup 2/ and its power consumption is 120 mW","a low-pow three-dimensional -LRB- 3-d -RRB- render engine be implement as part of a mobile personal digital assistant -LRB- pda -RRB- chip . six-megabit embed dram macro attach to 8-pixel-parallel render logic be logically localize with a 3 . 2-gb/s runtime reconfigurable bus , reduce the area by 25 % compare with conventional local frame-buffer architecture . the low power consumption be achieve by polygon-dependent access to the embed dram macro with line-block mapping provide read-modify-write data transaction . the 3-d rendering engine with 2 . 22-mpolygons/ draw speed be fabricate use 0 . 18 - mu m cmos embed memory logic technology . its area be 24 mm/sup 2 / and its power consumption be 120 mw",103,0.470588235
7303,Computers and IT,"A high-conversion-rate high-resolution oversampling digital-to-analog converter (DAC) for direct digital modulation is addressed in this paper. A new type of switching scheme, called differential-quad switching, is presented. To verify the feasibility of this scheme, essential parts with some auxiliary circuitry for interfacing were fabricated in a 0. 8- mu m CMOS technology. Measured results show that the switching scheme provides 11-b resolution at 100 MSamples/s and 6-b at 1 GSamples/s. The degradation in signal-to-noise ratio is not observed for the variation of the supply voltage down to 1. 5 V, which means the proposed scheme is suitable for low-voltage applications","a high-conversion-rate high-resolution oversampling digital-to-analog converter -LRB- dac -RRB- for direct digital modulation be address in this paper . a new type of switch scheme , call differential-quad switching , be present . to verify the feasibility of this scheme , essential part with some auxiliary circuitry for interfac be fabricate in a 0 . 8 - mu m cmos technology . measure result show that the switch scheme provide 11-b resolution at 100 msamples/ and 6-b at 1 gsamples/ . the degradation in signal-to-noise ratio be not observe for the variation of the supply voltage down to 1 . 5 v , which mean the propose scheme be suitable for low-voltage application",100,0.454545455
7304,Computers and IT,"This paper describes two techniques for designing phase-frequency detectors (PFDs) with higher operating frequencies [periods of less than 8* the delay of a fan-out-4 inverter (FO-4)] and faster frequency acquisition. Prototypes designed in 0. 25- mu m CMOS process exhibit operating frequencies of 1. 25 GHz [=1/(8. FO-4)] and 1. 5 GHz [=1/(6. 7. FO-4)] for two techniques, respectively, whereas a conventional PFD operates at 1 GHz [=1/(10. FO-4)]. The two proposed PFDs achieve a capture range of 1. 7* and 1. 4* the conventional design, respectively","this paper describe two technique for design phase-frequency detector -LRB- pfd -RRB- with high operating frequency -LRB- period of less than 8 * the delay of a fan-out-4 inverter -LRB- fo-4 -RRB- -RRB- and fast frequency acquisition . prototype design in 0 . 25 - mu m cmos process exhibit operate frequency of 1 . 25 ghz -LRB- = 1 / -LRB- 8 . fo-4 -RRB- -RRB- and 1 . 5 ghz -LRB- = 1 / -LRB- 6 . 7 . fo-4 -RRB- -RRB- for two technique , respectively , whereas a conventional pfd operate at 1 ghz -LRB- = 1 / -LRB- 10 . fo-4 -RRB- -RRB- . the two propose pfd achieve a capture range of 1 . 7 * and 1 . 4 * the conventional design , respectively",87,0.363636364
7305,Computers and IT,"In order to scale high-voltage transistors for high-density negative-gate channel-erasing NOR flash memories, two circuit techniques were developed. A proposed level shifter with low operating voltage is composed of three parts, a latch holding the negative erasing voltage, two coupling capacitors connected with the latched nodes in the latch, and high-voltage drivers inverting the latch, resulting in reduction of the maximum internal voltage by 0. 5 V. A proposed high-voltage generator adds a path-gate logic to a conventional high-voltage generator to realize both low noise and low ripple voltage, resulting in a reduction of the maximum internal voltage by 0. 5 V. As a result, these circuit techniques along with high coupling-ratio cell technology can scale down the high-voltage transistors by 15% and can realize higher density negative-gate channel-erase NOR flash memories in comparison with the source-erase NOR flash memories","in order to scale high-voltage transistor for high-density negative-gate channel-erasing nor flash memory , two circuit technique be develop . a proposed level shifter with low operating voltage be compose of three part , a latch hold the negative erase voltage , two coupling capacitor connect with the latched node in the latch , and high-voltage driver invert the latch , result in reduction of the maximum internal voltage by 0 . 5 v. a propose high-voltage generator add a path-gate logic to a conventional high-voltage generator to realize both low noise and low ripple voltage , result in a reduction of the maximum internal voltage by 0 . 5 v. as a result , these circuit technique along with high coupling-ratio cell technology can scale down the high-voltage transistor by 15 % and can realize high density negative-gate channel-erase nor flash memory in comparison with the source-erase nor flash memory",140,0.583333333
7306,Computers and IT,"This paper reports a 0. 8-V 128-kb four-way set-associative two-level CMOS cache memory using a novel two-stage wordline/bitline-oriented tag-compare (WLOTC/BLOTC) and sense wordline/bitline (SWL/SBL) tag-sense amplifiers with an eight-transistor (8-T) tag cell in Level 2 (L2) and a 10-T shrunk logic swing (SLS) memory cell. with the ground/floating (G/F) data sense amplifier in Level 1 (L1) for high-speed operation for low-voltage low-power VLSI system applications. Owing to the reduced loading at the SWL in the new 11-T tag cell using the WLOTC scheme, the 10-T SLS memory cell with G/F sense amplifier in L1, and the split comparison of the index signal in the 8-T tag cells with SWL/SBL tag sense amplifiers in L2, this 0. 8-V cache memory implemented in a 1. 8-V 0. 18- mu m CMOS technology has a measured L1/L2 hit time of 11. 6/20. 5 ns at the average dissipation of 0. 77 mW at 50 MHz","this paper report a 0 . 8-v 128-kb four-way set-associative two-level cmo cache memory use a novel two-stage wordline/bitline-oriented tag-compare -LRB- wlotc/blotc -RRB- and sense wordline/bitline -LRB- swl/sbl -RRB- tag-sense amplifier with an eight-transistor -LRB- 8-t -RRB- tag cell in level 2 -LRB- l2 -RRB- and a 10-t shrink logic swing -LRB- sl -RRB- memory cell . with the ground/float -LRB- g/f -RRB- data sense amplifier in level 1 -LRB- l1 -RRB- for high-speed operation for low-voltage low-pow vlsi system application . owe to the reduce load at the swl in the new 11-t tag cell use the wlotc scheme , the 10-t sl memory cell with g/f sense amplifier in l1 , and the split comparison of the index signal in the 8-t tag cell with swl/sbl tag sense amplifier in l2 , this 0 . 8-v cache memory implement in a 1 . 8-v 0 . 18 - mu m cmos technology have a measure l1/l2 hit time of 11 . 6/20 . 5 n at the average dissipation of 0 . 77 mw at 50 mhz",152,0.380952381
7307,Computers and IT,"The ability to learn spatial relations is a prerequisite for performing many relevant tasks such as those associated with motion, orientation, navigation, etc. This paper reports on using an Inductive Logic Programming (ILP) system for learning function-free Horn-clause descriptions of spatial knowledge. Its main contribution, however, is to show that an existing relation between two reference systems-the speaker-relative and the absolute-can be automatically learned by an ILP system, given the proper background knowledge and positive examples","the ability to learn spatial relation be a prerequisite for perform many relevant task such as those associate with motion , orientation , navigation , etc. this paper report on use an inductive logic programming -LRB- ilp -RRB- system for learn function-free horn-clause description of spatial knowledge . its main contribution , however , be to show that an exist relation between two reference systems-the speaker-relative and the absolute-can be automatically learn by an ilp system , give the proper background knowledge and positive example",76,0.5
7308,Computers and IT,"The Windows NT family of operating systems has always supported the concept of multiple user accounts, but they've taken the concept a step further with Windows XP's Fast User Switching feature. Fast User Switching is a new feature of Windows XP that allows multiple users to log on to the same machine and quickly switch between the logged on accounts. Fast User Switching is implemented using some of the built-in capabilities of Terminal Services. Terminal Server has been around for a while but is much more feature rich and integrated in Windows XP. A machine with the terminal services (Remote Desktop) client can log on to and run applications on a remote machine running the terminal server","the window nt family of operate system have always support the concept of multiple user account , but they 've take the concept a step far with window xp 's fast user switch feature . fast user switching be a new feature of window xp that allow multiple user to log on to the same machine and quickly switch between the log on account . fast user switching be implement use some of the built-in capability of terminal service . terminal server have be around for a while but be much more feature rich and integrate in window xp . a machine with the terminal service -LRB- remote desktop -RRB- client can log on to and run application on a remote machine run the terminal server",117,0.714285714
7309,Computers and IT,"The . NET framework SDK includes several tools that convert source code into executable code-the C# and VB. NET compilers get most of the attention, but there are others. The Regex class (in the System. Text. RegularExpressions namespace) has the ability to compile favorite regular expressions into a . NET assembly. In fact, the NET Common Language Runtime (CLR) contains a whole namespace full of classes to help us build assemblies, define types, and emit their implementations, all at run time. These classes, which comprise the System. Reflection. Emit namespace, are known collectively as Reflection. Emit","the . net framework sdk include several tool that convert source code into executable code-the c # and vb . net compiler get most of the attention , but there be other . the regex class -LRB- in the system . text . regularexpression namespace -RRB- have the ability to compile favorite regular expression into a . net assembly . in fact , the net common language runtime -LRB- clr -RRB- contain a whole namespace full of class to help us build assembly , define type , and emit their implementation , all at run time . these class , which comprise the system . reflection . emit namespace , be know collectively as reflection . emit",96,0.75
7310,Computers and IT,"The author considers obfuscation options for protecting . NET code. Many programs won't need obfuscation because the loss caused by reverse engineering will be nonexistent. Numerous obfuscators are already available for the . NET platform, ranging from a basic renaming obfuscator to a fully functional obfuscator that handles mixed IL/native code assemblies created in any managed language, including Microsoft's C++ with Managed Extensions. An obfuscator simply makes your application harder to reverse engineer. It does not prevent reverse engineering. However, the cost of obfuscation is insignificant when compared to the cost of a typical software development project. If you feel like an obfuscator provides you any benefit at all, it's probably worth the price","the author consider obfuscation option for protect . net code . many program wo n't need obfuscation because the loss cause by reverse engineering will be nonexistent . numerous obfuscator be already available for the . net platform , range from a basic renaming obfuscator to a fully functional obfuscator that handle mixed il/native code assembly create in any manage language , include microsoft 's c + + with manage extension . an obfuscator simply make your application hard to reverse engineer . it do not prevent reverse engineering . however , the cost of obfuscation be insignificant when compare to the cost of a typical software development project . if you feel like an obfuscator provide you any benefit at all , it ' probably worth the price",114,0.333333333
7311,Computers and IT,"In this paper, a tuning method for proportional-integral-derivative (PID) controller and the performance assessment formulas for this method are proposed. This tuning method is based on a genetic algorithm based PID controller design method. For deriving the tuning formula, the genetic algorithm based design method is applied to design PID controllers for a variety of processes. The relationship between the controller parameters and the parameters that characterize the process dynamics are determined and the tuning formula is then derived. Using simulation studies, the rules for assessing the performance of a PID controller tuned by the proposed method are also given. This makes it possible to incorporate the capability to determine if the PID controller is well tuned or not into an autotuner. An autotuner based on this new tuning method and the corresponding performance assessment rules is also established. Simulations and real-time experimental results are given to demonstrate the effectiveness and usefulness of these formulas","in this paper , a tuning method for proportional-integral-derivative -LRB- pid -RRB- controller and the performance assessment formula for this method be propose . this tuning method be base on a genetic algorithm base pid controller design method . for derive the tune formula , the genetic algorithm base design method be apply to design pid controller for a variety of process . the relationship between the controller parameter and the parameter that characterize the process dynamic be determine and the tune formula be then derive . use simulation study , the rule for assess the performance of a pid controller tune by the propose method be also give . this make it possible to incorporate the capability to determine if the pid controller be well tune or not into an autotuner . an autotuner base on this new tuning method and the corresponding performance assessment rule be also establish . simulation and real-time experimental result be give to demonstrate the effectiveness and usefulness of these formula",155,0.714285714
7312,Computers and IT,"In previous averaged models, the state-space averaging technique or switch waveforms analysis were usually applied over perfect elements, non-inclusive of the ohmic losses. However, if these elements play an active role in the DC transfer function, they affect the small-signal AC analysis by introducing various damping effects. A model is introduced in a boost voltage-mode application","in previous average model , the state-space averaging technique or switch waveform analysis be usually apply over perfect element , non-inclusive of the ohmic loss . however , if these element play an active role in the dc transfer function , they affect the small-signal ac analysis by introduce various damp effect . a model be introduce in a boost voltage-mode application",56,0.625
7313,Computers and IT,"Typically, power supply design involves electronic and magnetic components. In this paper, the authors describe, using a flyback converter example, how CAD/CAE tools can aid the power supply engineer in both areas, reducing prototyping costs and providing insights into system performance","typically , power supply design involve electronic and magnetic component . in this paper , the author describe , use a flyback converter example , how cad/cae tool can aid the power supply engineer in both area , reduce prototyp cost and provide insight into system performance",41,0.428571429
7314,Computers and IT,"A desktop virtual reality (VR) program was designed and evaluated to teach children about the accessibility and attitudinal barriers encountered by their peers with mobility impairments. Within this software, children sitting in a virtual wheelchair experience obstacles such as stairs, narrow doors, objects too high to reach, and attitudinal barriers such as inappropriate comments. Using a collaborative research methodology, 15 youth with mobility impairments assisted in developing and beta-testing the software. The effectiveness of the program was then evaluated with 60 children in Grades 4-6 using a controlled pretest/posttest design. The results indicated that the program was effective for increasing children's knowledge of accessibility barriers. Attitudes, grade level, familiarity with individuals with a disability, and gender were also investigated","a desktop virtual reality -LRB- vr -RRB- program be design and evaluate to teach child about the accessibility and attitudinal barrier encounter by their peer with mobility impairment . within this software , child sit in a virtual wheelchair experience obstacle such as stair , narrow door , object too high to reach , and attitudinal barrier such as inappropriate comment . use a collaborative research methodology , 15 youth with mobility impairment assist in develop and beta-test the software . the effectiveness of the program be then evaluate with 60 child in grade 4-6 use a controlled pretest/postt design . the result indicate that the program be effective for increase child 's knowledge of accessibility barrier . attitude , grade level , familiarity with individual with a disability , and gender be also investigate",119,0.583333333
7315,Computers and IT,"This study measured the effect of specific white space features on learning from instructional Web materials. The study also measured learners' beliefs regarding Web-based instruction. Prior research indicated that small changes in the handling of presentation elements can affect learning. Achievement results from this study indicated that in on-line materials, when content and overall structure are sound, minor differences regarding table borders and vertical spacing in text do not hinder learning. Beliefs regarding Web-based instruction and instructors who use it did not differ significantly between treatment groups. Implications of the study and cautions regarding generalizing from the results are discussed","this study measure the effect of specific white space feature on learn from instructional web material . the study also measure learner ' belief regard web-based instruction . prior research indicate that small change in the handling of presentation element can affect learn . achievement result from this study indicate that in on-line material , when content and overall structure be sound , minor difference regard table border and vertical spacing in text do not hinder learn . belief regard web-based instruction and instructor who use it do not differ significantly between treatment group . implication of the study and caution regard generalize from the result be discuss",100,0.571428571
7316,Computers and IT,"The effectiveness of electronic telecommunications as a supplementary aid to instruction and as a communication link between students, and between students and instructors in fostering interpersonal relationships was explored in this study. More specifically, the impacts of e-mail, one of the most accessible, convenient, and easy to use computer-mediated communications, on student attitudes toward the instructor, group-mates, and other classmates were investigated. A posttest-only experimental design was adopted. In total, 68 prospective teachers enrolling in a ""Computers in Education"" course participated in the study for a whole semester. Results from the study provided substantial evidence supporting e-mail's beneficial effects on student attitudes toward the instructor and other classmates","the effectiveness of electronic telecommunication as a supplementary aid to instruction and as a communication link between student , and between student and instructor in foster interpersonal relationship be explore in this study . more specifically , the impact of e-mail , one of the most accessible , convenient , and easy to use computer-mediated communication , on student attitude toward the instructor , group-mate , and other classmate be investigate . a posttest-only experimental design be adopt . in total , 68 prospective teacher enrol in a `` computer in education '' course participate in the study for a whole semester . result from the study provide substantial evidence support e-mail 's beneficial effect on student attitude toward the instructor and other classmate",108,0.625
7317,Computers and IT,"This paper proposes a new method for obtaining a linear quadratic Gaussian (LQG) benchmark in terms of the variances of process input and output from closed-loop data, for assessing the controller performance. LQG benchmark has been proposed in the literature to assess controller performance since the LQG tradeoff curve represents the limit of performance in terms of input and output variances. However, an explicit parametric model is required to calculate the LQG benchmark. In this work, we propose a data driven subspace approach to calculate the LQG benchmark under closed-loop conditions with certain external excitations. The optimal LQG-benchmark variances are obtained directly from the subspace matrices corresponding to the deterministic inputs and the stochastic inputs, which are identified using closed-loop data with setpoint excitation. These variances are used for assessing the controller performance. The method proposed in this paper is applicable to both univariate and multivariate systems. Profit analysis for the implementation of feedforward control to the existing feedback-only control system is also analyzed under the optimal LQG performance framework","this paper propose a new method for obtain a linear quadratic gaussian -LRB- lqg -RRB- benchmark in term of the variance of process input and output from closed-loop data , for assess the controller performance . lqg benchmark have be propose in the literature to assess controller performance since the lqg tradeoff curve represent the limit of performance in term of input and output variance . however , an explicit parametric model be require to calculate the lqg benchmark . in this work , we propose a data drive subspace approach to calculate the lqg benchmark under closed-loop condition with certain external excitation . the optimal lqg-benchmark variance be obtain directly from the subspace matric corresponding to the deterministic input and the stochastic input , which be identify use closed-loop data with setpoint excitation . these variance be use for assess the controller performance . the method propose in this paper be applicable to both univariate and multivariate system . profit analysis for the implementation of feedforward control to the exist feedback-only control system be also analyze under the optimal lqg performance framework",170,0.583333333
7318,Computers and IT,"A surge of telecom executives and directors purchasing their own companies, stock in the last two months points toward a renewed optimism in the beleaguered sector, say some observers, who view the rash of insider buying as a vote of confidence from management. Airgate PCS, Charter Communications, Cox Communications, Crown Castle International, Nextel Communications and Nortel Networks all have seen infusions of insider investment this summer, echoing trends in both the telecom industry and the national economy","a surge of telecom executive and director purchase their own company , stock in the last two month point toward a renew optimism in the beleaguered sector , say some observer , who view the rash of insider buying as a vote of confidence from management . airgate pc , charter communication , cox communication , crown castle international , nextel communication and nortel network all have see infusion of insider investment this summer , echo trend in both the telecom industry and the national economy",77,1
